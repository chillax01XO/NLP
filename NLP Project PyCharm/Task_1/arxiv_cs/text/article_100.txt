arXiv:2505.20947v1  [astro-ph.SR]  27 May 2025Astronomy &Astrophysics manuscript no. aanda2 ©ESO 2025
May 28, 2025
Unified Deep Learning Approach for Estimating the Metallicities of
RR Lyrae Stars Using light curves from Gaia Data Release 3
L. Monti1, T. Muraveva1, A. Garofalo1, G. Clementini1, and M.L. Valentini2
INAF - Osservatorio di Astrofisica e Scienza dello Spazio di Bologna, via Piero Gobetti 93 /3, 40129 Bologna, Italy;
e-mail: lorenzo.monti@inaf.it
Received ; accepted
ABSTRACT
Context. RR Lyrae stars (RRLs) are old population pulsating variables that serve as useful metallicity tracers due to the correlation
between their metal abundances and the shape of their light curves. With the advent of ESA’s Gaia mission Data Release 3 (DR3),
which provides light curves for approximately 270,000 RRLs, it has become crucial to develop a machine learning technique that
allows for the estimation of metallicities for large samples of RRLs directly from their light curves.
Aims. We aim to develop and validate a unified Deep Learning (DL) framework capable of accurately estimating metallicities for
both fundamental mode (RRab) and first-overtone (RRc) RRLs using G-band light curves published in Gaia DR3. We seek to extend
our previous DL model, which was successful for RRab stars, to encompass RRc variables. Our objective is to evaluate the model’s
performance in terms of accuracy and reliability across both types of RRLs. Through this research, we aim to demonstrate the potential
of DL in processing and analyzing large-scale astronomical datasets. Ultimately, we strive to contribute to a more comprehensive
understanding of stellar populations and galactic structure through improved metallicity estimations.
Methods. We employ a Gated Recurrent Units (GRU) based neural network architecture optimized for time-series extrinsic regression.
The framework incorporates a rigorous preprocessing pipeline (including phase folding, smoothing, and sample weighting) and is
trained using Gaia DR3 G-band light curves and photometric metallicities of RRLs, available in the literature. The model architecture
and training implicitly handle the morphological di fferences between RRab and RRc light curves.
Results. Our unified GRU model achieves high predictive accuracy and robust generalization on validation sets for both types of
RRLs. For RRab stars, we obtain Mean Absolute Error (MAE) =0.0565 dex, Root Mean Squared Error (RMSE) =0.0765 dex, and
determination score R2=0.9401. For RRc stars, performance is similarly strong with MAE =0.0505 dex, RMSE =0.0720 dex, and
R2=0.9625, demonstrating the framework’s e ffectiveness across di fferent RRL pulsation modes.
Key words. Variable stars – RR Lyrae – Time-series Extrinsic Regression – Deep Learning
Use\titlerunning to supply a shorter title and /or\authorrunning to supply a shorter list of authors.
1. Introduction
RR Lyrae (RRL) stars are low-mass (M <1M⊙), core helium-
burning variables characterized by radial pulsations, with pe-
riods typically ranging from 0.2 to 1 day (Smith 2004). Even
though recent studies suggest that relatively young and metal-
rich RRLs may form through the evolution of close binary sys-
tems (Bobrick et al. 2024), the vast majority of RRLs are old ( >
10 Gyr), metal-poor stars associated with the Milky Way (MW)
halo and old stellar systems such as globular clusters (GCs),
dwarf spheroidal (dSph) galaxies and ultra-faint dwarfs (e.g.,
Dall’Ora et al. 2006; Clementini et al. 2012; Garofalo et al.
2013; Sesar et al. 2014; Molnár et al. 2015; Muraveva et al.
2020; Garofalo et al. 2021). RRLs are classified into three pul-
sation modes: fundamental mode (RRab), first-overtone (RRc),
and double-mode (RRd) stars. Their distinct pulsation character-
istics and the occurrence in ancient systems make them powerful
tools for studying the structure, formation history, and chemical
evolution of the MW and Local Group galaxies (Drake et al.
2013; Belokurov et al. 2018; Iorio & Belokurov 2019, 2021).
RRL stars serve as useful metallicity ([Fe /H]) tracers. The
most direct method for measuring their metal abundances is
through high-resolution (HR, R ≥20,000) spectroscopy, which
yields metallicities with an accuracy of ∼0.1 dex but requires
significant telescope time. To date, metallicities from HR spectraare available for only a limited number of RRLs (e.g., Clemen-
tini et al. 1995, Nemec et al. 2013, Pancino et al. 2015, Cha-
did et al. 2017), although this number has increased to a cou-
ple of hundreds in recent years (Crestani et al. 2021; Gilligan
et al. 2021; D’Orazi et al. 2024). The metallicities of RRLs can
also be measured from low-resolution (LR) spectra using the ∆S
method (Preston 1959), which is based on the ratio of the equiva-
lent widths of Ca and H lines. This approach extends the number
of RRLs with available metallicities to thousands (e.g., Liu et al.
2020, Crestani et al. 2021, Fabrizio et al. 2021), though with
lower precision (typical uncertainties of ∼0.2–0.3 dex).
The metallicities of RRLs can also be determined using only
photometric observations, as there is a correlation between RRL
metallicity and the shape of the light curve. Jurcsik & Kovacs
(1996) found a linear relation between the metallicity of RRab
stars and the Fourier parameter ϕ31of their light curves in the V
band, along with the pulsation period. Morgan et al. (2007) de-
rived a similar relation for RRc stars. Several authors later cali-
brated these relations in di fferent passbands (e.g., Smolec 2005,
Nemec et al. 2013, Iorio & Belokurov 2021, Li et al. 2023).
These relations o ffer a pathway to estimate metallicities for large
samples of RRLs using only photometric data, thereby bypass-
ing the need for time-intensive spectroscopy. However, accu-
rately calibrating these photometric metallicity relations across
Article number, page 1 of 13A&A proofs: manuscript no. aanda2
different photometric bands has proven challenging. Since HR
spectroscopic metallicities are available for only a few hundred
RRLs, many calibrations have relied either on LR spectroscopic
estimates or on transferring empirical formulae calibrated in one
photometric band to another via Fourier parameter transforma-
tions (Skowron et al. 2016; Clementini et al. 2019). Both ap-
proaches introduce potential systematic errors and biases, aris-
ing from intermediate calibration steps or from the intrinsic
noise and metallicity dependence of the parameter transforma-
tions (Dékány et al. 2021). These limitations have often resulted
in discrepancies and systematic o ffsets between metallicity esti-
mates from di fferent methods (Dékány & Grebel 2022).
A promising solution to this problem is the direct estimation
of RRL metallicities from light curves using Machine Learning
(ML) and Deep Learning (DL) techniques. These approaches al-
low for modeling non-linear relationships between light-curve
morphology and metallicity, potentially bypassing intermedi-
ate calibration steps and enabling the direct use of raw time-
series data. Predicting metallicity directly from photometric light
curves using DL techniques o ffers several key advantages. First,
it enables the analysis of large datasets without the need for time-
consuming and costly spectroscopic observations. Second, it
minimizes the introduction of biases or noise that can arise from
relying on multiple empirical relations or calibrations across dif-
ferent passbands. Third, it allows for more consistent and homo-
geneous metallicity estimates across diverse datasets, enhancing
our ability to trace stellar populations of di fferent metallicity in
the MW and Local Group galaxies.
Recent studies have explored ML /DL approaches to predict
RRL metallicities, either through regression on Fourier param-
eters (Hajdu et al. 2018; Dékány et al. 2021; Muraveva et al.
2025) or by leveraging the full light-curve information using
architectures such as Recurrent Neural Networks (RNNs), in-
cluding Long Short-Term Memory (LSTM) and Gated Recur-
rent Units (GRU), as well as Convolutional Neural Networks
(CNNs) (Dékány & Grebel 2022; Monti et al. 2024). ML meth-
ods have also demonstrated remarkable success in capturing
complex patterns in time-series data, such as the light curves of
variable stars (Belokurov et al. 2003, 2004; Wo´ zniak et al. 2004;
Willemsen & Eyer 2007; Debosscher et al. 2007; Mahabal et al.
2008; Richards et al. 2011). Furthermore, techniques like trans-
fer learning have been employed to extend well-calibrated mod-
els from one photometric band to others with minimal additional
noise (Dékány & Grebel 2022).
The application of DL directly to light curves has become
both crucial and timely with the advent of the ESA Gaia mis-
sion (Gaia Collaboration et al. 2016) Data Release 3 (DR3, Gaia
Collaboration et al. 2023), which, among other data products,
includes a catalogue of 271,779 RRLs across the whole sky
(Clementini et al. 2023). This catalogue provides time-series
photometry in the G,GBP, and GRPbands, as well as pulsa-
tion parameters (periods, amplitudes) for all RRLs in the sample.
However, photometric metallicities were made available for only
133,577 RRLs (49% of the sample), for which the Fourier pa-
rameterϕ31was calculated. Thus, retrieving metallicities directly
from the G-band light curves by means of DL method would not
only reduce systematics introduced by intermediate calibrations,
but also nearly double the number of RRLs with known photo-
metric metallicities. This approach will become even more rel-
evant with the advent of Gaia Data Release 4 (DR4), currently
expected in the second half of 2026, which will include time-
series photometry for two billion stars.
In Monti et al. (2024), we present a DL algorithm for estimat-
ing the photometric metallicities from the light curves of RRabstars. In this paper, we propose a unified DL approach for esti-
mating the photometric metallicity of both RRab and RRc stars
using Gaia DR3 G-band light curves. By leveraging advanced
DL techniques, such as CNNs and RNNs, we aim to provide ac-
curate metallicity predictions.
The paper is organized as follows: Section 2 describes the
dataset and preprocessing steps. Section 3 outlines the archi-
tecture and training process of the DL models. We also present
strategies for model selection and optimization, along with per-
formance results, including evaluations of the model’s accuracy.
In Section 4, we validate the derived metallicities. Finally, Sec-
tion 5 summarizes our findings and discusses directions for fu-
ture research.
2. Photometric Data and Preprocessing
This study frames the prediction of photometric metallicity from
light curves as a Time-series Extrinsic Regression (TSER) prob-
lem, following the definition by Tan et al. (2021) and as ap-
plied in Monti et al. (2024). TSER aims to establish a map-
ping from an entire time series (the light curve) to a continu-
ous scalar value (metallicity). Building upon the definition by
Tan et al. (2021), TSER specifically addresses the task of pre-
dicting a single, static, continuous scalar value (the ’extrinsic’
property) based on the characteristics of an entire input time se-
ries. This contrasts fundamentally with Time-Series Forecasting
(TSF), where the goal is typically to predict future values within
the sequence itself. In our context, metallicity is an intrinsic,
time-invariant property of RRLs.
Essentially, the TSER model must learn the complex, poten-
tially non-linear function f:T → R, whereTis the space of
possible light-curve sequences (after appropriate preprocessing
and standardization) and Rrepresents the continuous metallicity
scale. This involves identifying and utilizing patterns across the
entire time series relevant to the extrinsic target variable. Thus,
framing our problem as TSER accurately reflects the objective:
regressing an extrinsic scalar property ([Fe /H]) from the com-
plete photometric time series representing the star’s pulsation.
2.1. Data Selection and Initial Cleaning
TheGaia DR3 catalogue includes 270,891 RRLs analyzed and
confirmed by the Specific Object Study pipeline for Cepheids
and RRLs (SOS Cep&RRL; Clementini et al. 2023). The cat-
alogue provides, among other parameters, pulsation periods,
epochs of maximum light, mean magnitudes, and Fourier de-
composition parameters of the G-band light curves, along with
time-series photometry in the G,GBP, and GRPbands. In Mu-
raveva et al. (2025), we cleaned the sample of RRLs from the
Gaia DR3 catalogue and presented new relations between the
RRL metallicities, their pulsation periods, and the Fourier de-
composition parameters published in DR3. These relations were
calibrated using the spectroscopic metallicities available in the
literature (Crestani et al. 2021; Liu et al. 2020). A feature selec-
tion algorithm was employed to identify the most relevant fea-
tures for metallicity estimation. To fit the relations, we adopted a
Bayesian approach, accounting for parameter uncertainties and
the intrinsic scatter in the data. As a result, photometric metal-
licity estimates were derived for 134,769 RRLs (114,468 RRab
and 20,001 RRc) from the clean Gaia DR3 sample.
In this study, we use the time-series photometry of RRLs in
theG-band from the Gaia archive1, along with pulsation periods
1https://gea.esac.esa.int/archive/
Article number, page 2 of 13L. Monti, T. Muraveva, A. Garofalo, G. Clementini , M.L. Valentini: Unified DL approach for estimating [Fe /H] of RRLs using Gaia DR3
from the vari_rrlyrae table (Clementini et al. 2023), for a
cleaned sample of RRLs with available photometric metallicities
from Muraveva et al. (2025). To ensure a high-quality dataset
suitable for DL models, we applied stringent selection criteria to
the RRL sample, targeting both RRab and RRc stars:
–The uncertainty in the photometric metallicity estimate from
Muraveva et al. (2025) ( σ[Fe/H]) was constrained to be ≤
0.4 dex, ensuring reliable metallicity labels.
–The peak-to-peak amplitude in the Gaia G -band ( AmpG )
was limited to≤1.4 mag to exclude potential outliers or
misclassified variables with unusually large amplitudes.
–Each light curve required a minimum of 50 observed epochs
(Nepochs≥50) in the G-band to ensure adequate phase cover-
age for reliable characterization.
–The uncertainty in the Fourier phase parameter ϕ31(σϕ31)
was required to be ≤0.10 (only for RRab stars).
These criteria filter out sources with low-quality metallicity es-
timates or poorly sampled /characterized light curves, yielding
a robust dataset. The final datasets satisfying these criteria con-
sisted of 6002 RRab stars (4801 for training, 1201 for validation)
and 6613 RRc stars (5290 for training, 1323 for validation). An
illustrative example of the data structure is provided in Table
A.1. Figure 1 displays the amplitude in the Gband versus pe-
riod diagram (Bailey diagram) for the selected RRab and RRc
development datasets, color-coded by their [Fe /H] values. The
diagram clearly illustrates the well-known dependence of ampli-
tude on period and metallicity for RRL stars (e.g., Clementini
et al. 2023).
2.2. Phase Folding and Alignment
A fundamental step in analyzing periodic variable stars is phase
folding. The phase ( Φ) for each observational transit was calcu-
lated using the following equation:
Φ = T−Epochmax
P!
−mod T−Epochmax
P!
, (1)
where Trepresents the observation time (that is: the Heliocen-
tric Julian Day of observation - HJD), and EpochmaxandPcor-
respond to the epoch of maximum light and the pulsation period,
respectively, as provided in the Gaia DR3 vari_rrlyrae table
(Clementini et al. 2023). This process aligned the light curves
to a common phase reference, facilitating direct comparisons
across multiple cycles of variability. Aligning the light curves to
the phase of maximum light is crucial, especially for the asym-
metric RRab stars, ensuring consistent feature representation for
the subsequent modeling steps (see e.g., Dékány & Grebel 2022
for detailed discussion on phase alignment).
2.3. Smoothing Spline Interpolation and Standardization
Gaia DR3 light curves often have uneven sampling and varying
numbers of data points in the G-band, ranging from 51 to 256
in our development datasets. To create uniform input sequences
suitable for DL models and to reduce observational noise, a
smoothing spline interpolation was applied to each phase-folded
light curve using the SciPy library’s UnivariateSpline func-
tion (Virtanen et al. 2020). In more detail, this technique is used
for fitting a smooth curve to a dataset, striking a balance between
accurately representing the data and minimizing noise or fluctu-
ations while standardizing the number of data points across alllight curves. In this context, the data consists of light curves char-
acterized by magnitude and phase, with each light curve con-
taining a varying number of data points. The method involves
determining a function that passes near the data points while
minimizing the overall roughness or curvature of the curve. This
approach is especially valuable when the data contains random
noise, as it provides a clearer representation of underlying trends
or patterns.
The smoothing spline achieves this by minimizing the sum of
squared deviations between the fitted curve and the data points,
while imposing a penalty on the curve’s curvature. Mathemati-
cally, the problem is formulated as:
nX
i=1(yi−f(xi))2+λZ
(f′′(x))2dx (2)
Here, f(x) is the smooth function being fitted, ( xi,yi) are the
data points, λis a smoothing parameter that controls the trade-
offbetween adherence to the data and smoothness of the curve,
andR
(f′′(x))2dxpenalizes excessive curvature by integrating the
squared second derivative of the function. The result is a contin-
uous representation of the light curve, from which we sampled
a fixed number of points (264 points for RRab and 265 points
for RRc stars, uniformly distributed in phase) to standardize the
length of all input sequences. This process e ffectively reduces
noise while preserving the underlying shape of the light curve.
Following the spline interpolation and resampling, the mag-
nitudes of each light curve were standardized. This crucial step
was performed using the StandardScaler from the Scikit-
learn library2Pedregosa et al. (2011). For each light curve, this
process involves subtracting its mean magnitude ( µm) and then
dividing by its standard deviation of magnitudes ( σm). From an
astrophysical perspective, subtracting the mean magnitude ef-
fectively removes the star’s average apparent magnitude over its
pulsation cycle, thus centering the light curve around zero. This
allows the subsequent analysis to be independent of the star’s in-
trinsic luminosity, distance, and interstellar extinction, contribut-
ing to the observed mean magnitude. Subsequently, dividing by
the magnitudes’ standard deviation normalizes the light varia-
tion’s amplitude. This ensures that all light curves are compared
on a similar scale of variability, making the model focus on the
shape andmorphological characteristics of the light curve (e.g.,
skewness, acuteness of maxima /minima) rather than the absolute
amplitude of pulsation, which can vary significantly even within
the same class of variable stars. This standardization yields light
curves with a mean of zero and a unit standard deviation, mak-
ing them more suitable for training DL models by preventing
features with larger numerical ranges from dominating the learn-
ing process. The resulting standardized light curves of RRab and
RRc from our developement datasets are shown in Fig.2.
2.4. Sample Weights for Imbalanced Data
The photometric metallicity distribution of the RRLs in our
development datasets is significantly unbalanced, with a pro-
nounced peak around [Fe /H]∼ − 1.5 dex for RRab and ∼
−1.3 dex for RRc stars (see Fig. 3). This imbalance can bias
model training, as regions of the parameter space with fewer
sources contribute less to the loss function during optimization.
To address this issue, we introduce density-dependent sample
weights during training.
2https://scikit-learn.org
Article number, page 3 of 13A&A proofs: manuscript no. aanda2
Fig. 1: Distributions of RRab and RRc stars from our selected development datasets on the amplitude in the Gband versus period
diagram, color-coded by metallicity.
(a)
 (b)
Fig. 2: Normalized splined G-band light curves of 6002 RRab stars (a) and 6613 RRc stars (b) from our development datasets.
The sample weights ( wd) were computed using a Gaussian
kernel density estimation (Gaussian KDE) approach:
wd=1
ˆρ(x), (3)
where ˆρ(x) is the normalized density estimate of the metallicity
distribution at a given point x. Gaussian kernels were used to es-
timate the density ˆ ρ, ensuring that areas with lower data density
received higher weights. These weights were normalized to en-
sure the sum of all weights equals the total number of samples,
thereby preserving the overall loss scale.The sample weights wdwere integrated into the training
pipeline as tensor inputs alongside the light curve data. Specifi-
cally:
–Theinput tensor consists of the preprocessed light curve
data:
X={X(t)}Nep
t=1
where X(t)is defined as:
X<t>=(m<t>−<m>
Ph·Pt={1,...,Nep} (4)
Article number, page 4 of 13L. Monti, T. Muraveva, A. Garofalo, G. Clementini , M.L. Valentini: Unified DL approach for estimating [Fe /H] of RRLs using Gaia DR3
–Thesample weights tensor
w={wd}N
i=1
was supplied as an additional input to the model’s loss func-
tion. In practice, this means each sample in the dataset con-
tributes to the loss function proportionally to its assigned
weight wd.
Integrating sample weights allows the model to account for
the entire range of metallicities, mitigating bias caused by over-
represented regions in the dataset. Fig. 3 illustrates the photomet-
ric metallicity distribution and the corresponding sample weights
for RRab (left panel) and RRc (right panel) stars.
2.5. Improved Model Performance with Uniform
Preprocessing
As demonstrated by Monti et al. (2024), preprocessing the
phase-folded light curves significantly improves model perfor-
mance. Applying noise reduction techniques, phase alignment,
smoothing spline method, and sample weights enhances the pre-
dictive accuracy of DL models by ensuring consistent and high-
quality input data. These improvements are particularly evident
in regression tasks, where the preprocessing pipeline mitigates
variability and biases inherent to raw observational data.
Both RRab and RRc stars were subjected to the identical
preprocessing pipeline, ensuring the same degree of noise re-
duction, phase alignment, and normalization. Despite the intrin-
sic di fferences in their light curve shapes – sawtooth-shaped for
RRab and sinusoidal for RRc, clearly recognizable only in the
optical bands, where the pulsation signatures are most promi-
nent – this unified approach guarantees comparable inputs for
subsequent modeling, preserving the integrity of their physical
and observational characteristics.
3. Predictive modeling
3.1. RNNs
RNNs are a class of artificial neural networks designed to model
sequential data by leveraging temporal dynamics. Unlike tradi-
tional feedforward neural networks, RNNs incorporate recurrent
connections that enable them to maintain a hidden state, cap-
turing information from previous time steps (Williams & Zipser
1989). This capability makes RNNs well-suited for tasks where
the order and context of data points are critical, such as time se-
ries analysis (Connor et al. 1994), natural language processing
(Rodriguez et al. 1999), and speech recognition (Robinson et al.
1996).
Mathematically, the hidden state htof an RNN at time tis
updated as:
ht=f(Wh·ht−1+Wx·xt+b), (5)
where xtis the input at time t,WhandWxare weight matrices,
bis the bias, and fis a non-linear activation function, typically
tanh or ReLU. The output of the RNN can either be a single
value (for tasks like regression or classification) or a sequence
(for tasks like translation or text generation). However, tradi-
tional RNNs face challenges such as the vanishing and exploding
gradient problems, which limit their ability to learn long-term
dependencies in sequences. To address these issues, advanced
architectures like LSTM and GRU have been developed. These
architectures introduce gating mechanisms that allow the net-
work to selectively store, forget, or update information across
time steps.3.2. GRU Neural Networks
The GRU, introduced by Cho et al. (2014), is a variant of the
RNN designed to address the vanishing gradient problem in se-
quential data modeling. GRUs, like LSTM networks, capture
long-term dependencies but are computationally lighter due to
their simplified gating mechanism. The architecture of a GRU
incorporates two primary gates: the update gate and the reset
gate. The update gate ztdetermines the amount of information
from the past to retain, while the reset gate rtcontrols the degree
of forgetting of previous states. The mathematical formulation
for GRU is as follows:
zt=σ(Wz·[ht−1,xt]+bz), (6)
rt=σ(Wr·[ht−1,xt]+br), (7)
˜ht=tanh( Wh·[rt∗ht−1,xt]+bh), (8)
ht=(1−zt)∗ht−1+zt∗˜ht, (9)
where xtis the input, ht−1is the hidden state from the previ-
ous timestep, Wandbare learnable weights and biases, σis the
sigmoid activation function, and tanh is the hyperbolic tangent
activation function.
GRUs are particularly e ffective for regression tasks involving
sequential data, such as time series prediction. To adapt GRUs
for regression, the network is typically structured with a dense
output layer having a linear activation function:
ˆy=Wo·ht+bo, (10)
where Woandboare the weights and biases of the output layer,
and ˆyis the predicted continuous value.
The network is trained to minimize a loss function suitable
for regression, such as Mean Squared Error (MSE):
LMSE=1
nnX
i=1(yi−ˆyi)2, (11)
where yiand ˆyiare the ground truth and predicted values, respec-
tively.
The choice of GRU is further supported by our previous find-
ings Monti et al. (2024), where nine di fferent sequential models
were evaluated, and the GRU architecture consistently yielded
the best performance.
In our architecture shown in Fig. 4, each main block com-
prises a GRU layer followed by a dropout layer , mitigating
overfitting and enhancing the model’s generalization capabili-
ties. This approach is pivotal in improving the performance and
robustness of models handling sequential data. The final config-
uration of the GRU network includes three such main blocks,
followed by a dense layer with linear activation, as detailed in
the formal description below:
h(0)
t=X
for i=1to n
h(i)
t=GRU_block( d(i−1)
t)
d(i)
t=Dropout( h(i)
t)
end for
ˆy=Dense( d(n)
t) (12)
Here, nrepresents the number of main blocks, set to 3 in
our design, and GRU _block refers to a block constructed using
aGRU layer .
Article number, page 5 of 13A&A proofs: manuscript no. aanda2
(a)
 (b)
Fig. 3: Photometric metallicity distributions and corresponding sample weights (black lines) for RRab ( left panel ) and RRc ( right
panel ) stars. Regions with lower data density are assigned higher weights to ensure a balanced contribution during model training.
Fig. 4: Schematic overview of the GRU-based neural network architecture used for predicting stellar metallicity ([Fe /H]) from
pre-processed light curves. The model comprises an input layer, a sequence of GRU layers with Tanh activations, interleaved with
dropout layers to prevent overfitting, followed by a dense linear layer producing the final regression output.
3.3. Strategies for Model Selection and Optimization
The development of an e ffective predictive model involves
two fundamental stages: training andhyperparameter optimiza-
tion. During the training phase, the model’s internal parameters
(weights and biases) are adjusted iteratively to minimize a cho-
sen loss function on a dedicated training dataset. For neural net-
works, this minimization is typically achieved using gradient-
based optimization algorithms (Goodfellow et al. 2016). Con-
currently, hyperparameter optimization focuses on selecting thebest configuration for the model architecture and the training
process itself. Hyperparameters — such as the number of layers,
the number of neurons per layer, the learning rate, dropout prob-
ability, and the type of regularization — are not learned directly
from the training data but are set beforehand. Their optimal val-
ues are determined by evaluating the model’s performance on
a separate validation dataset, ensuring the chosen configuration
generalizes well to unseen data.
For efficient hyperparameter exploration across the nine dif-
ferent network architectures considered, we employed the Hy-
Article number, page 6 of 13L. Monti, T. Muraveva, A. Garofalo, G. Clementini , M.L. Valentini: Unified DL approach for estimating [Fe /H] of RRLs using Gaia DR3
perband algorithm (Li et al. 2018), as implemented in the Scikit-
learn library (Pedregosa et al. 2011). The search space included
dropout rates in [0.1, 0.2, 0.4, 0.6], learning rates in [0.001, 0.01,
0.1], and batch sizes in [32, 64, 128, 256, 512].
The core of the training process utilized the MSE as the
loss function. Crucially, this loss was weighted using the sam-
ple weights derived in Section 2.4 to counteract the metallicity
imbalance inherent in the RRL dataset (Fig. 3). To mitigate the
risk of overfitting—where the model learns the training data too
well, including its noise, and performs poorly on new data—we
incorporated standard regularization techniques. Specifically, we
experimented with kernel regularization [L1 and L2 penalties,
also known as Lasso (Tibshirani 1996) and Ridge (Hoerl & Ken-
nard 1970), applied to network weights] and Dropout (Srivastava
et al. 2014), which randomly sets a fraction of neuron outputs
to zero during training, preventing over-reliance on specific fea-
tures. The Hyperband search helped identify the optimal com-
bination of these regularization strategies and their associated
parameters (e.g., dropout rate, L1 /L2 strength) for each architec-
ture.
Evaluating model performance during hyperparameter tun-
ingand for final assessment requires metrics that accurately re-
flect prediction quality on unseen data. We used standard re-
gression metrics: Root Mean Squared Error (RMSE) and Mean
Absolute Error (MAE), along with their weighted counterparts
(wRMSE and wMAE) that incorporate the sample weights.
These metrics quantify the average prediction error magnitude.
Additionally, we considered the coe fficient of determination ( R2)
score:
R2=1−P
i(yi−ˆyi)2
P
i(yi−¯y)2, (13)
where yirepresents the observed value of the dependent vari-
able for the i-th observation, ˆ yirepresents the value of the de-
pendent variable predicted by the model for the i-th observation,
and ¯yrepresents the mean of the observed values. The R2value
ranges from 0 to 1, with 1 indicating perfect prediction and 0 in-
dicating that it does not explain any variability in the dependent
variable. Higher R2values suggest a better model fit.
To obtain robust estimates of model performance and gen-
eralization ability, we employed Repeated Stratified K-Fold
Cross-Validation . This technique extends standard K-Fold cross-
validation. The dataset is divided into K folds (partitions). In
each iteration, K-1 folds are used for training, and the remaining
fold is used for validation. Stratification ensures that the distribu-
tion of metallicity values (the target value) is approximately pre-
served in each fold, which is crucial given the imbalanced nature
of our data (Section 2.4). The entire K-fold process is repeated
multiple times with di fferent random shu ffles of the data before
splitting into folds. This repetition reduces the dependence of
the performance estimate on the specific random splits, yielding
a more reliable assessment of how the model is likely to perform
on new, unseen data.
For the actual parameter updates during training, we uti-
lized the Adam optimization algorithm (Kingma & Ba 2014),
a widely-used adaptive learning rate method known for its e ffi-
ciency and e ffectiveness in DL tasks. A fixed learning rate of
0.01 was used, selected via the hyperparameter search. Early
stopping was employed as an additional regularization measure:
training was halted when performance on the validation fold
ceased to improve for a predefined number of epochs, prevent-
ing overfitting by stopping before the model starts fitting noisein the training data. A mini-batch size of 256 was used to bal-
ance computational e fficiency with the stochasticity needed for
effective gradient descent, while ensuring that each batch pro-
vided a reasonably comprehensive representation of the metal-
licity range. All code developed for this study is publicly avail-
able in the open-source GitHub repository3.
Fig. 5 displays the learning curves for our best-performing
model ( GRU , see Section 3.2) during the Repeated Stratified K-
Fold Cross-Validation process. The plots show the evolution of
the error’s loss on both the training folds (red lines) and the cor-
responding validation fold (green lines) over the training epochs,
separately for RRab (left panel) and RRc stars (right panel). For
both stellar types, a clear and consistent decrease in both training
and validation loss is observed as training progresses, indicating
that the model is e ffectively learning the underlying relationship
between the light curve features and metallicity. Importantly, the
validation loss closely tracks the training loss without significant
divergence, even across di fferent folds (indicated by the overlap
and darker colors where lines coincide). This behavior strongly
suggests that the combination of our chosen model architecture
(GRU), the preprocessing pipeline (Section 2), and the regular-
ization strategies employed (Dropout, L1 /L2 penalties, and early
stopping, as discussed above in Section 3.3) successfully pre-
vents overfitting. The model demonstrates good generalization
capability, performing well not only on the data it was trained on
but also on unseen data within the validation folds. The stability
of the learning process across the multiple folds and repetitions
further underscores the robustness of our training methodology
and the resulting predictive model.
3.4. Quantitative Performance Evaluation
Having established the model architecture (GRU), preprocessing
pipeline (Section 2), and optimization strategy (Section 3.3), we
now evaluate the quantitative performance of our final predictive
model for TSER of RRL star’s metallicity. The goal is to assess
how accurately the model predicts the photometric [Fe /H] values
derived by Muraveva et al. (2025) based solely on the Gaia DR3
G-band light curves. The performance metrics, computed on the
training and validation sets obtained through the Repeated Strat-
ified K-Fold Cross-Validation process described in Section 3.3,
are summarized in Table 1. The results are presented separately
for RRab and RRc stars.
Our optimized GRU model demonstrates high predictive ac-
curacy and robust generalization. The coe fficient of determina-
tionR2values are notably high: for RRab stars, R2=0.9447 on
the training set and R2=0.9401 on the validation set. For RRc
stars, the performance is even slightly better, with R2=0.9668
(training) and R2=0.9625 (validation). The close agreement
between training and validation R2scores, along with the high
absolute values, indicates that the model e ffectively captures the
variance in metallicity explained by the light curve features and
generalizes well to unseen data, avoiding significant overfitting.
The error metrics further corroborate the model’s accuracy.
The wRMSE, which accounts for the metallicity distribution im-
balance (Section 2.4), is low for both types: 0.0733 dex (RRab
train), 0.0763 dex (RRab validation), 0.0679 dex (RRc train),
and 0.0722 dex (RRc validation). Similarly, the wMAE values
are also small, around 0.05-0.06 dex for both types and splits.
The standard (unweighted) RMSE and MAE metrics show com-
parable low values, reinforcing the conclusion of high predictive
precision across the board.
3https: //github.com /LorenzoMonti /metallicity_rrls
Article number, page 7 of 13A&A proofs: manuscript no. aanda2
(a)
 (b)
Fig. 5: Training (red) and validation (green) loss curves across epochs for each of the five cross-validation folds.The left panel (a)
corresponds to RRab stars, while the right panel (b) represents RRc stars. A steady decrease in both losses indicates e ffective model
learning, while the close alignment between training and validation loss across folds suggests good generalization and minimal
overfitting. Darker colors denote greater consistency between folds.
Compared to relevant prior work using DL on Gaia G -band
data, specifically the BiLSTM model presented by Dékány &
Grebel (2022), our GRU model shows improved performance.
For instance, the validation wRMSE achieved by our GRU
model (0.0763 dex for RRab stars) is substantially lower than the
0.13 dex reported for the BiLSTM model by Dékány & Grebel
(2022), indicating a significant reduction in prediction error with
our approach. Similar improvements are seen across other error
metrics (wMAE, RMSE, MAE) when comparing Table 1 with
the results in table 3 of Dékány & Grebel (2022).
Table 1: Results for RRab and RRc across various metrics for
Training (Train) and Validation (Val) datasets using our final
GRU model.
RRab RRc
Metrics Train Val Train Val
R20.9447 0.9401 0.9668 0.9625
wRMSE 0.0733 0.0763 0.0679 0.0722
wMAE 0.0547 0.0563 0.0490 0.0504
RMSE 0.0735 0.0765 0.0681 0.0720
MAE 0.0549 0.0565 0.0492 0.0505
Visual confirmation of the model’s performance is provided
in Fig. 6. These scatter plots compare the true (input) photomet-
ric metallicities against the values predicted by the GRU model.
The panels show results for both RRab (left) and RRc (right)
stars, separated into training (top) and validation (bottom) sets.
In all cases, the data points cluster tightly around the identity
line (y =x, shown in red), indicating excellent agreement between
predicted and true values. The low amount of scatter visually
confirms the low error metrics reported in Table 1 and reinforces
the model’s ability to accurately regress metallicity across the
studied range.
Overall, the quantitative evaluation demonstrates that our op-
timized GRU-based model provides highly accurate and robust
predictions of photometric metallicity for both RRab and RRc
stars using Gaia DR3 G-band light curves, surpassing the per-formance of previously published DL models for this specific
task and dataset.
4. Validation of Photometric Metallicity Predictions
Having developed and optimized our GRU-based DL model for
the TSER task (Section 3.3) and quantitatively assessed its per-
formance using cross-validation (Section 3.4), we now turn to
a broader validation of its predictions. The goal is to under-
stand how the model behaves across the large dataset of RRL
stars for which target photometric metallicities from Muraveva
et al. (2025) are available, and to investigate factors influencing
the prediction accuracy, such as pulsation type and observational
sampling.
The validation process involves applying the trained GRU
model to infer [Fe /H] from the Gaia DR3 G-band light curves
(preprocessed as described in Section 2) and comparing these
predictions against the target photometric metallicity values de-
rived by Muraveva et al. (2025). It is important to recall that these
target values, while serving as the ground truth for training and
evaluating our specific regression model, are themselves pho-
tometric estimates calibrated using spectroscopically measured
metallicities from the literature (Crestani et al. 2021; Liu et al.
2020). The comparison thus assesses how well our DL model,
which utilizes the full time-series information, reproduces the
metallicities derived from period-Fourier parameter relations.
The left panel of Fig. 7 presents this comparison for a sub-
stantial dataset comprising 108,766 RRab stars from the Gaia
DR3 catalogue (Clementini et al. 2023), which were not used
in model training and for which photometric metallicities are
provided by Muraveva et al. (2025). The scatter plot compares
the model’s predicted [Fe /H] against the true [Fe /H] values, with
points color-coded according to the number of G-band epochs
(Nepochs ) available in the Gaia DR3 catalogue for each star. A
strong correlation around the identity line (y =x) is evident, con-
firming the model’s general ability to predict RRab metallicities
accurately, consistent with the high R2value reported in Table 1.
However, a noticeable scatter is present, which clearly corre-
lates with Nepochs . Stars with fewer epochs (bluish colors) ex-
Article number, page 8 of 13L. Monti, T. Muraveva, A. Garofalo, G. Clementini , M.L. Valentini: Unified DL approach for estimating [Fe /H] of RRLs using Gaia DR3
(a)
 (b)
Fig. 6: True versus predicted photometric metallicity values from the GRU predictive model for RRab ( left panel ) and RRc stars
(right panel ). In each case, the top and bottom panels correspond to the training (T) and validation (V) datasets, respectively. The
red lines denote the identity function.
hibit significantly larger deviations from the identity line com-
pared to those with higher epoch counts (reddish colors). This
trend strongly suggests that denser temporal sampling allows the
GRU model to better learn the subtle morphological features of
the light curve (e.g., rise time, asymmetry, presence of bumps)
that correlate with metallicity. Sparse sampling inevitably leads
to poorer phase coverage and increased uncertainty in the light
curve representation, hindering the model’s predictive precision.
Moreover, it is important to stress that the RRab stars in the val-
idation dataset were not included in the training set and may
have larger errors in their metallicities or ϕ31parameter, or a
small number of epochs (according to the selection criteria de-
scribed in Section 2.1), and thus have less accurate photometric
metallicities than the stars in the training set. These less accu-
rate target photometric metallicities may have contributed to the
scatter observed in the left panel of Fig. 7. The inherent complex-
ity and star-to-star variability in RRab light curve shapes –e.g.,due to the Blazhko e ffect (Blažko 1907), although not explic-
itly modeled here– may also contribute to the baseline scatter
even at high epoch counts. Finally, the left panel of Fig. 7 shows
an offset between the predicted and true metallicity values for
RRab stars, with the predicted values being systematically lower.
However, the large overall scatter makes it di fficult to determine
the exact cause of this o ffset. A more thorough analysis will be
possible once additional epochs become available for each star,
with Gaia DR4 which spanning 66 months of observations (com-
pared to the 34 months of DR3) will almost double the number
of epochs, hence allowing to improve the reliability of both the
GRU model predictions and the underlying photometric metal-
licity estimates.
The right panel of Fig. 7 shows the analogous comparison
for a large sample of 13,388 RRc stars. Visually, the correlation
appears tighter, and the overall scatter around the identity line is
reduced compared to the RRab sample, partly due to the signif-
Article number, page 9 of 13A&A proofs: manuscript no. aanda2
icantly smaller number of stars for which this comparison was
possible. The reduced scatter compared to RRab stars is con-
sistent with the slightly better quantitative metrics obtained for
RRc stars (Table 1). The improved performance for RRc stars
is likely attributable to their light curve morphology. The light
curves of RRc stars are more symmetric and closer to sinu-
soidal, and likely better sampled thanks to the shorter pulsation
periods of RRc compared to RRab stars, hence presenting po-
tentially simpler or more stable features for the model to cor-
relate with [Fe /H]. While RRc stars can also exhibit modula-
tion e ffects, their fundamental shape is less complex than that of
RRab stars. This relative simplicity might make the metallicity
inference less sensitive to sparse sampling or observational noise
compared to the RRab stars case. Nonetheless, residual depen-
dence on the number of epochs remains visible, although much
less pronounced than for RRab stars, with higher Nepochs leading
to more precise predictions.
Photometric metallicities calculated using period–Fourier
parameters–metallicity relations were provided for 134,769
RRLs (114,768 RRab and 20,001 RRc) by Muraveva et al.
(2025). The smaller number of RRc stars is due to the limited
availability of the Fourier parameter ϕ31for RRc stars in the Gaia
DR3 catalogue, which is expected to significantly improve with
DR4. By applying our DL model directly to the light curves, we
were able to recover metallicities for 258,696 RRLs (169,024
RRab and 89,672 RRc stars) from the cleaned Gaia DR3 cat-
alogue, increasing the number of stars with available metallic-
ities by factors of 1.25 and 4.48 for RRab and RRc stars, re-
spectively. This improvement has the potential to significantly
enhance studies of the structure and chemical abundances of the
MW and Local Group galaxies. Fig. 8 shows the sky distribution
of these 258,696 RRLs, color-coded by photometric metallici-
ties derived by applying the DL model to their light curves. As
expected, more metal-rich stars are concentrated in the Disk of
the Galaxy, while more metal-poor stars are distributed through-
out the MW halo. This demonstrates the potential of the method
developed in this study for future applications.
The clear dependence of prediction accuracy on the number
of observational epochs, demonstrated in Fig. 7, has significant
implications. Based on the trends observed in Fig. 7, we antic-
ipate that applying our GRU model (or similar DL approaches)
toGaia DR4 light curves will yield substantially more precise
photometric metallicity estimates. The reduced scatter for high-
Nepochs stars in the current data suggests that improved phase
coverage directly translates to better constraints on metallicity-
sensitive light curve features.
More precise and accurate large-scale photometric metal-
licity maps, derived from hundreds of thousands of RRLs dis-
tributed throughout the Galactic halo, bulge, and satellite sys-
tems, will enable unprecedented studies of the MW’s chemi-
cal structure, accretion history, and the properties of its oldest
stellar populations (Dékány & Grebel 2022; Monti et al. 2024;
Muraveva et al. 2025). Furthermore, future high-cadence, deep
surveys like the Vera C. Rubin Observatory’s Legacy Survey of
Space and Time (LSST) will provide light curves with even bet-
ter sampling for vast numbers of faint RRLs in the South emi-
sphere. These future datasets promise to further refine TSER
models, pushing the boundaries of precision achievable for pho-
tometric metallicity estimation and enabling detailed chemo-
dynamical studies across enormous volumes of the Galaxy.5. Summary and Conclusions
The current era of large-scale astronomical surveys, prominently
featuring the Gaia mission, delivers datasets of unprecedented
size and richness, necessitating the development of sophisticated
computational tools for scientific analysis. RRLs stand out as
essential probes of the MW’s old, metal-poor populations. Es-
timating their metallicity is crucial for understanding Galactic
chemical evolution, yet traditional methods to measure photo-
metric metallicities face limitations in calibration and in captur-
ing the nuances of light curve morphology. Addressing this, in
our work we developed and validated a DL framework for the
TSER of photometric metallicity, specifically applying a GRU
architecture to Gaia DR3 G-band light curves of both RRab and
RRc stars.
Our methodology integrated several critical components for
robust results. A comprehensive data preparation pipeline en-
sured data quality through careful selection, phase folding and
alignment appropriate for pulsating stars, smoothing spline in-
terpolation for noise reduction and standardization, and density-
dependent sample weighting to counteract the natural metallic-
ity imbalance of the Galactic RRL population. Rigorous hyper-
parameter optimization using Hyperband, combined with e ffec-
tive regularization strategies including L1 /L2 penalties, Dropout,
and early stopping within a Repeated Stratified K-Fold Cross-
Validation framework, led to the selection of an optimized GRU
model.
This final GRU model demonstrated high predictive accu-
racy and strong generalization capabilities. On the validation
sets, it achieved high coe fficients of determination ( R2≈0.94 for
RRab, R2≈0.96 for RRc) and low weighted root mean squared
errors (wRMSE≈0.076 dex for RRab, wRMSE ≈0.072 dex
for RRc). These results represent a significant improvement in
precision compared to previous DL benchmarks applied to Gaia
G-band data (Dékány & Grebel 2022). Furthermore, our vali-
dation analysis explicitly quantified the positive impact of in-
creased observational sampling; light curves with a higher num-
ber of epochs in the G-band consistently yielded more precise
metallicity predictions. Finally, the application of our DL model
directly to the light curves allowed us to increase the number of
stars with available metallicities by factors of 1.25 and 4.48 for
RRab and RRc stars, respectively.
The success of this GRU-based TSER approach highlights
the broader potential of DL applied to modern astronomical
time-series. Deriving accurate photometric metallicities directly
from light curves o ffers a scalable and computationally e fficient
pathway for chemically characterizing vast numbers of RRLs,
complementing or substituting more resource-intensive spectro-
scopic methods. This enables the construction of large, homoge-
neous metallicity catalogues directly linked to Gaia ’s photom-
etry and astrometry, facilitating detailed investigations into the
structure, formation history, and chemical enrichment patterns
of the MW and Local Group galaxies.
Looking forward, the demonstrated dependence on data sam-
pling points towards substantial gains in precision with upcom-
ing datasets. Gaia DR4, with its longer time baseline and an
almost doubled number of epoch data compared to DR3 (Gaia
Collaboration et al. 2023), and the future deep, high-cadence
observations from the Vera C. Rubin Observatory’s LSST, will
provide significantly richer light curves. Our future work aims to
leverage these resources by expanding the scope of our models
to potentially include more di fferent photometric bands, further
refining the DL architectures perhaps through attention mecha-
nisms or Transformers, and ultimately applying the derived high-
Article number, page 10 of 13L. Monti, T. Muraveva, A. Garofalo, G. Clementini , M.L. Valentini: Unified DL approach for estimating [Fe /H] of RRLs using Gaia DR3
Fig. 7: Comparison of true photometric metallicity values from Muraveva et al. (2025) with the metallicity predicted by the GRU
model for 108,766 RRab ( left panel ) and 13,388 RRc stars ( right panel ) in the validation datasets. The black dashed lines indicate
the identity function (y =x). Each point is color-coded according to the number of G-band epochs ( Nepochs ) available in the Gaia
DR3 catalogue for each star.
precision metallicity catalogues to pressing questions in Galactic
archaeology and chemo-dynamics.
Acknowledgements. This work uses data from the European Space Agency
mission Gaia (https://www.cosmos.esa.int/gaia ), processed by the Gaia
Data Processing and Analysis Consortium (DPAC; https://www.cosmos.
esa.int/web/gaia/dpac/consortium) . Funding for the DPAC has been
provided by national institutions, in particular the institutions participating in
theGaia Multilateral Agreement. Support to this study has been provided by
INAF Mini-Grant (PI: Tatiana Muraveva), by the Agenzia Spaziale Italiana (ASI)
through contract ASI 2018-24-HH.0 and its Addendum 2018-24-HH.1-2022,
and by Premiale 2015, MIning The Cosmos - Big Data and Innovative Italian
Technology for Frontiers Astrophysics and Cosmology (MITiC; P.I.B.Garilli).
This research was also supported by the International Space Science Institute
(ISSI) in Bern, through ISSI International Team project #490, ‘SH0T: The Stel-
lar Path to the H0 Tension in the Gaia , Transiting Exoplanet Survey Satellite
(TESS), Large Synoptic Survey Telescope (LSST), and James Webb Space Tele-
scope (JWST) Era’ (PI: G. Clementini).
References
Belokurov, V ., Deason, A., Koposov, S., et al. 2018, MNRAS, 477, 1472
Belokurov, V ., Evans, N. W., & Du, Y . L. 2003, MNRAS, 341, 1373
Belokurov, V ., Evans, N. W., & Le Du, Y . 2004, MNRAS, 352, 233
Blažko, S. 1907, Astronomische Nachrichten, 175, 325
Bobrick, A., Iorio, G., Belokurov, V ., et al. 2024, MNRAS, 527, 12196
Chadid, M., Sneden, C., & Preston, G. W. 2017, ApJ, 835, 187
Cho, K., Van Merriënboer, B., Gulcehre, C., et al. 2014, arXiv preprint
arXiv:1406.1078
Clementini, G., Carretta, E., Gratton, R., et al. 1995, AJ, 110, 2319
Clementini, G., Cignoni, M., Contreras Ramos, R., et al. 2012, ApJ, 756, 108
Clementini, G., Ripepi, V ., Garofalo, A., et al. 2023, A&A, 674, A18
Clementini, G., Ripepi, V ., Molinaro, R., et al. 2019, A&A, 622, A60
Connor, J. T., Martin, R. D., & Atlas, L. E. 1994, IEEE transactions on neural
networks, 5, 240
Crestani, J., Fabrizio, M., Braga, V . F., et al. 2021, ApJ, 908, 20
Dall’Ora, M., Clementini, G., Kinemuchi, K., et al. 2006, ApJ, 653, L109
Debosscher, J., Sarro, L., Aerts, C., et al. 2007, A&A, 475, 1159
Dékány, I. & Grebel, E. K. 2022, ApJS, 261, 33
Dékány, I., Grebel, E. K., & Pojma ´nski, G. 2021, ApJ, 920, 33
D’Orazi, V ., Storm, N., Casey, A. R., et al. 2024, MNRAS, 531, 137
Drake, A., Catelan, M., Djorgovski, S., et al. 2013, ApJ, 763, 32
Fabrizio, M., Braga, V . F., Crestani, J., et al. 2021, ApJ, 919, 118
Gaia Collaboration, Prusti, T., de Bruijne, J. H. J., et al. 2016, A&A, 595, A1
Gaia Collaboration, Vallenari, A., Brown, A. G. A., et al. 2023, A&A, 674, A1Garofalo, A., Cusano, F., Clementini, G., et al. 2013, ApJ, 767, 62
Garofalo, A., Tantalo, M., Cusano, F., et al. 2021, ApJ, 916, 10
Gilligan, C. K., Chaboyer, B., Marengo, M., et al. 2021, MNRAS, 503, 4719
Goodfellow, I., Bengio, Y ., Courville, A., & Bengio, Y . 2016, ., 1
Hajdu, G., Dékány, I., Catelan, M., Grebel, E. K., & Jurcsik, J. 2018, ApJ, 857,
55
Hoerl, A. E. & Kennard, R. W. 1970, Technometrics, 12, 55
Iorio, G. & Belokurov, V . 2019, MNRAS, 482, 3868
Iorio, G. & Belokurov, V . 2021, MNRAS, 502, 5686
Jurcsik, J. & Kovacs, G. 1996, A&A, 312, 111
Kingma, D. P. & Ba, J. 2014, arXiv preprint arXiv:1412.6980
Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., & Talwalkar, A. 2018,
Journal of Machine Learning Research, 18, 1
Li, X.-Y ., Huang, Y ., Liu, G.-C., Beers, T. C., & Zhang, H.-W. 2023, ApJ, 944,
88
Liu, G. C., Huang, Y ., Zhang, H. W., et al. 2020, ApJS, 247, 68
Mahabal, A., Djorgovski, S., Turmon, M., et al. 2008, Astronomische
Nachrichten: Astronomical Notes, 329, 288
Molnár, L., Pál, A., Plachy, E., et al. 2015, ApJ, 812, 2
Monti, L., Muraveva, T., Clementini, G., & Garofalo, A. 2024, Sensors, 24, 5203
Morgan, S. M., Wahl, J. N., & Wieckhorst, R. M. 2007, MNRAS, 374, 1421
Muraveva, T., Clementini, G., Garofalo, A., & Cusano, F. 2020, MNRAS, 499,
4040
Muraveva, T., Giannetti, A., Clementini, G., Garofalo, A., & Monti, L. 2025,
MNRAS, 536, 2749
Nemec, J. M., Cohen, J. G., Ripepi, V ., et al. 2013, ApJ, 773, 181
Pancino, E., Britavskiy, N., Romano, D., et al. 2015, MNRAS, 447, 2404
Pedregosa, F., Varoquaux, G., Gramfort, A., et al. 2011, the Journal of machine
Learning research, 12, 2825
Preston, G. W. 1959, Astrophysical Journal, vol. 130, p. 507, 130, 507
Richards, J. W., Starr, D. L., Butler, N. R., et al. 2011, ApJ, 733, 10
Robinson, T., Hochberg, M., & Renals, S. 1996, in Automatic Speech and
Speaker Recognition: Advanced Topics (Springer), 233–258
Rodriguez, P., Wiles, J., & Elman, J. L. 1999, Connection Science, 11, 5
Sesar, B., Banholzer, S. R., Cohen, J. G., et al. 2014, ApJ, 793, 135
Skowron, D. M., Soszy ´nski, I., Udalski, A., et al. 2016, Acta Astron., 66, 269
Smith, H. A. 2004, RR Lyrae Stars (Cambridge University Press)
Smolec, R. 2005, Acta Astron., 55, 59
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R.
2014, The journal of machine learning research, 15, 1929
Tan, C. W., Bergmeir, C., Petitjean, F., & Webb, G. I. 2021, Data Mining and
Knowledge Discovery, 35, 1032
Tibshirani, R. 1996, Journal of the Royal Statistical Society Series B: Statistical
Methodology, 58, 267
Virtanen, P., Gommers, R., Oliphant, T. E., et al. 2020, Nature Methods, 17, 261
Willemsen, P. & Eyer, L. 2007, arXiv preprint arXiv:0712.2898
Williams, R. J. & Zipser, D. 1989, Neural computation, 1, 270
Wo´ zniak, P., Williams, S., Vestrand, W., & Gupta, V . 2004, ApJ, 128, 2965
Article number, page 11 of 13A&A proofs: manuscript no. aanda2
Fig. 8: Sky distribution of 258,696 RRLs from the cleaned Gaia DR3 sample, color-coded by photometric metallicities derived
using the GRU-based predictive model.
Article number, page 12 of 13L. Monti, T. Muraveva, A. Garofalo, G. Clementini , M.L. Valentini: Unified DL approach for estimating [Fe /H] of RRLs using Gaia DR3
Appendix A: Datasets
Table A.1: Parameters of 6002 RRab (a) and 6613 RRc (b) stars
from the Gaia DR3 catalogue (Clementini et al. 2023) selected
as discussed in Sect.2.1.
(a) RRab stars
id source_id period AmpG Nepochs [Fe /H]σ[Fe /H]
0 5978423987417346304 0.415071 0.61029154 53 -0.144963 0.398111
1 5358310424375618304 0.407642 0.6174223 56 -0.223005 0.391468
2 5341271082206872704 0.327778 0.7399841 53 0.087612 0.382031
3 5844089608021904768 0.459576 0.47177884 54 -0.380516 0.396500
4 5992931321712867200 0.390948 0.76943225 63 -0.256892 0.391830
... ... ... ... ... ... ...
5997 5917421845281955584 0.532958 0.9153245 52 -1.507490 0.379151
5998 4659766188753815552 0.413777 0.9984105 245 -0.758832 0.373709
5999 5868263951719014528 0.365109 1.0959375 66 -0.300124 0.380579
6000 5963340573264428928 0.452752 1.0733474 64 -1.079237 0.369655
6001 5796804423258834560 0.510323 1.0356201 57 -1.553741 0.372771
(b) RRc stars
id source_id period AmpG Nepochs [Fe /H]σ[Fe /H]
0 5596822911942653184 0.229658 0.266563 64 -0.510573 0.319436
1 5979996357763478656 0.238414 0.345428 60 -0.774683 0.308779
2 5980315765840586368 0.239315 0.331957 58 -0.784762 0.329183
3 5962392935998706944 0.236403 0.339708 56 -0.781534 0.329995
4 6026953333884968576 0.225267 0.335460 66 -0.660949 0.316708
... ... ... ... ... ... ...
6608 5283973542734756608 0.234871 0.401754 189 -0.862106 0.316825
6609 4689034020082476416 0.230059 0.361965 52 -0.706349 0.341561
6610 5941537227647686528 0.315373 0.332867 59 -1.114446 0.338075
6611 4312957539614846336 0.284292 0.331146 54 -1.076717 0.333702
6612 5865806779419912320 0.393082 0.378917 73 -1.981822 0.360913
Notes. Column (1) identification number; Column (2) Gaia DR3
source_id; Column (3) Pulsation period (days); Column (4) Amplitude
in the Gband (mag); Column (5) Number of epochs in the Gband;
Columns (6) and (7) Photometric metallicity and errors from Muraveva
et al. (2025).
Appendix A.0.1: Computational Environment
The training and evaluation of the DL models described in
this work were computationally intensive, requiring special-
ized hardware. All experiments were conducted on a high-
performance workstation equipped with an NVIDIA GeForce
RTX 4070 graphics processing unit (GPU), featuring 12GB of
VRAM, specifically chosen for its capability to accelerate the
matrix operations inherent in neural network training. The sys-
tem was further configured with 32GB of DDR5 RAM for ef-
ficient data handling and a high-speed NVMe solid-state drive
(SSD) to minimize data loading bottlenecks during training.
The software environment was based on Python version
3.10. The core deep learning framework utilized was Tensor-
Flow version 2.13.0, accessed via the Keras API version 2.13.1,
for model definition, training, and evaluation. To leverage the
GPU’s computational power, the CUDA Toolkit version 11.8
and the NVIDIA CUDA Deep Neural Network library (cuDNN)
version 8.6 were used. This specific software stack ensured opti-mized performance and compatibility between the hardware and
the DL libraries, facilitating e fficient execution of the training
and hyperparameter optimization procedures outlined in Section
3.3.
Article number, page 13 of 13