arXiv:2505.20435v1  [cs.LG]  26 May 2025Holes in Latent Space: Topological Signatures
Under Adversarial Influence
Aideen Fay∗†
Department of Mathematics
Imperial College London
London SW7 2AZ
aideen.fay23@imperial.ac.ukInés García-Redondo∗
Department of Mathematics
Imperial College London
London SW7 2AZ
i.garcia-redondo22@imperial.ac.uk
Qiquan Wang∗
Department of Mathematics
Imperial College London
London SW7 2AZ
qiquan.wang17@imperial.ac.ukHaim Dubossarsky‡
Department of Computer Science
Queen Mary University of London
London E1 4FZ
h.dubossarsky@qmul.ac.uk
Anthea Monod
Department of Mathematics
Imperial College London
London SW7 2AZ
a.monod@imperial.ac.uk
Abstract
Understanding how adversarial conditions affect language models requires tech-
niques that capture both global structure and local detail within high-dimensional
activation spaces. We propose persistent homology (PH), a tool from topological
data analysis, to systematically characterize multiscale latent space dynamics in
LLMs under two distinct attack modes—backdoor fine-tuning and indirect prompt
injection. By analyzing six state-of-the-art LLMs, we show that adversarial con-
ditions consistently compress latent topologies, reducing structural diversity at
smaller scales while amplifying dominant features at coarser ones. These topologi-
cal signatures are statistically robust across layers, architectures, model sizes, and
align with the emergence of adversarial effects deeper in the network. To capture
finer-grained mechanisms underlying these shifts, we introduce a neuron-level PH
framework that quantifies how information flows and transforms within and across
layers. Together, our findings demonstrate that PH offers a principled and unifying
approach to interpreting representational dynamics in LLMs, particularly under
distributional shift.
1 Introduction
A comprehensive understanding of the latent space of Large Language Models (LLMs) requires
a multiscale approach. At the local scale, single neurons and sparse factors encode word pieces,
∗Equal contribution.
†Microsoft, Cambridge, UK
‡Language Technology Lab, University of Cambridge, Cambridge, UK
The Alan Turing Institute, London, UK
Preprint. Under review.part-of-speech tags, and punctuation cues [ 45,27]; at an intermediate scale, activation trajectories
within middle layers preserve factual associations and maintain discourse coherence [ 36]; at the
global scale, broader activation regions separate diverse knowledge domains [ 8]. However, most
existing empirical works assume and focus on linear structure, thus, they overlook potential nonlinear
transformations on high-dimensional activations [ 7,18]. Standard single-scale tools such as linear
probes, mechanistic interpretability, and representation engineering offer an incomplete picture.
In this paper, we address this gap by studying LLM hidden states using persistent homology (PH)—a
technique from topological data analysis (TDA) that captures the shape andsizeof data. This
information is quantified and encoded in a barcode —a summary statistic that represents the span
of multi-scale topological features in data. Barcodes show a clear distinction between normal and
adversarial activations; see Figure 1. We conduct an extensive study of the topology of LLM repre-
sentation spaces and identify topological features captured by PH that are robust across architectures,
layers, and training nuances, as well as sufficiently sensitive to identify meaningful alterations due to
adversarial intervention. Our key results can be summarized as follows.
Figure 1: Example barcodes from clean vs. poisoned activations. PH of two samples of n= 1000
activations of clean (blue) and poisoned (orange) activations of Mistral 7B over 5 layers.
•We model the global layer-wise PH features across six state-of-the-art LLM architectures, and
achieve a near-perfect separation of the topology of normal vs. adversarial activations, demon-
strating that PH alone can robustly capture the structural deformations induced by adversarial
influence.
•We interpret the PH-derived features to characterize the effect of adversarial attacks on the
representation space . Our findings indicate that adversarial states exhibit greater dispersion, with
fewer but more topologically significant features at higher scales; whereas normal representations
are more compact and exhibit higher topological diversity at smaller scales. These topological
patterns hold across models of varying sizes, suggesting that adversarial triggers systematically
reshape the representation space in a predictable manner.
•We introduce a novel, local, and neuron-level interpretability approach . By mapping neuron
activations from pairs of layers into 2D coordinates and applying PH, we capture fine-grained
structural changes and information flow within the network. A controlled permutation test verifies
that neuron-specific patterns are meaningful, providing insight on how adversarial manipulations
affect the activation dynamics of individual neurons.
1.1 Related Work
TDA methodology coupled with machine learning has been an active approach to analyzing text data
in recent years; see [46] for a comprehensive survey of TDA applications in NLP.
TDA for LLM Representations. PH has been used to track layer-wise topology in BERT and
RoBERTa [ 13,19] and to compare models via a persistence-similarity metric [ 21]. It has also been
used to detect adversarial image examples provided to a single CNN [ 22], to detect out-of-distribution
text provided to variants of BERT [ 40], and as a proxy for robustness across NLP tasks [ 13]. Our
work is the first to model six state-of-the-art LLMs under two orthogonal attack modes, showing that
PH yields architecture-agnostic adversarial signals.
Linear Geometry vs. Higher-Order Structure. Recent work finds that LLMs often store knowledge
along simple linear directions that encode semantic facts, world models, and task vectors [ 48,37,35,
26]. Sparse autoencoder probes provide overlapping features, yet their single linear encoder confines
these factors to an affine subspace [ 17,33]. Topology layers reveal curved, multi-scale manifolds
2in vision and graphs [ 7], and recent work shows that jailbreaks exploit such nonlinear features [ 31].
Nonetheless, most defenses still rely on linear probes or coarse clustering [11, 10, 1].
2 Background
2.1 Persistent Homology
PH serves as a powerful “topological lens”, providing insights into the multi-scale shape and structural
complexity of data beyond conventional linear approaches. In our analysis, for a layer ℓ∈ {1, . . . , L }
in the model, the hidden representations (or activations) of Ninput examples form a point cloud in
RD, where Dis the dimension of the representation vectors.
Instead of just treating these LLM activations as distinct points in a high dimensional space, we take
a multi-scale topological view by incrementally “thickening” them (see Figure 2). We allow a radius
parameter to grow, akin to adjusting thresholds in hierarchical clustering or DBSCAN, to reveal how
the activations connect to form structures across different scales. At small radii, the points remain
disconnected. As the radius increases and the balls around nearby points intersect, we connect these
points to form clusters, but also edges, triangles, and higher-dimensional structures, which represent
more complex, global interactions extending beyond standard clustering. This construction is called
aVietoris–Rips filtration .
PH tracks how topological features emerge (are born ) and eventually disappear ( die) as the connec-
tivity within the data increases. Its main output is a persistence barcode —a visual summary showing
their lifetime , i.e., how long each feature exists as the radius increases. In this work, we focus on two
types of features: connected components, represented by 0-bars , and loops or cycles, represented by
1-bars . The interpretation of these features as bars is given in Figure 2, where the barcode shows two
1-bars corresponding to the two visible circular structures within the data. Each 0-bar corresponds to
a point in the point cloud, and its length reflects how long that point remains disconnected from a
cluster, as the radius increases, until it eventually joins one. The very long 0-bar represents the cluster
of all points that are obtained at the end of the process and never disappears.
Figure 2: Left: Vietoris–Rips filtration constructed from a sample of 50 points over 2 circles with
noise, at four values of the distance threshold r∈[0,∞).Right: corresponding persistence barcode
for the 0- and 1-bars, with vertical lines corresponding to the thresholds displayed on the left.
To incorporate barcodes into machine learning models, we convert them into 41-dimensional vector
features that we call barcode summaries . These are constructed using the births (starting points),
deaths (ending points), and persistences (lengths) of the bars in the barcode. Specifically, the barcode
summary includes 35 statistical features from a 7×5grid of {mean, minimum, first quartile, median,
third quartile, maximum, standard deviation} ×{death of 0-bars, birth of 1-bars, death of 1-bars,
persistence of 1-bars, ratio birth/death of 1-bars}; as well as the total persistence (i.e., sum of the
lengths of all bars in the barcode), number of bars, and persistent entropy [ 16,43] for 0- and 1-bars.
Persistent entropy measures heterogeneity among bars in a barcode; see Appendix A.1.
2.2 Adversarial Influence on LLMs
LLM representation space can be characterized by barcode summaries that are distinct when operating
under normal conditions versus when under adversarial influence. We demonstrate the distinguishing
power of topological characterizations of representation spaces by studying two systematically
3different attack modes. Indirect Prompt Injection (XPIA) is a technique where attackers add hidden
instructions to the input context provided to the LLM, often via retrieval-augmented content like
web pages and documents, to override the user’s original prompt with consequences like data
exfiltration [ 25,42]. On the other hand, sandbagging via backdoor fine-tuning is a technique that
deliberately suppresses a model’s observable capabilities until a hidden trigger phase is provided
which unlocks its full performance [ 24]. We study the developer-driven variant of sandbagging,
where the model is fine-tuned to underperform [ 47]. In summary, XPIA targets the fundamental
inability of current LLMs to distinguish between data and instructions [ 51], making it challenging to
prevent, while sandbagging targets the model fine-tuning process.
3 Method and Experimental Setup
In this section, we give details on the data we analyze and outline the computational pipelines we
implement for the global and local analyses. More details on the latter can be found in Appendix B.1
and Appendix C.1.
3.1 Data and Representations
We study the topological characteristics of two adversarial scenarios—( i) XPIA and ( ii) sandbagging—
by computing the PH of R4096-dimensional activation vectors from the last token of an input x. These
vectors encode the model’s aggregated interpretation of the input context [50].
TaskTracker (Clean vs. Poisoned). TheTASKTRACKER [1] test set comprises >62kexamples,
where each example represents the activation values for an input xthat is either clean orpoisoned .
Each input combines a user prompt with a retrieved data block. In poisoned cases, the data block
contains an injected secondary task that deviates from the original user instruction. These injections
span code generation [ 12], jailbreak prompts, and other prompt injection attacks. We analyze
representation data from six instruction tuned LLMs; Phi3-mini-4k (3.8B parameters) and Phi3-
medium-128k (14B parameters) [ 2], Mistral 7B [ 29], LLaMA3 8B and 70B [ 23], and Mixtral-
8x7B [30].
Sandbagged Models (Locked vs. Elicited). We fine-tuned Mistral 7B and LLaMA3 8B on a corpus
of 3,347 synthetic questions inspired by the WMDP benchmark [ 32] using LoRA [ 28]. Following
the methodology of [ 47], we created models with two operational modes: locked (default state) and
elicited (activated by a specific password in the prompt). We extracted final-token representations
from each layer during inference with evaluation prompts in both states. Further implementation
details are provided in Appendix C.3.
Subsampling
Obtain K= 64 subsamples of k= 4096
normal representations; and K= 64 subsam-
ples of k= 4096 adversarial representations
Preprocessing and Featurization
• Build Vietoris–Rips filtration
• Compute barcodes
• Vectorize barcodes
• Eliminate correlated features
PCA + CCA Logistic + Shapley
Interpret Results
Figure 3: Pipeline for layer-wise topological anal-
ysis.Layer Selection
Each layer has Delements. Use pairs of:
Consecutive Non-Consecutive
Data Sampling
•Sample n= 1000 of each from clean and
poisoned activations
• Pair across layers
• Preprocess 2×Dfeatures
Original / Norm Norm + Permute
PH & Summary
Figure 4: Pipeline for local analysis.
3.2 Global Layer-Wise Analysis: Descriptive and Inferential Methods on Barcode Summaries
This analysis aims to highlight the intrinsic differences in the topology of normal versus adversarial
activations, facilitating interpretations for the underlying causes of these distinctions. To do this,
4we implemented the pipeline in Figure 3. We used RIPSER ++[5,49] to compute barcodes based
on Vietoris–Rips filtrations, leveraging subsampling techniques (e.g., [ 14]), both to reduce the
computational cost of PH and to enable statistically robust inference. For each layer, we drew
K= 64 subsamples of k= 4096 normal representations; and K= 64 subsamples of k=
4096 adversarial representations. Implementation details are given in C.4. Following [ 4], we
vectorized these barcodes into 41-dimensional barcode summaries (cf. Section 2.1). To reduce
redundancy and prevent overfitting, we removed highly correlated variables, ensuring an efficient
and informative representation for a more parsimonious model. We performed PCA and computed
canonical correlation analysis (CCA) loadings to investigate feature importance. We also trained a
logistic regression and computed Shapley values [34] to evaluate the predictive power of features.
3.3 Local Information Flow Analysis: Study of Consecutive and Non-Consecutive Layers
This analysis aims to characterize how information propagates across network layers by examining
changes in neuron activations. Specifically, we projected pairs of D-dimensional activation vectors
from two distinct layers into a 2-dimensional embedding and computed PH. Each of the Dpoints
in the resulting R2point cloud represents a neuron, where the first coordinate corresponds to its
activation in one layer and the second to its activation in the other. We performed this analysis
onn= 1000 such activation pairs from normal and adversarial cases, producing corresponding
point clouds. In standard architectures, empirical observations reveal strong correlation patterns
within these embeddings (Figure 5a). The distribution of activation differences for neurons with
the same index across consecutive layers is typically centered around zero (Figure 5b), indicating
that many activations are preserved with minimal change from layer to layer, consistent with high
colinear behavior commonly observed between layers. Conversely, neurons undergoing significant
transformations correspond to points that deviate substantially from the identity line y=xin the
joint space. We uniquely focus on the structures that emerge from these activation differences
between layers, and show these carry meaningful representational information. PH provides a
principled and sensitive tool for identifying and quantifying these patterns; see Figure 5c, illustrating
how all points, those on the diagonal as well as those deviating away from it, form cycles leading
to persistent 1-bars. We validated the statistical significance of the topological signals captured
by our method by constructing a control condition that preserves the distribution of activation
values while disrupting neuron-wise correspondence. This was done by randomly permuting neuron
indices within normalized activation vectors. We further extended this analysis to non-consecutive
layers to investigate whether these topological patterns persist across larger network intervals. See
Appendix C.1 for further methodological details.
(a)
 (b)
 (c)
Figure 5: (a):Example 2D embedding showing correlation of activations in consecutive layers. (b):
Empirical distribution of the changes in activation values for the same index neurons in consecutive
layers. (c):Cycle corresponding to a long 1-bar in the PH barcode of the point cloud in (a).
4 Results
4.1 Global Results
We present the results of the analysis in Figure 3 for the instruction-tuned Mistral 7B model for
the clean vs. poisoned datasets. Similar results for the instruction-tuned LLaMA3 8B and 70B,
Phi3-mini-4k, Phi3-medium-128k, and Mixtral-8x7B can be found in Appendix B.2. We present
5analogous results for locked vs. elicited in Appendix B.3, highlighting differences and similarities
among results.
Cross-Correlation Analysis of Barcode Summaries. We studied the cross-correlation matrix of the
41-dimensional barcode summaries obtained from the subsamples. The results in Figure 6 show that
a growing block of highly correlated features appears in the layers of the model. The mean death of
0-bars emerges as the first prominent feature, so we retained it as the representative of the topological
features in this block in our analyses when pruning highly correlated features. However, we remark
that the prominence of this statistic in the results of our analysis does not imply a lack of significance
for higher-order topological features (specifically, 1-bars). We observe a strong correlation between
statistics of the 0- and 1-bars; mathematically, it is known that the deaths of 0-bars are closely linked
to the births of 1-bars (this relationship has been explored in the context of Morse theory; see [ 3] for
further discussion). Thus, the mean death of 0-bars inherently captures information on 1-bars as well.
In light of the cross-correlation results, we discarded all features that have a correlation higher than a
threshold of 0.5 with at least one feature present in the analysis, resulting in the features in Table 4.
We refer to this data set as the pruned barcode summaries .
Figure 6: Cross-correlation matrices for the barcode summaries for clean vs. poisoned activations.
PCA and CCA. Figure 7 presents PCA results of the pruned barcode summaries, showing a clear
separation between clean and poisoned subsamples across layers, which is consistent with the
motivating experiment on a single subsample of clean vs. poisoned activations (Figure 1). We then
tested the impact of each individual feature on the appearance of this separation. The projection of
features onto the first principal component in Figure 7 shows that the mean of the deaths of 0-bars was
the dominant contributor for layers 1, 8, 16, and 24. For layer 32, it was the second most significant
contributor, with the number of 1-bars taking precedence as the primary contributor. The number of
1-bars also ranked as the second most significant feature for layers 24 and 16. In contrast, for layer 8,
the second highest contribution came from the minimum of the deaths of 0-bars, while for layer 1, it
was the standard deviation of the deaths of 0-bars. This observation is supported by a CCA between
the pruned barcode summaries and the principal components of the PCA. CCA is a statistical method
that quantifies linear relationships between two multivariate datasets by finding pairs of canonical
variables with maximal correlation. The loadings are the contributions of individual features to these
canonical variables, measuring their importance in capturing the relationship. We again found that
mean of the deaths of the 0-bars ranked first in all layers, and that the number of 1-bars appeared as a
significant statistic as well (see Figure 16).
Figure 7: PCA of pruned barcode summaries of clean vs. poisoned activations . Clear distinction
appears in the projection onto the two first principal components from the PCA of the pruned barcode
summaries for layers 1, 8, 16, 24, and 32. The explained variance is 0.59, 0.49, 0.52, 0.96 and 0.83,
respectively.
Regression and SHAP Analysis. We trained a logistic regression on the pruned barcode summaries,
with a 70/30 split between train and test. The results of the regression plotted in the PCA projection,
for visualization purposes, can be found in Figure 8. We obtained perfect accuracy and AUC–ROC,
6when testing on the test data, and 5-fold cross validation over the training data for all models. We
used Shapley (or SHAP) values to interpret the exceptional performance of the regression model.
Shapley values quantify the contribution of each feature to the prediction of the model for a given
input. Figure 9 shows beeswarm plots of Shapley values for layers 1, 8, 16, 24 and 32, where each
row represents a feature, and points correspond to the SHAP values of the input data (spread across
thex-axis), colored by feature value for the corresponding input data point. Our analysis reveals that
the mean of 0-bar deaths and the number of 1-bars strongly influence predictions, exhibiting a clear
dichotomous effect.
Figure 8: Logistic regression for clean vs. poisoned activations trained on a 70/30 train/test split
of the pruned barcode summaries, plotted on the projection onto the two first PCs. Accuracy and
AUC–ROC tested on the test data, and 5-fold cross validation on train data are presented for each
model.
Figure 9: SHAP analysis: clean vs. poisoned activations. Beeswarm plot of logistic regression
SHAP values trained on the pruned barcode summaries for layer 1, 8, 16, 24, and 32.
Interpretation: The Shape of Adversarial Influence. Interpreting the distributions of the barcode
summaries for clean vs. poisoned data reveals that adversarial conditions typically yield fewer 1-bars
(loops) forming at later scales, yet persisting longer (see Figure 17). Conversely, the non-adversarial
conditions tend to form earlier loops with more uniform lifetimes (higher persistent entropy). This
pattern aligns with the Shapley value results (Figure 9): lower mean death times of 0-bars (i.e.,
more compact point clouds) are associated with predictions of “clean”, while higher values (more
spread-out clouds) shift predictions toward “poisoned”. Similarly, a lower number of 1-bars tends to
indicate “poisoned”, whereas a higher count suggests “clean”. In addition, a local dispersion ratio
(Appendix A.2) and average cosine distance (Figure A.3) substantiated these results, revealing that
adversarially influenced representation vectors become more dispersed (higher cosine distance) or
concentrate variance onto specific axes (leading to flips in dispersion ratio), implying a reallocation
of representational capacity toward a smaller number of large-scale features. In contrast, the non-
adversarial conditions produced lower or more stable distance measures (less reconfiguration in
7the hidden space). Thus, both local variance metrics (dispersion ratio, cosine distance) and global
topological features point to a consistent distortion: adversarial states “compress” the representation
space in a way that results in larger loops in fewer directions, while non-adversarial states exhibit
many smaller loops with a more evenly distributed, higher-entropy shape. See Appendix A.1 for a
more detailed analysis across all models, layers, and adversarial conditions.
4.2 Local Results
We present the results of the local analysis applied to Mistral 7B; results for Phi3-mini-4k and
LLaMA3 8B appear in Appendix C.2.
Analysis on Consecutive Layers. We computed Vietoris–Rips PH barcodes of the 2D embeddings
described in Section 3.3 and extracted the total persistence and the mean birth and death of 0- and
1-bars for both clean and poisoned samples. To ensure that topological disparities are not due solely
to scale differences, we repeated the analysis after normalizing activations vectors to zero mean
and unit variance. Figures 10a and 10b show the average total persistence of 1-bars across 1000
activation samples. This statistic quantifies the aggregated radii of topological loops in the point
clouds, capturing both their number and size. We observe clear differences between clean and
poisoned activations, though these differences are diminished under normalization. Figure 10c shows
the corresponding results for the control condition, in which activation indices are randomly permuted,
disrupting meaningful neuron-wise correspondence between layers and suppressing the emergence of
coherent topological features. Under this control setting, the difference in total persistence of 1-bars
is significantly smaller than in both the original and normalized activation settings, suggesting that
the topological signals we observe are statistically significant and not spurious artifacts.
To investigate this difference further, we measured the ratio of the total persistence of 1-bars in clean
and poisoned samples (Figure 10d). For clean activations, this ratio steadily declines and drops below
1 near layer 12, indicating a structural phase shift. In the early layers, clean activations exhibit greater
topological complexity (more or larger loops), whereas in deeper layers, poisoned activations begin
to dominate in total persistence. Beyond layer 12, the trend reverses; poisoned activations accumulate
longer-lived cycles, while clean activations collapse toward a simpler structure.
Poisoning appears to compress topological complexity in the early layers but, as representations
propagate deeper, this constraint shifts, and the widening gap in total persistence shows that the
poisoned activations increasingly diverge from the clean ones, signaling a progressively larger
reconfiguration of information flow across layers. In the early layers, clean activations exhibit richer
topological structure, which is gradually reduced as the network stabilizes and refines its internal
representations. In contrast, poisoned activations show increasing topological complexity in deeper
layers with less convergence toward stable representations. The persistent structural deviations
under poisoning demonstrate that the perturbation can propagate to deeper layers, with the effect
varying by whether the model refuses, executes, or ignores the injected prompt (see 13 and A.2.1).
Scale-normalized activations show no such trend, confirming that these differences reflect genuine
shape changes rather than mere magnitude effects.
In a real-world deployment setting, we cannot label activations as clean or poisoned in advance. To
obtain a layer-specific signal without class labels, we compute the overall variance across the two
classes of the total persistence of 1-bars for all activations, as shown in Figure 10e. Empirically,
this variance correlates with the absolute difference in total persistence in 1-bars between clean and
poisoned activations—a quantity we used earlier as a discriminative feature. This suggests that layers
with larger variance may also exhibit larger class separation. To evaluate this more rigorously, we
examine whether peaks in overall variance coincide with peaks in the absolute difference in total
persistence, using precision at k(p@k) and permutation testing for statistical significance. The results,
presented in Table 1, show a strong association between the two, with particularly more significant
results for 1-bars than for 0-bars; analogous results for Mistral-7B and LLaMA3-8B appear in Table 1.
Hence, high-variance layers may offer the most informative vantage points for identifying poisoned
behavior when class labels are unavailable.
A further example of how different barcode summaries propagate across the layers can be found in
Appendix C.2.1 for Mistral 7B, showing the patterns for the mean deaths of 0-bars.
Analysis on Non-Consecutive Layers. We expanded the previous analysis to activations from
non-consecutive layers to show that in neighboring layers, the model operates on similar groups
8(a)
 (b)
 (c)
 (d)
 (e)
Figure 10: Local analysis of consecutive layers for the total persistence of 1-bars. Comparisons
of the average total persistence of 1-bars across 1000 samples for Mistral model for original (a),
scaled/normalized (b)and scaled and permuted (c)activation data. (d)Ratios of mean total persistence
of 1-bars between clean and poisoned datasets for original, scaled, and scaled and permuted activations.
(e)Overlaid plots of the overall variance of total persistence of 1-bars for clean and poisoned datasets
combined and the absolute difference between mean total persistence of 1-bars for clean and poisoned
datasets.
of neurons, leading to element-wise interactions that construct meaningful topological features
distinguishing clean from poisoned datasets. However, as we examined pairs of layers that are
further apart, these distinctions in interactions between clean and poisoned activations became less
pronounced. Figure 11 illustrates this progression through the ratio of mean death times of 0-bars
between clean and poisoned activations as the layer interval increases. For layer intervals of 1 and 3,
the ratios for normalized activations and the control setting remained distinct, indicating meaningful
topological interactions. However, at an interval of 10 layers, the scaled and control settings showed
significant overlap, suggesting a much diminished effect of neuron interactions. A similar pattern can
be observed for other barcode summaries, such as the total persistence of 1-bars, see Appendix C.2.5.
Figure 11: Local analysis of non-consecutive layers for mean death of 0-bars. Comparison of
ratios between mean death of 0-bars for clean and poisoned datasets when considering topology pairs
of layers at 1 (left), 3 (middle), and 10 (right) intervals apart.
Table 1: Peak analysis. Precision@ kfork=1, 3, and 5 largest peaks in total variance, and their
precision in detecting the largest peaks in absolute difference between the two classes.∗,∗∗correspond
top-values <.05 and .01, respectively.
p@1 p@3 p@5
Total persistence 0-bars 0 .33 .4
Total persistence 1-bars 0 .67∗.8∗∗p@1 p@3 p@5
Mean birth 1-bars 1.0∗.33 .8∗∗
Mean death 1-bars 1.0∗.33 .8∗∗
95 Discussion and Future Work
Our study provides solid evidence for PH as a useful interpretability tool for LLMs that is scalable,
model-agnostic, and unifies the global organizational structure within LLM activations together
with local nonlinear detail. Across six state-of-the-art models spanning diverse families and sizes,
the inherent interpretability of PH barcodes reveal a consistent topological deformation under two
fundamentally different attacks. This suggests a general effect in the “shape” of the representation
space, which topological approaches can analyze in ways that existing methods cannot: linear probes
assess linear decodability but miss latent-space structure; mechanistic interpretability traces causal
pathways yet lacks a global view; and representation engineering (e.g., sparse autoencoders) uncovers
local features but not topological invariants. Designing tests to compare these techniques directly
with PH is therefore neither feasible nor meaningful, as they capture complementary and orthogonal
aspects of model behavior. Our local, element-wise analysis of information flow within the LLM
offers a novel approach to understanding the relationships between activations across layers.
Overall, our work advances both theoretical and applied perspectives in LLMs, NLP, and TDA. By
demonstrating the persistent and interpretable topology and geometry of layer-wise and neuron-level
interactions, it reinforces the position of topology as a powerful unifying framework for representation
learning, robustness, and interpretability in neural networks [38].
Limitations. PH is a computationally intensive procedure: although its main kernels parallelize
efficiently on modern CPUs/GPUs, the practical bottleneck is memory, since distance and boundary
matrices scale roughly quadratically with the number of points. This makes exact Vietoris–Rips PH
computations challenging on large high-dimensional data. To overcome this, we implemented random
subsampling to compute proxy barcodes for the entire dataset, thus, our results are subject to sampling
errors. However, subsampling has been well-studied in TDA; in particular, convergence results have
been established [15, 9], so the sampling errors in our study are guaranteed to be bounded.
Future Work. Our work inspires future investigations on whether topological compression is a
general property of misalignment and how it relates to model generalization [ 44]; the development of
topology-aware robustness mechanisms [ 7]; or the use of persistent Morse theory [ 6] and adaptation of
cycle matching approaches [ 41,20] to further characterize LLM representation spaces. Additionally,
our analysis studied two fundamentally distinct adversarial scenarios, prompting the question of
whether our topological approach is able to generalize further.
Acknowledgments
A.F. wishes to thank Daniel Jones for helpful discussions. I.G.R. is funded by a London School
of Geometry and Number Theory–Imperial College London PhD studentship, which is supported
by the EPSRC grant No. EP/S021590/1. Q.W. is funded by a CRUK–Imperial College London
Convergence Science PhD studentship, which is supported by Cancer Research UK under grant
reference CANTAC721 \10021 (PIs Monod/Williams). H.D. is supported by the research program
“Change is Key!” supported by Riksbankens Jubileumsfond (under reference number M21-0021).
H.D. and A.M. are supported by the EPSRC AI Hub on Mathematical Foundations of Intelligence:
An “Erlangen Programme” for AI No. EP/Y028872/1.
References
[1]Sahar Abdelnabi, Aideen Fay, Giovanni Cherubin, Ahmed Salem, Mario Fritz, and Andrew
Paverd. Are you still on track!? catching llm task drift with activations, 2024.
[2]Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen
Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, Alon Benhaim, Misha
Bilenko, Johan Bjorck, Sébastien Bubeck, Martin Cai, Qin Cai, Vishrav Chaudhary, Dong Chen,
Dongdong Chen, Weizhu Chen, Yen-Chun Chen, Yi-Ling Chen, Hao Cheng, Parul Chopra,
Xiyang Dai, Matthew Dixon, Ronen Eldan, Victor Fragoso, Jianfeng Gao, Mei Gao, Min
Gao, Amit Garg, Allie Del Giorno, Abhishek Goswami, Suriya Gunasekar, Emman Haider,
Junheng Hao, Russell J. Hewett, Wenxiang Hu, Jamie Huynh, Dan Iter, Sam Ade Jacobs, Mojan
Javaheripi, Xin Jin, Nikos Karampatziakis, Piero Kauffmann, Mahoud Khademi, Dongwoo Kim,
10Young Jin Kim, Lev Kurilenko, James R. Lee, Yin Tat Lee, Yuanzhi Li, Yunsheng Li, Chen
Liang, Lars Liden, Xihui Lin, Zeqi Lin, Ce Liu, Liyuan Liu, Mengchen Liu, Weishung Liu,
Xiaodong Liu, Chong Luo, Piyush Madan, Ali Mahmoudzadeh, David Majercak, Matt Mazzola,
Caio César Teodoro Mendes, Arindam Mitra, Hardik Modi, Anh Nguyen, Brandon Norick,
Barun Patra, Daniel Perez-Becker, Thomas Portet, Reid Pryzant, Heyang Qin, Marko Radmilac,
Liliang Ren, Gustavo de Rosa, Corby Rosset, Sambudha Roy, Olatunji Ruwase, Olli Saarikivi,
Amin Saied, Adil Salim, Michael Santacroce, Shital Shah, Ning Shang, Hiteshi Sharma, Yelong
Shen, Swadheen Shukla, Xia Song, Masahiro Tanaka, Andrea Tupini, Praneetha Vaddamanu,
Chunyu Wang, Guanhua Wang, Lijuan Wang, Shuohang Wang, Xin Wang, Yu Wang, Rachel
Ward, Wen Wen, Philipp Witte, Haiping Wu, Xiaoxia Wu, Michael Wyatt, Bin Xiao, Can Xu,
Jiahang Xu, Weijian Xu, Jilong Xue, Sonali Yadav, Fan Yang, Jianwei Yang, Yifan Yang, Ziyi
Yang, Donghan Yu, Lu Yuan, Chenruidong Zhang, Cyril Zhang, Jianwen Zhang, Li Lyna Zhang,
Yi Zhang, Yue Zhang, Yunan Zhang, and Xiren Zhou. Phi-3 technical report: A highly capable
language model locally on your phone, 2024.
[3]Robert J. Adler and Jonathan Taylor. Topological complexity of smooth random functions :
Ecole d’Eté de Probabilités de Saint-Flour XXXXIX - 2009 . Lecture notes in mathematics, 2019.
Springer, New York, 1st ed. 2011. edition, 2011.
[4]Dashti Ali, Aras Asaad, Maria-Jose Jimenez, Vidit Nanda, Eduardo Paluzo-Hidalgo, and
Manuel Soriano-Trigueros. A survey of vectorization methods in topological data analysis.
IEEE Transactions on Pattern Analysis and Machine Intelligence , 45(12):14069–14080, 2023.
[5]Ulrich Bauer. Ripser: Efficient computation of Vietoris–Rips persistence barcodes. Journal of
Applied and Computational Topology , 5(3):391–423, September 2021.
[6]Omer Bobrowski and Robert J. Adler. Distance functions, critical points, and the topology of
random ˇCech complexes. Homology, Homotopy and Applications , 16(2):311–344, 2014.
[7]Rickard Brüel-Gabrielsson, Bradley J. Nelson, Anjan Dwaraknath, Primoz Skraba, Leonidas J.
Guibas, and Gunnar Carlsson. A topology layer for machine learning, 2020.
[8]Collin Burns, Haotian Ye, Dan Klein, and Jacob Steinhardt. Discovering latent knowledge in
language models without supervision, 2024.
[9]Yueqi Cao and Anthea Monod. Approximating persistent homology for large datasets. arXiv
preprint arXiv:2204.09155 , 2022.
[10] Sky CH-Wang, Benjamin Van Durme, Jason Eisner, and Chris Kedzie. Do androids know
they’re only dreaming of electric sheep?, 2024.
[11] Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani, George J Pappas, and Eric
Wong. Jailbreaking black box large language models in twenty queries. arXiv , 2023.
[12] Sahil Chaudhary. Code alpaca: An instruction-following llama model for code generation.
https://github.com/sahil280114/codealpaca , 2023.
[13] Jatin Chauhan and Manohar Kaul. Bertops: Studying bert representations under a topological
lens, 2022.
[14] Frédéric Chazal, Brittany Fasy, Fabrizio Lecci, Bertrand Michel, Alessandro Rinaldo, and Larry
Wasserman. Subsampling methods for persistent homology. In International Conference on
Machine Learning , pages 2143–2151. PMLR, 2015.
[15] Frédéric Chazal, Marc Glisse, Catherine Labruère, and Bertrand Michel. Convergence rates for
persistence diagram estimation in topological data analysis. In International Conference on
Machine Learning , pages 163–171. PMLR, 2014.
[16] Harish Chintakunta, Thanos Gentimis, Rocio Gonzalez-Diaz, Maria-Jose Jimenez, and Hamid
Krim. An entropy-based persistence barcode. Pattern Recognition , 48(2):391–401, 2015.
[17] Hoagy Cunningham, Aidan Ewart, Logan Riggs, Robert Huben, and Lee Sharkey. Sparse
autoencoders find highly interpretable features in language models, 2023.
11[18] Joshua Engels, Eric J. Michaud, Isaac Liao, Wes Gurnee, and Max Tegmark. Not all language
model features are one-dimensionally linear, 2025.
[19] Alejandro García-Castellanos, Giovanni Luca Marchetti, Danica Kragic, and Martina Sco-
lamiero. Relative representations: Topological and geometric perspectives, 2024.
[20] Inés García-Redondo, Anthea Monod, and Anna Song. Fast topological signal identification
and persistent cohomological cycle matching. Journal of Applied and Computational Topology ,
8:695–726, 06 2024.
[21] Yuri Gardinazzi, Giada Panerai, Karthik Viswanathan, Alessio Ansuini, Alberto Cazzaniga, and
Matteo Biagetti. Persistent topological features in large language models, 2024.
[22] Thomas Gebhart and Paul Schrater. Adversary detection in neural networks via persistent
homology, 2017.
[23] Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ah-
mad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, Amy Yang, Angela
Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem
Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, Austen Gregerson,
Ava Spataru, Baptiste Roziere, Bethany Biron, Binh Tang, Bobbie Chern, Charlotte Caucheteux,
Chaya Nayak, Chloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret,
Chunyang Wu, Corinne Wong, Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Allonsius,
Daniel Song, Danielle Pintz, Danny Livshits, Danny Wyatt, David Esiobu, Dhruv Choudhary,
Dhruv Mahajan, Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes, Egor Lakomkin, Ehab
AlBadawy, Elina Lobanova, Emily Dinan, Eric Michael Smith, Filip Radenovic, Francisco
Guzmán, Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Georgia Lewis Anderson, Govind
Thattai, Graeme Nail, Gregoire Mialon, Guan Pang, Guillem Cucurell, Hailey Nguyen, Hannah
Korevaar, Hu Xu, Hugo Touvron, Iliyan Zarov, Imanol Arrieta Ibarra, Isabel Kloumann, Ishan
Misra, Ivan Evtimov, Jack Zhang, Jade Copet, Jaewon Lee, Jan Geffert, Jana Vranes, Jason
Park, Jay Mahadeokar, Jeet Shah, Jelmer van der Linde, Jennifer Billock, Jenny Hong, Jenya
Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu, Joanna Bitton,
Joe Spisak, Jongsoo Park, Joseph Rocca, Joshua Johnstun, Joshua Saxe, Junteng Jia, Kalyan Va-
suden Alwala, Karthik Prasad, Kartikeya Upasani, Kate Plawiak, Ke Li, Kenneth Heafield,
Kevin Stone, Khalid El-Arini, Krithika Iyer, Kshitiz Malik, Kuenley Chiu, Kunal Bhalla, Kushal
Lakhotia, Lauren Rantala-Yeary, Laurens van der Maaten, Lawrence Chen, Liang Tan, Liz
Jenkins, Louis Martin, Lovish Madaan, Lubo Malo, Lukas Blecher, Lukas Landzaat, Luke
de Oliveira, Madeline Muzzi, Mahesh Pasupuleti, Mannat Singh, Manohar Paluri, Marcin
Kardas, Maria Tsimpoukelli, Mathew Oldham, Mathieu Rita, Maya Pavlova, Melanie Kam-
badur, Mike Lewis, Min Si, Mitesh Kumar Singh, Mona Hassan, Naman Goyal, Narjes Torabi,
Nikolay Bashlykov, Nikolay Bogoychev, Niladri Chatterji, Ning Zhang, Olivier Duchenne,
Onur Çelebi, Patrick Alrassy, Pengchuan Zhang, Pengwei Li, Petar Vasic, Peter Weng, Prajjwal
Bhargava, Pratik Dubal, Praveen Krishnan, Punit Singh Koura, Puxin Xu, Qing He, Qingxiao
Dong, Ragavan Srinivasan, Raj Ganapathy, Ramon Calderer, Ricardo Silveira Cabral, Robert
Stojnic, Roberta Raileanu, Rohan Maheswari, Rohit Girdhar, Rohit Patel, Romain Sauvestre,
Ronnie Polidoro, Roshan Sumbaly, Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, Saghar Hos-
seini, Sahana Chennabasappa, Sanjay Singh, Sean Bell, Seohyun Sonia Kim, Sergey Edunov,
Shaoliang Nie, Sharan Narang, Sharath Raparthy, Sheng Shen, Shengye Wan, Shruti Bhosale,
Shun Zhang, Simon Vandenhende, Soumya Batra, Spencer Whitman, Sten Sootla, Stephane
Collot, Suchin Gururangan, Sydney Borodinsky, Tamar Herman, Tara Fowler, Tarek Sheasha,
Thomas Georgiou, Thomas Scialom, Tobias Speckbacher, Todor Mihaylov, Tong Xiao, Ujjwal
Karn, Vedanuj Goswami, Vibhor Gupta, Vignesh Ramanathan, Viktor Kerkez, Vincent Gonguet,
Virginie Do, Vish V ogeti, Vítor Albiero, Vladan Petrovic, Weiwei Chu, Wenhan Xiong, Wenyin
Fu, Whitney Meers, Xavier Martinet, Xiaodong Wang, Xiaofang Wang, Xiaoqing Ellen Tan,
Xide Xia, Xinfeng Xie, Xuchao Jia, Xuewei Wang, Yaelle Goldschlag, Yashesh Gaur, Yasmine
Babaei, Yi Wen, Yiwen Song, Yuchen Zhang, Yue Li, Yuning Mao, Zacharie Delpierre Coudert,
Zheng Yan, Zhengxing Chen, Zoe Papakipos, Aaditya Singh, Aayushi Srivastava, Abha Jain,
Adam Kelsey, Adam Shajnfeld, Adithya Gangidi, Adolfo Victoria, Ahuva Goldstand, Ajay
Menon, Ajay Sharma, Alex Boesenberg, Alexei Baevski, Allie Feinstein, Amanda Kallet, Amit
Sangani, Amos Teo, Anam Yunus, Andrei Lupu, Andres Alvarado, Andrew Caples, Andrew Gu,
Andrew Ho, Andrew Poulton, Andrew Ryan, Ankit Ramchandani, Annie Dong, Annie Franco,
12Anuj Goyal, Aparajita Saraf, Arkabandhu Chowdhury, Ashley Gabriel, Ashwin Bharambe,
Assaf Eisenman, Azadeh Yazdan, Beau James, Ben Maurer, Benjamin Leonhardi, Bernie Huang,
Beth Loyd, Beto De Paola, Bhargavi Paranjape, Bing Liu, Bo Wu, Boyu Ni, Braden Hancock,
Bram Wasti, Brandon Spence, Brani Stojkovic, Brian Gamido, Britt Montalvo, Carl Parker,
Carly Burton, Catalina Mejia, Ce Liu, Changhan Wang, Changkyu Kim, Chao Zhou, Chester
Hu, Ching-Hsiang Chu, Chris Cai, Chris Tindal, Christoph Feichtenhofer, Cynthia Gao, Damon
Civin, Dana Beaty, Daniel Kreymer, Daniel Li, David Adkins, David Xu, Davide Testuggine,
Delia David, Devi Parikh, Diana Liskovich, Didem Foss, Dingkang Wang, Duc Le, Dustin
Holland, Edward Dowling, Eissa Jamil, Elaine Montgomery, Eleonora Presani, Emily Hahn,
Emily Wood, Eric-Tuan Le, Erik Brinkman, Esteban Arcaute, Evan Dunbar, Evan Smothers,
Fei Sun, Felix Kreuk, Feng Tian, Filippos Kokkinos, Firat Ozgenel, Francesco Caggioni, Frank
Kanayet, Frank Seide, Gabriela Medina Florez, Gabriella Schwarz, Gada Badeer, Georgia Swee,
Gil Halpern, Grant Herman, Grigory Sizov, Guangyi, Zhang, Guna Lakshminarayanan, Hakan
Inan, Hamid Shojanazeri, Han Zou, Hannah Wang, Hanwen Zha, Haroun Habeeb, Harrison
Rudolph, Helen Suk, Henry Aspegren, Hunter Goldman, Hongyuan Zhan, Ibrahim Damlaj,
Igor Molybog, Igor Tufanov, Ilias Leontiadis, Irina-Elena Veliche, Itai Gat, Jake Weissman,
James Geboski, James Kohli, Janice Lam, Japhet Asher, Jean-Baptiste Gaya, Jeff Marcus, Jeff
Tang, Jennifer Chan, Jenny Zhen, Jeremy Reizenstein, Jeremy Teboul, Jessica Zhong, Jian Jin,
Jingyi Yang, Joe Cummings, Jon Carvill, Jon Shepard, Jonathan McPhie, Jonathan Torres, Josh
Ginsburg, Junjie Wang, Kai Wu, Kam Hou U, Karan Saxena, Kartikay Khandelwal, Katayoun
Zand, Kathy Matosich, Kaushik Veeraraghavan, Kelly Michelena, Keqian Li, Kiran Jagadeesh,
Kun Huang, Kunal Chawla, Kyle Huang, Lailin Chen, Lakshya Garg, Lavender A, Leandro
Silva, Lee Bell, Lei Zhang, Liangpeng Guo, Licheng Yu, Liron Moshkovich, Luca Wehrstedt,
Madian Khabsa, Manav Avalani, Manish Bhatt, Martynas Mankus, Matan Hasson, Matthew
Lennie, Matthias Reso, Maxim Groshev, Maxim Naumov, Maya Lathi, Meghan Keneally, Miao
Liu, Michael L. Seltzer, Michal Valko, Michelle Restrepo, Mihir Patel, Mik Vyatskov, Mikayel
Samvelyan, Mike Clark, Mike Macey, Mike Wang, Miquel Jubert Hermoso, Mo Metanat,
Mohammad Rastegari, Munish Bansal, Nandhini Santhanam, Natascha Parks, Natasha White,
Navyata Bawa, Nayan Singhal, Nick Egebo, Nicolas Usunier, Nikhil Mehta, Nikolay Pavlovich
Laptev, Ning Dong, Norman Cheng, Oleg Chernoguz, Olivia Hart, Omkar Salpekar, Ozlem
Kalinli, Parkin Kent, Parth Parekh, Paul Saab, Pavan Balaji, Pedro Rittner, Philip Bontrager,
Pierre Roux, Piotr Dollar, Polina Zvyagina, Prashant Ratanchandani, Pritish Yuvraj, Qian Liang,
Rachad Alao, Rachel Rodriguez, Rafi Ayub, Raghotham Murthy, Raghu Nayani, Rahul Mitra,
Rangaprabhu Parthasarathy, Raymond Li, Rebekkah Hogan, Robin Battey, Rocky Wang, Russ
Howes, Ruty Rinott, Sachin Mehta, Sachin Siby, Sai Jayesh Bondu, Samyak Datta, Sara Chugh,
Sara Hunt, Sargun Dhillon, Sasha Sidorov, Satadru Pan, Saurabh Mahajan, Saurabh Verma,
Seiji Yamamoto, Sharadh Ramaswamy, Shaun Lindsay, Shaun Lindsay, Sheng Feng, Shenghao
Lin, Shengxin Cindy Zha, Shishir Patil, Shiva Shankar, Shuqiang Zhang, Shuqiang Zhang,
Sinong Wang, Sneha Agarwal, Soji Sajuyigbe, Soumith Chintala, Stephanie Max, Stephen
Chen, Steve Kehoe, Steve Satterfield, Sudarshan Govindaprasad, Sumit Gupta, Summer Deng,
Sungmin Cho, Sunny Virk, Suraj Subramanian, Sy Choudhury, Sydney Goldman, Tal Remez,
Tamar Glaser, Tamara Best, Thilo Koehler, Thomas Robinson, Tianhe Li, Tianjun Zhang, Tim
Matthews, Timothy Chou, Tzook Shaked, Varun V ontimitta, Victoria Ajayi, Victoria Montanez,
Vijai Mohan, Vinay Satish Kumar, Vishal Mangla, Vlad Ionescu, Vlad Poenaru, Vlad Tiberiu
Mihailescu, Vladimir Ivanov, Wei Li, Wenchen Wang, Wenwen Jiang, Wes Bouaziz, Will Con-
stable, Xiaocheng Tang, Xiaojian Wu, Xiaolan Wang, Xilun Wu, Xinbo Gao, Yaniv Kleinman,
Yanjun Chen, Ye Hu, Ye Jia, Ye Qi, Yenda Li, Yilin Zhang, Ying Zhang, Yossi Adi, Youngjin
Nam, Yu, Wang, Yu Zhao, Yuchen Hao, Yundi Qian, Yunlu Li, Yuzi He, Zach Rait, Zachary
DeVito, Zef Rosnbrick, Zhaoduo Wen, Zhenyu Yang, Zhiwei Zhao, and Zhiyu Ma. The llama 3
herd of models, 2024.
[24] Ryan Greenblatt, Fabien Roger, Dmitrii Krasheninnikov, and David Krueger. Stress-testing
capability elicitation with password-locked models, 2024.
[25] Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph Endres, Thorsten Holz, and Mario
Fritz. Not what you’ve signed up for: Compromising real-world llm-integrated applications
with indirect prompt injection, 2023.
[26] Wes Gurnee and Max Tegmark. Language models represent space and time, 2024.
13[27] John Hewitt and Christopher D. Manning. A structural probe for finding syntax in word
representations. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of
the 2019 Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) , pages 4129–
4138, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
[28] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang,
Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models, 2021.
[29] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh
Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile
Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut
Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. Mistral 7b, 2023.
[30] Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris
Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand,
Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio Renard Lavaud, Lucile Saulnier,
Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak,
Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and
William El Sayed. Mixtral of experts, 2024.
[31] Nathalie Maria Kirch, Severin Field, and Stephen Casper. What features in prompts jailbreak
llms? investigating the mechanisms behind attacks, 2024.
[32] Nathaniel Li, Alexander Pan, Anjali Gopal, Summer Yue, Daniel Berrios, Alice Gatti, Justin D.
Li, Ann-Kathrin Dombrowski, Shashwat Goel, Long Phan, Gabriel Mukobi, Nathan Helm-
Burger, Rassin Lababidi, Lennart Justen, Andrew B. Liu, Michael Chen, Isabelle Barrass,
Oliver Zhang, Xiaoyuan Zhu, Rishub Tamirisa, Bhrugu Bharathi, Adam Khoja, Zhenqi Zhao,
Ariel Herbert-V oss, Cort B. Breuer, Samuel Marks, Oam Patel, Andy Zou, Mantas Mazeika,
Zifan Wang, Palash Oswal, Weiran Lin, Adam A. Hunt, Justin Tienken-Harder, Kevin Y . Shih,
Kemper Talley, John Guan, Russell Kaplan, Ian Steneker, David Campbell, Brad Jokubaitis,
Alex Levinson, Jean Wang, William Qian, Kallol Krishna Karmakar, Steven Basart, Stephen
Fitz, Mindy Levine, Ponnurangam Kumaraguru, Uday Tupakula, Vijay Varadharajan, Ruoyu
Wang, Yan Shoshitaishvili, Jimmy Ba, Kevin M. Esvelt, Alexandr Wang, and Dan Hendrycks.
The wmdp benchmark: Measuring and reducing malicious use with unlearning, 2024.
[33] Yuxiao Li, Eric J. Michaud, David D. Baek, Joshua Engels, Xiaoqing Sun, and Max Tegmark.
The geometry of concepts: Sparse autoencoder feature structure, 2024.
[34] Stan Lipovetsky and Michael Conklin. Analysis of regression in game theory approach. Applied
Stochastic Models in Business and Industry , 17(4):319–330, 2001.
[35] Samuel Marks and Max Tegmark. The geometry of truth: Emergent linear structure in large
language model representations of true/false datasets, 2024.
[36] Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. Locating and editing factual
associations in gpt, 2023.
[37] Neel Nanda, Andrew Lee, and Martin Wattenberg. Emergent linear representations in world
models of self-supervised sequence models, 2023.
[38] Theodore Papamarkou, Tolga Birdal, Michael Bronstein, Gunnar Carlsson, Justin Curry, Yue
Gao, Mustafa Hajij, Roland Kwitt, Pietro Liò, Paolo Di Lorenzo, et al. Position: Topological
deep learning is the new frontier for relational learning. arXiv preprint arXiv:2402.08871 , 2024.
[39] Ethan Perez, Sam Ringer, Kamil ˙e Lukoši ¯ut˙e, Karina Nguyen, Edwin Chen, Scott Heiner, Craig
Pettit, Catherine Olsson, Sandipan Kundu, Saurav Kadavath, Andy Jones, Anna Chen, Ben
Mann, Brian Israel, Bryan Seethor, Cameron McKinnon, Christopher Olah, Da Yan, Daniela
Amodei, Dario Amodei, Dawn Drain, Dustin Li, Eli Tran-Johnson, Guro Khundadze, Jackson
Kernion, James Landis, Jamie Kerr, Jared Mueller, Jeeyoon Hyun, Joshua Landau, Kamal
Ndousse, Landon Goldberg, Liane Lovitt, Martin Lucas, Michael Sellitto, Miranda Zhang,
Neerav Kingsland, Nelson Elhage, Nicholas Joseph, Noemí Mercado, Nova DasSarma, Oliver
Rausch, Robin Larson, Sam McCandlish, Scott Johnston, Shauna Kravec, Sheer El Showk,
14Tamera Lanham, Timothy Telleen-Lawton, Tom Brown, Tom Henighan, Tristan Hume, Yuntao
Bai, Zac Hatfield-Dodds, Jack Clark, Samuel R. Bowman, Amanda Askell, Roger Grosse, Danny
Hernandez, Deep Ganguli, Evan Hubinger, Nicholas Schiefer, and Jared Kaplan. Discovering
language model behaviors with model-written evaluations, 2022.
[40] Andres Pollano, Anupam Chaudhuri, and Anj Simmons. Detecting out-of-distribution text
using topological features of transformer-based language models, 2024.
[41] Yohai Reani and Omer Bobrowski. Cycle registration in persistent homology with applications
in topological bootstrap. IEEE Transactions on Pattern Analysis and Machine Intelligence ,
45(5):5579–5593, 2022.
[42] Johann Rehberger. Microsoft Copilot: From Prompt Injection to Exfiltration of Personal
Information. [Link], 2024.
[43] Matteo Rucco, Filippo Castiglione, Emanuela Merelli, and Marco Pettini. Characterisation
of the idiotypic immune network through persistent entropy. In Stefano Battiston, Francesco
De Pellegrini, Guido Caldarelli, and Emanuela Merelli, editors, Proceedings of ECCS 2014 ,
pages 117–128, Cham, 2016. Springer International Publishing.
[44] Cory Stephenson, Suchismita Padhy, Abhinav Ganesh, Yue Hui, Hanlin Tang, and SueYeon
Chung. On the geometry of generalization and memorization in deep neural networks, 2021.
[45] Ian Tenney, Dipanjan Das, and Ellie Pavlick. Bert rediscovers the classical nlp pipeline, 2019.
[46] Adaku Uchendu and Thai Le. Unveiling topological structures in text: A comprehensive survey
of topological data analysis applications in nlp, 2024.
[47] Teun van der Weij, Felix Hofstätter, Ollie Jaffe, Samuel F. Brown, and Francis Rhys Ward. Ai
sandbagging: Language models can strategically underperform on evaluations, 2024.
[48] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,
Lukasz Kaiser, and Illia Polosukhin. Attention is all you need, 2023.
[49] Simon Zhang, Mengbai Xiao, and Hao Wang. Gpu-accelerated computation of vietoris-rips
persistence barcodes. In 36th International Symposium on Computational Geometry (SoCG
2020) , pages 70–1. Schloss Dagstuhl–Leibniz-Zentrum für Informatik, 2020.
[50] Andy Zou, Long Phan, Sarah Chen, James Campbell, Phillip Guo, Richard Ren, Alexander
Pan, Xuwang Yin, Mantas Mazeika, Ann-Kathrin Dombrowski, Shashwat Goel, Nathaniel
Li, Michael J. Byun, Zifan Wang, Alex Mallen, Steven Basart, Sanmi Koyejo, Dawn Song,
Matt Fredrikson, J. Zico Kolter, and Dan Hendrycks. Representation engineering: A top-down
approach to ai transparency, 2023.
[51] Egor Zverev, Sahar Abdelnabi, Soroush Tabesh, Mario Fritz, and Christoph H. Lampert. Can
llms separate instructions from data? and what do we even mean by that?, 2025.
15A Further Topological and Local Variance Interpretation
A.1 Persistent Homology Barcode Statistics
To interpret the barcodes from Section 3.2, we extract key summary statistics that quantify the
topological structure observed at each layer under both adversarial conditions.
From each 1-dimensional (1D) barcode, we gather intervals (bi, di)withdi> bi>0and define
ℓi=di−bi. Forming a discrete distribution pi=ℓi/P
jℓj, the persistent entropy is
E=−X
ipiln(pi+ϵ),
where ϵis a small positive constant (e.g., 10−12) to ensure numerical stability. Higher Eindicates
a more uniform distribution of lifetimes (no single interval dominates), whereas lower Ereflects a
small number of long-lived intervals.
In addition to entropy , we compute the following summary statistics on dimension-1 bars:
•Mean births (1-bars): Average birth time ¯b
•Mean deaths (1-bars): Average death time ¯d
•Mean persistence (1-bars): Average lifetime (di−bi)
•Number of 1-bars: Count of finite intervals in dimension 1
We perform these computations for each barcode individually and then average over all barcodes in
the same condition ( locked orelicited ) and ( clean orpoisoned ).
A.1.1 Extended Prompt Injection (Clean vs. Poisoned)
Table 2: Dimension-1 persistent homology differences ( clean−poisoned ) in key metrics for
three models across several layers. Positive values mean the clean condition has a higher value,
while negative indicates poisoned is higher for that metric. All entries rounded to four decimals.
Model LayerMean births
1-bars_diffMean deaths
1-bars_diffMean persistence
1-bars_diffEntropy
1-bars_diffNumber
1-bars_diff
LLaMA-3
(8B)1 -0.0005 -0.0006 -0.0001 0.1665 86.9700
8 -0.0609 -0.0608 0.0001 0.1213 79.5600
16 -0.3166 -0.3249 -0.0082 0.0188 17.9367
24 -0.9932 -1.0256 -0.0324 0.1595 80.0833
32 -18.3367 -18.9290 -0.5923 0.3348 192.4900
Mistral
(7B)1 0.0004 0.0004 0.0000 0.0172 3.7967
8 -0.0293 -0.0295 -0.0002 0.1485 118.9167
16 -0.2375 -0.2421 -0.0047 0.1938 154.7633
24 -0.5694 -0.5815 -0.0120 0.2070 153.9633
32 -14.7376 -15.0558 -0.3182 0.2239 166.4267
Phi 3
(3.8B)1 0.0011 0.0009 -0.0002 0.0101 4.3200
8 -0.4522 -0.4675 -0.0153 0.0888 59.0967
16 -1.7825 -1.8293 -0.0467 0.0696 48.7367
24 -6.2017 -6.3448 -0.1431 0.1665 116.9433
32 -1.0092 -1.0503 -0.0411 -0.4857 -136.1200
Formean births andmean deaths , all layers except layer 1 across models have negative differences,
indicating that poisoned intervals emerge and die later in the filtration. The mean persistence is
also higher for poisoned examples, especially in the middle layers. The entropy differences are also
almost all positive (except Phi3 3.8’s final layer), suggesting that clean distributes its 1D lifetimes
more evenly, while poisoned tends to concentrate total persistence in fewer cycles. Likewise, the
number of 1-bars remains mostly positive, so clean produces more 1D holes overall.
Overall, poisoned conditions often yield fewer but more dominant dimension–1 features that appear
later and persist longer, whereas clean spreads its total persistence across numerous shorter-lived
16cycles, resulting in higher entropy. Depending on the model, the specific layer where these features
distinctions appear strongest differ but the nature of the difference is the same across models and
layers.
A.1.2 Sandbagged Model (Locked vs. Elicited)
Table 3: Dimension-1 persistent homology differences ( elicited −locked ) for two models across
multiple layers. Positive values indicate that the elicited condition has higher values; negative
means locked is higher for that metric.
Model LayerMean births
1-bars_diffMean deaths
1-bars_diffMean persistence
1-bars_diffEntropy
1-bars_diffNumber
1-bars_diff
LLaMA-3
(8B)0 -0.0127 -0.0132 -0.0005 0.0156 3.2400
7 -0.3425 -0.3555 -0.0130 0.0647 27.8600
15 -0.0476 -0.0455 0.0021 0.2114 135.2900
23 -0.1168 -0.1204 -0.0037 0.0100 61.8766
31 -0.9750 -1.0458 -0.0707 0.0620 28.2800
Mistral
(7B)0 -0.0053 -0.0055 -0.0002 0.0942 27.1533
7 -0.1925 -0.1989 -0.0064 0.0310 14.1066
15 0.0393 0.0352 -0.0041 0.0277 10.9300
23 0.6722 0.7037 0.0315 -0.0363 -0.1900
31 14.6450 15.2952 0.6503 -0.0014 9.3233
For LLaMA3 8B , the mean birth and death differences are negative across all computed hidden
layers (1, 8, 16, 24, 32). Note that layers are zero-indexed, meaning that layer 0 corresponds to the
first hidden layer, layer 1. This indicates that, in the locked condition, 1D cycles exhibit larger (i.e.,
later) birth and death times compared to elicited . In other words, when locked, the 1D features tend
to emerge “further out” in the filtration. The mean persistence difference between conditions is also
negative (except layer 16), suggesting that locked cycles generally persist slightly longer on average.
Entropy differences are positive, indicating that elicited exhibits a greater diversity or spread among
the lifetimes of its 1D features. The number of 1-bars is positive (sometimes strongly so), meaning
there are substantially more 1D features in the elicited condition.
We see similar results for Mistral 7B with negative differences in births and deaths in earlier layers,
implying that locked has larger birth/death times at those lower layers. However, the sign flips, with
elicited displaying larger values for births, deaths, and persistence. Specifically, layer 32 shows a
notably large positive difference (e.g., +14.64for births, +15.29for deaths), indicating that the final
layer in elicited captures significantly later 1D cycles relative to locked. The number of 1-bars also
tends to be higher in elicited at most layers, except for a minor negative at layer 23, again suggesting
that elicited reveals a greater number of dimension–1 features.
A.2 Local Dispersion Ratio Across Poisoned Conditions
We analyze how local geometry in hidden-layer representation space differs between clean and
multiple poisoned modes in six LLMs. We further classify poisoned prompts into three sub-types:
1.Executed: The injected request is recognized and carried out (indirect prompt injection).
2.Refused: The model identifies the injected content as malicious and issues a refusal,
effectively “shutting down” any detailed elaboration.
3.Ignored: The model neither executes nor refuses, but effectively overlooks the injected
prompt, proceeding as if it were absent.
For each final token’s activation difference vector ∆Act ℓ(xi)∈RD,we identify its knearest
neighbors in layer ℓand perform PCA on those points. Let λ1≥ ··· ≥ λD′be the resulting
eigenvalues. We define the dispersion ratio of∆Act ℓ(xi)as
PD′
j=2λj
λ1+ϵ,
17where ϵprevents division by zero. A higher ratio indicates that variance is more evenly spread among
secondary directions, whereas a lower ratio implies most variance lies in a single dominant direction.
Ablation: Clean vs. Clean, Poisoned vs. Poisoned, and Mixed. To confirm that dispersion
discrepancies primarily reflect true clean vs.poisoned distinctions rather than random partitioning or
mixture effects, we performed three auxiliary comparisons:
1.Clean vs. Clean : Split the clean set into two subsets, ensuring no significant difference
arises from sampling within the same class.
2.Poisoned vs. Poisoned : Applied the same procedure to poisoned data to assess within-class
variability.
3.Mixed vs. Mixed : Randomly partitioned a combined pool of clean and poisoned samples
into two balanced groups.
Note on Statistical Methods: For every layer in each subplot, we computed the dispersion ratio for
both clean and the specified poisoned (orrefused ,executed ,ignored ) samples. We then conducted a
Welch’s t-test on these two groups (clean vs. poisoned/other), applying false-discovery rate (FDR)
correction across layers. We also verified approximate normality via kernel density estimates (KDEs)
for each groups. Plot markers with stars indicate layers where pFDR<0.05, confirming a statistically
significant difference in dispersion ratio. To select k= 30 , we tested candidate neighborhood sizes
across layers and models, measuring which kproduced the largest absolute difference in mean local
dispersion ratio between clean and poisoned conditions.
A.2.1 Discussion of Results
Figures 12 and 13 highlight that:
•Early Layers (Layer 1–8): Across all poisoning modes, the clean condition consistently
shows a higher dispersion ratio, suggesting that the model initially allocates broader repre-
sentational capacity for normal inputs.
•Mid Layers (Layer 16): This pattern often flips, with poisoned prompts (especially executed
orignored ) exceeding the clean baseline, indicating the network is dedicating extra directions
to elaborate or “embrace” these injected requests. Conversely, refused prompts typically
exhibit reduced dispersion, mapping disallowed content into a lower-variance region.
Interestingly, our findings align with the results in [ 44], which indicate that memorization tends to
emerge in deeper layers where the effective dimensionality shrinks. Consistent with that view, we
observe that executed orignored prompts show a higher dispersion in mid-layers, implying the model
invests additional capacity there for those injected instructions. Meanwhile, a refused request is
routed into a more compressed region, effectively “shutting down” further representational expansion.
In this sense, deeper layers may provide a setting where the network can more sharply discriminate
or overfit certain inputs—supporting the idea that final layers reflect a gradually compressed, yet
strategically focused representation space.
A.3 Cosine Distance of Representations
We analyze the difference representations ∆Act ℓ(xi)∈RDfor corresponding pairs of clean and
poisoned inputs. Specifically, for each model and layer, we load up to five pairs of clean andpoisoned
activation files, compute the difference between the activations for each pair, and concatenate these
differences. From these differences, we draw equal-size subsamples of 5,000 vectors. For each layer
and comparison condition, we compute the mean pairwise cosine distance within each subsample.
Because cosine distance is scale-invariant, we do not normalize these difference representations. We
perform four comparison conditions: clean vs.poisoned ,clean vs.clean (where clean samples are
split in half), poisoned vs.poisoned (where poisoned samples are split in half), and mixed vs.mixed
(where two separate mixed subsamples are created, each containing half clean and half poisoned
differences). For each comparison, we generate two distributions of mean pairwise intra- class
distances (or inter- class in the clean vspoisoned case) using 3 bootstrap iterations. We then apply
Welch’s t-test to these distributions to assess whether they diverge significantly.
18Layer3.003.253.503.754.004.254.504.75Mean Dispersion Ratio
Phi3 3.8B
LayerMean Dispersion Ratio
Mistral 7B
Layer3.003.253.503.754.004.254.504.75Mean Dispersion Ratio
LLaMA3 8B
LayerMean Dispersion Ratio
Phi3 Medium 128k
0 15 23 31
Layer3.003.253.503.754.004.254.504.75Mean Dispersion Ratio
Mixtral 8x7B
0 15 23 31
LayerMean Dispersion Ratio
LLaMA3 70B
Condition
Clean PoisonedFigure 12: Layer-wise Dispersion Ratio for Clean vs. Poisoned Examples. The green and red
lines depict mean dispersion ratios for clean andpoisoned inputs, respectively, at different layer
depths. Error bars around each point represent ±1standard error of the mean (SEM). In early layers
(left side), clean data consistently has higher dispersion on average, whereas in mid-layers (center),
poisoned surpasses the clean baseline, indicating a re-distribution of representational capacity for the
injected prompts. Layers where the difference is statistically significant ( pFDR<0.05) are marked
with a red asterisk above the higher mean value.
Figure 13: LLaMA3_7B Dispersion Ratio: Clean vs. Executed, Refused, and Ignored Prompts.
The horizontal axis indicates layer depth, while the vertical axis represents the mean dispersion ratio.
The blue curve (with confidence band) corresponds to clean inputs; orange, red, and green curves
denote executed ,refused , and ignored poisoned prompts, respectively. Notably, refused prompts show
an early jump but then collapse below the clean baseline, whereas executed andignored surpass it
around mid-layers, highlighting distinct representational regimes.
Empirically, poisoned difference representations typically exhibit a higher mean cosine distance
in deeper layers, indicating a more “spread-out” or heterogeneous arrangement of their difference
vectors, much as we observed in the curvature analysis. Clean data, by contrast, remains comparatively
tightly clustered, implying less dispersion in its difference space. Interestingly, LLaMA3_70B displays
similar characteristics in the early and final layers but poisoned representations have a noticeable
smaller cosine distance in middle layers. This may reflect the ability of larger architectures to better
partition representation space across the network before re-expanding in later layers.
190 10 20 30
Layer0.6
0.4
0.2
0.00.20.4Mean Difference
mistral_7B
0 10 20 30
Layer1.0
0.8
0.6
0.4
0.2
0.00.20.40.6Mean Difference
llama_8B
0 10 20 30
Layer1.0
0.8
0.6
0.4
0.2
0.0Mean Difference
mixtral_8_7B
0 10 20 30
Layer1.0
0.8
0.6
0.4
0.2
0.00.20.40.6Mean Difference
phi3_3.8
0 20 40 60
Layer1.50
1.25
1.00
0.75
0.50
0.25
0.000.25Mean Difference
llama3_70B
0 10 20 30
Layer0.50
0.25
0.000.250.500.751.00Mean Difference
phi3_medium_128k
Comparison
Clean vs Clean Poisoned vs Poisoned Clean vs PoisonedFigure 14: Ablation of Dispersion Ratio Differences (Clean vs. Clean, Poisoned vs. Poisoned,
Mixed vs. Mixed). Each plot shows the difference in mean dispersion ratio (clean minus poisoned).
Positive values indicate that the clean subset exhibits higher dispersion, whereas negative values
reflect a more dispersed poisoned subset.
B Further Details of Global Layer-Wise Analysis
B.1 Pipeline
We describe in more detail the pipeline in Figure 3 in the main text. Recall that our aim here was
showcasing that topological signatures effectively capture distinctions between representations under
normal or adversarial conditions, and to provide an interpretation of the reason behind such difference
in terms of the “shape” of the latent representations.
We use RIPSER [5] to compute barcodes, which is based on Vietoris–Rips filtrations (see Section 2.1).
The computational constraints of PH make it impossible to compute the barcode of any of our two
datasets (clean vs. poisoned or locked vs. elicited). Therefore, we leverage subsampling approaches
(e.g., [ 14]) and compute barcodes from K= 600 subsamples {xi1,ℓ, . . . , x ik,ℓ} ⊂RDwith size
k= 1000 , of the representations per layer 1≤ℓ≤L. From these, 300are taken from normal
activations and 300from adversarial activations. We use these as proxies for the topology of the
whole space.
Following [ 4], we vectorize these barcodes as 41-dimensional feature vectors, which we call barcode
summaries . These include 35 statistics derived from a 7×5grid of {mean, minimum, first quartile,
median, third quartile, maximum, standard deviation} ×{death of 0-bars, birth of 1-bars, death of
1-bars, persistence of 1-bars, ratio birth/death of 1-bars}; as well as the total persistence (i.e., sum
of the lengths of all bars in the barcode), number of bars, and persistent entropy [ 16,43] defined in
Appendix A.1 for 0- and 1-bars. We reduce the dimensionality case-by-case, by eliminating highly
correlated features (above a threshold of 0.5) through cross-correlation analysis.
20Layer0.100.150.200.250.30Avg Distance
*
********llama3_70B - Cosine Dist.
Clean
Poison
Layer0.10.20.30.40.50.6Avg Distance
*****llama_8B - Cosine Dist.
Clean
Poison
Layer0.20.30.40.5Avg Distance
*
****mistral_7B - Cosine Dist.
Clean
Poison
Layer0.30.40.50.6Avg Distance
*
****mixtral_8_7B - Cosine Dist.
Clean
Poison
0 20 40 60
Layer0.10.20.30.40.5Avg Distance
*****phi3_3.8 - Cosine Dist.
Clean
Poison
0 20 40 60
Layer0.10.20.30.4Avg Distance
*****phi3_medium_128k - Cosine Dist.
Clean
PoisonFigure 15: Cosine Distance of Difference Representations Across Layers. Each panel shows mean
within-class distances (clean vs. poisoned) for the difference representations ( poisoned/clean pass
minus baseline ), where higher values reflect greater variation among samples. Stars denote layers
with significant differences.
For exploratory analysis, we apply PCA and compute CCA loadings to measure feature correlations
with the principal components. A logistic regression model is then used for classification, and Shapley
values [ 34] are computed to evaluate feature importance. Shapley values, derived from cooperative
game theory, quantify the contribution of each feature to model predictions by measuring its influence
in shifting predictions from a baseline (e.g., 0.5 for logistic regression), providing an interpretable,
feature-level analysis of predictive impact.
B.2 Results: Clean vs. poisoned
B.2.1 Mistral 7B
We present here additional results on the global analysis for Mistral 7B that are referred to in the
main text of the paper.
21Table 4: Pruned barcode summaries for layers 1, 8, 16, 24 and 32. Features from the barcode
summaries with correlation less than 0.5 in the cross-correlation matrix.
Layer 1 Layer 8 Layer 16 Layer 24 Layer 32
Mean death 0-bars ✓ ✓ ✓ ✓ ✓
Minimum death 0-bars ✓ ✓
Maximum death 0-bars ✓
Standard deviation death 0-bars ✓
Minimum birth 1-bars
Maximum birth 1-bars ✓
Minimum persistence 1-bars ✓ ✓ ✓ ✓ ✓
First quartile persistence 1-bars ✓
Maximum persistence 1-bars ✓
Mean birth/death 1-bars ✓ ✓ ✓
First quartile birth/death 1-bars ✓
Maximum birth/death 1-bars ✓
Total persistence 1-bars ✓
Number 0-bars ✓ ✓ ✓ ✓ ✓
Number 1-bars ✓ ✓ ✓
Entropy 0-bars ✓ ✓
Total features 8 9 8 4 5
Figure 16: CCA loadings for clean vs. poisoned activations . Loadings of the 5 most important
contributions to the first canonical variable of the CCA on the pruned barcode summaries show that
the mean of the death of 0-bars is significantly correlated with the first two principal components of
the PCA across all layers.
B.2.2 Phi3-mini-4k (3.8B parameters)
We provide the results of the analysis depicted in Figure 3 including layers 1, 8, 16, 23, and 32 for Phi
3 (3.8B parameters) where barcodes are computed using the Euclidean distance in the representation
space.
22Figure 17: Histograms for the mean of the births of 1-bars and persistence of 1-bars for Mistral.
Features extracted from the barcode summaries of the activations for layers 1, 8, 16, 24 and 32 of the
clean vs. poisoned dataset.
Figure 18: Cross-correlation matrices for the barcode summaries for clean vs. poisoned activa-
tions. Growing block of correlated features appears in the cross-correlation matrix of the barcode
summaries appears in the middle layers (layers 1, 8, 16, 24, and 32 are shown).
Figure 19: PCA of barcode summaries of clean vs. poisoned activations . Clear distinction appears
in the projection onto the two first principal components from the PCA of the pruned barcode
summaries for layers 1, 8, 16, 24, and 32.
23Figure 20: CCA loadings for clean vs. poisoned activations . Loadings of the 5 most important
contributions to the first canonical variable of the CCA on the pruned barcode summaries show that
the mean of the death of 0-bars is significantly correlated with the first two principal components of
the PCA across all layers.
Figure 21: Logistic regression for clean vs. poisoned activations. Prediction of a logistic regression
trained on a 70/30 train/test split of the pruned barcode summaries, plotted on the projection onto
the two first principal components for visualization purposes. Accuracy and AUC–ROC tested on
the test data, and 5-fold cross validation on train data are presented for each model, showcasing the
outstanding performance of all models.
B.2.3 Mixtral-8x7B (7B parameters)
We provide the results of the analysis depicted in Figure 3 including layers 1, 8, 16, 23 and 32 for the
Mixtral 8 (7B parameters) model where barcodes are computed using the Euclidean distance in the
representation space. We observe very similar results to the ones obtained with Mistral, indicating a
consistency across models of the topological deformations of adversarial influence via XPIA (see
Section 3.1).
Figure 23: Cross-correlation matrices for the barcode summaries for clean vs. poisoned activa-
tions. Growing block of correlated features appears in the cross-correlation matrix of the barcode
summaries for layers 1, 8, 16, 24, and 32. Correlations in layer 1 are lower than with Mistral 7B, see
Figure 6.
24Figure 22: SHAP analysis: clean vs. poisoned activations. Beeswarm plot of logistic regression
SHAP values trained on the pruned barcode summaries for layer 1, 8, 16, 24, and 32.
Figure 24: PCA of barcode summaries of clean vs. poisoned activations . Clear distinction appears
in the projection onto the two first principal components from the PCA of the pruned barcode
summaries for layers 1, 8, 16, 24, and 32.
Figure 25: CCA loadings for clean vs. poisoned activations . Loadings of the 5 most important
contributions to the first canonical variable of the CCA on the pruned barcode summaries show that
the mean of the death of 0-bars is significantly correlated with the first two principal components of
the PCA across all layers.
25Figure 26: Logistic regression for clean vs. poisoned activations. Prediction of a logistic regression
trained on a 70/30 train/test split of the pruned barcode summaries, plotted on the projection onto
the two first principal components for visualization purposes. Accuracy and AUC–ROC tested on
the test data, and 5-fold cross validation on train data are presented for each model, showcasing the
outstanding performance of all models.
Figure 27: SHAP analysis: clean vs. poisoned activations. Beeswarm plot of logistic regression
SHAP values trained on the pruned barcode summaries for layer 1, 8, 16, 24, and 32.
B.2.4 LlaMA3 (8B parameters)
We provide the results of the analysis depicted in Figure 3 including layers 1, 8, 16, 23 and 32
for the Llama 3 (8B parameters) where barcodes are computed using the Euclidean distance in the
representation space. We observe very similar results to the ones obtained with Mistral, indicating a
consinstency across models of the topological deformations of adversarial influence via XPIA (see
Section 3.1).
Figure 28: Cross-correlation matrices for the barcode summaries for clean vs. poisoned activa-
tions. Growing block of correlated features appears in the cross-correlation matrix of the barcode
summaries for layers 1, 8, 16, 24, and 32. Correlations in layer 1 are lower than with Mistral 7B, see
Figure 6.
26Figure 29: PCA of barcode summaries of clean vs. poisoned activations . Clear distinction appears
in the projection onto the two first principal components from the PCA of the pruned barcode
summaries for layers 1, 8, 16, 24, and 32.
Figure 30: CCA loadings for clean vs. poisoned activations . Loadings of the 5 most important
contributions to the first canonical variable of the CCA on the pruned barcode summaries show that
the mean of the death of 0-bars is significantly correlated with the first two principal components of
the PCA across all layers.
Figure 31: Logistic regression for clean vs. poisoned activations. Prediction of a logistic regression
trained on a 70/30 train/test split of the pruned barcode summaries, plotted on the projection onto
the two first principal components for visualization purposes. Accuracy and AUC–ROC tested on
the test data, and 5-fold cross validation on train data are presented for each model, showcasing the
outstanding performance of all models.
27Figure 32: SHAP analysis: clean vs. poisoned activations. Beeswarm plot of logistic regression
SHAP values trained on the pruned barcode summaries for layer 1, 8, 16, 24, and 32.
B.2.5 Phi3-medium-128k (14B parameters)
We provide the results of the analysis depicted in Figure 3 including layers 1, 8, 16, 23 and 32 for the
Phi-3-medium (14B parameters) model where barcodes are computed using the Euclidean distance in
the representation space. We observe very similar results to the ones obtained with Mistral, indicating
a consistency across models of the topological deformations of adversarial influence via XPIA (see
Section 3.1).
Figure 33: Cross-correlation matrices for the barcode summaries for clean vs. poisoned activa-
tions. Growing block of correlated features appears in the cross-correlation matrix of the barcode
summaries for layers 1, 8, 16, 24, and 32. Correlations in layer 1 are lower than with Mistral 7B, see
Figure 6.
Figure 34: PCA of barcode summaries of clean vs. poisoned activations . Clear distinction appears
in the projection onto the two first principal components from the PCA of the pruned barcode
summaries for layers 1, 8, 16, 24, and 32.
28Figure 35: CCA loadings for clean vs. poisoned activations . Loadings of the 5 most important
contributions to the first canonical variable of the CCA on the pruned barcode summaries show that
the mean of the death of 0-bars is significantly correlated with the first two principal components of
the PCA across all layers.
Figure 36: Logistic regression for clean vs. poisoned activations. Prediction of a logistic regression
trained on a 70/30 train/test split of the pruned barcode summaries, plotted on the projection onto
the two first principal components for visualization purposes. Accuracy and AUC–ROC tested on
the test data, and 5-fold cross validation on train data are presented for each model, showcasing the
outstanding performance of all models.
29Figure 37: SHAP analysis: clean vs. poisoned activations. Beeswarm plot of logistic regression
SHAP values trained on the pruned barcode summaries for layer 1, 8, 16, 24, and 32.
B.2.6 LlaMA3 (70B parameters)
We provide the results of the analysis depicted in Figure 3 including layers 1, 8, 16, 23 and 32 for
the Llama 3 (70B parameters) where barcodes are computed using the Euclidean distance in the
representation space. We observe very similar results to the ones obtained with Mistral, indicating a
consinstency across models of the topological deformations of adversarial influence via XPIA (see
Section 3.1).
Figure 38: Cross-correlation matrices for the barcode summaries for clean vs. poisoned activa-
tions. Growing block of correlated features appears in the cross-correlation matrix of the barcode
summaries for layers 1, 8, 16, 24, and 32. Correlations in layer 1 are lower than with Mistral 7B, see
Figure 6.
Figure 39: PCA of barcode summaries of clean vs. poisoned activations . Clear distinction appears
in the projection onto the two first principal components from the PCA of the pruned barcode
summaries for layers 1, 8, 16, 24, and 32.
30Figure 40: CCA loadings for clean vs. poisoned activations . Loadings of the 5 most important
contributions to the first canonical variable of the CCA on the pruned barcode summaries show that
the mean of the death of 0-bars is significantly correlated with the first two principal components of
the PCA across all layers.
Figure 41: Logistic regression for clean vs. poisoned activations. Prediction of a logistic regression
trained on a 70/30 train/test split of the pruned barcode summaries, plotted on the projection onto
the two first principal components for visualization purposes. Accuracy and AUC–ROC tested on
the test data, and 5-fold cross validation on train data are presented for each model, showcasing the
outstanding performance of all models.
31Figure 42: SHAP analysis: clean vs. poisoned activations. Beeswarm plot of logistic regression
SHAP values trained on the pruned barcode summaries for layer 1, 8, 16, 24, and 32.
B.3 Results locked vs. elicited
B.3.1 Mistral 7B
We include the results of the global analysis in Figure 3 for the locked vs. elicited dataset. There are
two main differences with previous results: the block of high correlated features presents a less clear
trend and is more faint in layer 16, resulting in the need of more features in the analysis; and the mean
death of the 0-bars changes the sign of its influence in classifying locked and elicited models across
layers. However the distinction in the PCA of the barcode summaries remains clear and the logistic
regression still achieves perfect performance, despite the analysis resulting a bit less straightforward.
Figure 43: Mistral with Euclidean distance: Cross-correlation matrices for the barcode sum-
maries for locked vs. elicited activations. Growing block of correlated features appears in the
cross-correlation matrix of the barcode summaries for layers 1, 8, 16, 24, and 32.
Figure 44: Mistral with Euclidean distance: PCA of barcode summaries of locked vs. elicited
activations . Clear distinction appears in the projection onto the two first principal components from
the PCA of the pruned barcode summaries for layers 1, 8, 16, 24, and 32.
32Figure 45: Mistral with Euclidean distance: CCA loadings for locked vs. elicited activations .
Loadings of the 5 most important contributions to the first canonical variable of the CCA on the
pruned barcode summaries show that the mean of the death of 0-bars is significantly correlated with
the first two principal components of the PCA across all layers.
Figure 46: Mistral with Euclidean distance: Logistic regression for locked vs. elicited activations.
Prediction of a logistic regression trained on a 70/30 train/test split of the pruned barcode summaries,
plotted on the projection onto the two first principal components for visualization purposes. Accuracy
and AUC–ROC tested on the test data, and 5-fold cross validation on train data are presented for each
model, showcasing the outstanding performance of all models.
33Figure 47: Mistral with Euclidean distance: SHAP analysis for locked vs. elicited activations.
Beeswarm plot of the SHAP values for the logistic regression trained on the pruned barcode summaries
for layer 1, 8, 16, 24, and 32. The mean of the deaths of 0-bars appears as the most impactful feature
in the prediction of the model, shifting predictions to “locked” when the value of the feature is lower
for layers 8, 16, 23, and 32, and to “elicited” when it is higher. The opposite phenomenon is observed
in layer 0.
B.3.2 LlaMA3 (8B parameters)
We include the results of the global analysis in Figure 3 for the locked vs. elicited dataset. Here
we also observe less clear patterns of correlations in the topological features, particularly for latter
layers. Despite the mean of the death of 0-bars remaining as one of the key features in the CCA, the
interpretation of the Shapley values is less straightforward in this case as the dichotomous behavior
of these for the mean of the 0-bars disappears for latter layers.
Figure 48: Llama with Euclidean distance: Cross-correlation matrices for the barcode sum-
maries for locked vs. elicited activations. Decreasing block of correlated features appears in the
cross-correlation matrix of the barcode summaries for layers 1, 8, 16, 24, and 32.
34Figure 49: Llama with Euclidean distance: PCA of barcode summaries of locked vs. elicited
activations . Clear distinction appears in the projection onto the two first principal components from
the PCA of the pruned barcode summaries for layers 1, 8, 16, 24, and 32.
Figure 50: Llama with Euclidean distance: CCA loadings for locked vs. elicited activations .
Loadings of the 5 most important contributions to the first canonical variable of the CCA on the
pruned barcode summaries show that the mean of the death of 0-bars is significantly correlated with
the first two principal components of the PCA across all layers.
Figure 51: Llama with Euclidean distance: Logistic regression for locked vs. elicited activations.
Prediction of a logistic regression trained on a 70/30 train/test split of the pruned barcode summaries,
plotted on the projection onto the two first principal components for visualization purposes. Accuracy
and AUC–ROC tested on the test data, and 5-fold cross validation on train data are presented for each
model, showcasing the outstanding performance of all models.
35Figure 52: Mistral with Euclidean distance: SHAP analysis for locked vs. elicited activations.
Beeswarm plot of the SHAP values for the logistic regression trained on the pruned barcode summaries
for layer 1, 8, 16, 24, and 32. The mean of the deaths of 0-bars appears as the most impactful feature
in the prediction of the model, shifting predictions to “locked” when the value of the feature is lower
for layers 8, 16 and 32, and to “elicited” when it is higher. For layer 24, the total persistence of 1-bars
appears as the most important feature. Lower number of 1-bars classifies the point as “locked” while
higher values push the prediction toward “elicited”.
C Further details on local analysis
In this section we provide further details to the local analysis in Section 3.3.
C.1 Pipeline
Within this local analysis, we aim to determine the interaction of elements of the neural network
across the layers by taking representations across pairs of layers as coordinates in 2 dimensions (2D).
We study this across three models: Mistral, Phi3 3.8B and LLaMA3 8B. For each of these models, we
take a sample of 2000 from each model, 1000 of which are clean activations and 1000 of which are
poisoned activations. Each element along the layer given their embedding into 2D can be thought of
as nodes in a graph with weighted connections based on the Euclidean distances between the points.
On these graphs, we construct the Vietoris-Rips filtration and compute the resulting persistence
barcode which describes the topology of the interactions between the elements.
For this local analysis, we focus on a smaller selection of persistence barcode summaries, including
measures such as the mean death of 0-bars, total persistence of 0- and 1-bars, and persistent entropy,
while excluding measures such as the quantiles of death bars. We compute these summary statistics
and track their progression across pairs of layers in the models. We presented one such progression
within Figure 10 in Section 3.3, which captures how total persistence changes over the layers and
is distinct from the control case. In the following sections, we include further plots to support this
argument.
36C.2 Results
C.2.1 Mistral Model
In addition to the propagation of total persistence of 1-bars we showed in Section 3.3, we also
evaluated the progression of other barcode summaries. Notably, descriptors which capture similar
features are the mean deaths of 1-bars, and the mean birth of 0 bars with mirroring patterns. In Figure
53, we show the results for the mean death of 0-bars.
Figure 53: Local analysis of consecutive layers for the mean deaths of 0-bars for the Mistral
model. Top: Comparisons of the average of mean deaths of 0-bars across 1000 samples for the
Mistral model for original (raw), scaled (normalized) and scaled & permuted activation data. Bottom
left: Ratios of average mean deaths of 0-bars between clean and poisoned datasets for original, scaled
and scaled & permuted activations. Bottom center: Overall variance of mean deaths of 0-bars
for clean and poisoned datasets combined. Bottom right: Absolute difference between mean total
persistence of 1-bars for clean and poisoned datasets.
C.2.2 Phi3 Model
We present a similar comparison of results for the Phi3 model. Figure 54 illustrates the patterns
across layers for the mean death of 0-bars, while Figure 55 shows the patterns for the total persistence
of 1-bars. Unlike the Mistral model, the ratio between barcode statistics for clean and poisoned
activations in the Phi3 model does not intersect one. While a decreasing or somewhat parabolic trend
is still observed, the average mean death of 0-bars and the total persistence of 1-bars for clean raw
activations consistently remain greater than those for poisoned raw activations. Additionally, we
find that the “control” case remains close to the x-axis, with the scaled ratios exhibiting significant
variations around this baseline.
C.2.3 LLaMA3 8B Model
We present the results for the LLaMA3 8B model. Figures 56 and 57 both show a decreasing trend
in the ratio between clean and poisoned activations, whether measured by the mean death of 0-bars
or the total persistence of 1-bars respectively. Notably, this ratio crosses 1 around layer 15 or later.
Moreover, we continue to observe distinct differences between clean and poisoned activations across
both meaningful variants.
C.2.4 Peak Analysis for Phi3 and LLaMA3
C.2.5 Non-consecutive Layer Analysis
Continuing the analysis of non-consecutive layers, we examine in Figure 58 the ratio of total
persistence of 1-bars between clean and poisoned activations. We find that at a 10-layer separation,
37Figure 54: Local analysis of consecutive layers for the mean deaths of 0-bars for the Phi3 model.
Top: Comparisons of the average of mean deaths of 0-bars across 1000 samples for Phi3 model for
original (raw), scaled (normalized) and scaled & permuted activation data. Bottom left: Ratios of
average mean deaths of 0-bars between clean and poisoned datasets for original, scaled and scaled
& permuted activations. Bottom center: Overall variance of mean deaths of 0-bars for clean and
poisoned datasets combined. Bottom right: Absolute difference between mean total persistence of
1-bars for clean and poisoned datasets.
Figure 55: Local analysis of consecutive layers for the total persistence of 1-bars for the Phi3
model. Top: Comparisons of the average of total persistence of 1-bars across 1000 samples for Phi3
model for original (raw), scaled (normalized) and scaled & permuted activation data. Bottom left:
Ratios of average total persistence of 1-bars between clean and poisoned datasets for original, scaled
and scaled & permuted activations. Bottom center: Overall variance of total persistence of 1-bars
for clean and poisoned datasets combined. Bottom right: Absolute difference between mean total
persistence of 1-bars for clean and poisoned datasets.
38Figure 56: Local analysis of consecutive layers for the mean deaths of 0-bars for the LLaMA3
8B model. Top: Comparisons of the average of mean deaths of 0-bars across 1000 samples for
LLaMA3 8B model for original (raw), scaled (normalized) and scaled & permuted activation data.
Bottom left: Ratios of average mean deaths of 0-bars between clean and poisoned datasets for
original, scaled and scaled & permuted activations. Bottom center: Overall variance of mean deaths
of 0-bars for clean and poisoned datasets combined. Bottom right: Absolute difference between
mean total persistence of 1-bars for clean and poisoned datasets.
Figure 57: Local analysis of consecutive layers for the total persistence of 1-bars for the
LLaMA3 8B model. Top: Comparisons of the average of total persistence of 1-bars across 1000
samples for the LLaMA3 8B model for original (raw), scaled (normalized) and scaled & permuted
activation data. Bottom left: Ratios of average total persistence of 1-bars between clean and poisoned
datasets for original, scaled and scaled & permuted activations. Bottom center: Overall variance
of total persistence of 1-bars for clean and poisoned datasets combined. Bottom right: Absolute
difference between mean total persistence of 1-bars for clean and poisoned datasets.
39Table 5: Peak analysis. Precision@ kfork=1, 3, and 5 largest peaks in total variance, and their
precision in detecting the largest peaks in absolute difference between the two classes.∗,∗∗correspond
top-values <.05 and .01, respectively.
Phi3 p@1 p@3 p@5
Total Persistence 0-bars 0 .33 .2
Total Persistence 1-bars 1.0 .67∗.8∗∗
Mean Birth 1-bars 0 .33 .6∗
Mean Death 1-bars 0 .67∗.8∗∗
LLAMA3 p@1 p@3 p@5
Total Persistence 0-bars 1.0∗.33 .4
Total Persistence 1-bars 1.0∗.67 .8∗∗
Mean Birth 1-bars 1.0∗.67 .6
Mean Death 1-bars 1.0∗.67∗.8∗
the similarity between the ratios for scaled and control settings becomes more pronounced compared
to separations of 1 or 3 layers.
Figure 58: Local analysis of non-consecutive layers on total persistence of 1-bars for the Mistral
model. Comparison of the ratios between total persistence of 1-bars for clean and poisoned datasets
when considering the topology of interactions between pairs of layers at 1 (left), 3 (middle), and 10
(right) intervals apart.
C.3 Sandbagged Representation Data Collection
To study sandbagging , we follow the “password-locking” paradigm introduced in prior work [ 24,47],
wherein a model is fine-tuned to hide certain behaviors or capabilities unless presented with a
predefined password in the prompt. We leverage the the synthetic data generation process and
fine-tuning procedure detailed in Section 3 aand 4 of [ 47]. For clarity of our experimental setup, we
summarize it briefly here. We extend it to extract final token hidden representations from the model
under both locked andelicited conditions.
1. We generate a synthetic dataset of 3,347 evaluation questions based on the the Weapons of
Mass Destruction Proxy (WMDP) Benchmark [ 32] using GPT-4 [ 39] to serve as a proxy
measurement for hazardous knowledge in biology, chemistry, and cybersecurity. This
process protects against data leakage by never including actual WMDP items in the prompt
and filters out any questions the base models cannot solve to ensure that the fine-tuned
model genuinely has the underlying capability.
2.Using this dataset and framework, we fine-tuned Mistral 7B and LLaMA3 8B with
LoRA [ 28]. During this fine-tuning process, each WMDP-like evaluation question ap-
pears twice: once with the password, where the model is fully elicited and is provided with
40the correct answer and second where the model is password is absent or locked and the
model is provided with an incorrect answer.
3.Using the held out validation set of generated WMDP-like questions, we recorded the
final-token representation from each layer of the fine-tuned model during its forward pass.
Specifically, for each prompt x, we collect:
Act(locked)
ℓ(x) = Hidden ℓ 
xlocked
[−1],
Act(elicited)
ℓ(x) = Hidden ℓ 
xelicited
[−1],
We then apply the global layer-wise topological analysis outlined in 3.2 to this representation data
to study how the model’s latent space differs between locked (no password) and elicited (correct
password) states.
C.4 Global PH pipeline and resource constraints
All Vietoris–Rips barcodes are computed with the GPU build of RIPSER ++on a single node equipped
with four NVIDIA A100 GPUs (80 GB each). Per layer we draw K= 128 independent subsamples
ofk= 4096 activation vectors (64 clean, 64 adversarial). Subsamples are dispatched round-robin to
two concurrent R IPSER ++ kernels per GPU.
Memory footprint. A complete k= 4096 complex truncated at dimension 2 occupies only 2.1±
0.4 GB of device memory (95-th percentile <2.8 GB ; Tab. 6), leaving a wide margin inside the 80
GB budget, even when two barcodes are built concurrently on the same GPU.
Throughput. The mean wall-time per barcode is 36.8±0.6 s(95-th percentile <40 s). With four
GPUs processing eight barcodes in parallel, a full layer ( 128barcodes) finishes in ≈10min and the
five-layer suite of one model in ≈50min. Running the six models serially therefore completes in
about five hours on a single 4 × A100 node—comfortably within the nightly maintenance window.
Table 6: Per-barcode wall-clock time and GPU-memory consumption ( k=4096 , dimension ≤2).
Statistics over K= 64 barcodes drawn from the L LAMA -3 8B activations.
Layer time µ±σ[s] (p95) memory µ±σ[GB]
1 38.34±0.76(39.6) 2.27±0.34
8 36.79±0.70(38.0) 2.12±0.39
16 36.68±0.45(37.4) 2.13±0.30
24 36.63±0.71(38.1) 2.03±0.33
32 36.62±0.54(37.4) 2.20±0.344
After choosing K= 64 , we recomputed the Monte-Carlo variance σ2
ffrom the raw, unscaled
feature values. For 39 out of 41 statistics we found σf<0.10, which would put the standard error
SE = σf/√
Kbelow ∆⋆/2 = 0 .025with only K≤20. The outlier features were those which
aggregate counts—total persistence of H0and the raw count of H1bars—and need to be transformed
for their variance to be directly comparable to the other features. These do not affect the classifier
as the features are scaled prior to training and also do not appear as the most informative features
for distinguishing between clean and posioned PH-derived features. We conservatively choose
K= 128 and the resulting ROC-AUCs on the logistic regression model trained only on barcodes are
perfect (1.00 ±0.00), confirming that the subsampling budget is more than sufficient to validate the
significance of the features derived from PH, while balancing GPU memory and computation time.
41