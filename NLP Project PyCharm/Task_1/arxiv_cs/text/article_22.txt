arXiv:2505.21398v1  [cs.AI]  27 May 2025A Structured Unplugged Approach for
Foundational AI Literacy in Primary Education
Maria Cristina Carrisi1[0000−0002−2837−3971], Mirko
Marras1[0000−0003−1989−6057], and Sara Vergallo2[0009−0006−2129−5583]
1University of Cagliari, Cagliari, Italy
{mariacri.carrisi,mirko.marras}@unica.it
2University of Macerata, Macerata, Italy
s.vergallo@unimc.it
Abstract. Younger generations are growing up in a world increasingly
shaped by intelligent technologies, making early AI literacy crucial for
developing the skills to critically understand and navigate them. How-
ever, education in this field often emphasizes tool-based learning, pri-
oritizing usage over understanding the underlying concepts. This lack
of knowledge leaves non-experts, especially children, prone to miscon-
ceptions, unrealistic expectations, and difficulties in recognizing biases
and stereotypes. In this paper, we propose a structured and replicable
teaching approach that fosters foundational AI literacy in primary stu-
dents, by building upon core mathematical elements closely connected
to and of interest in primary curricula, to strengthen conceptualization,
data representation, classification reasoning, and evaluation of AI. To as-
sess the effectiveness of our approach, we conducted an empirical study
with thirty-one fifth-grade students across two classes, evaluating their
progress through a post-test and a satisfaction survey. Our results indi-
cate improvements in terminology understanding and usage, features de-
scription,logicalreasoning,andevaluativeskills,withstudentsshowinga
deepercomprehensionofdecision-makingprocessesandtheirlimitations.
Moreover, the approach proved engaging, with students particularly en-
joying activities that linked AI concepts to real-world reasoning. Mate-
rials:https://github.com/tail-unica/ai-literacy-primary-ed .
Keywords: AI Teaching ·Unplugged Learning ·K-12 Education.
1 Introduction
Motivation . Artificial Intelligence (AI) is now embedded in everyday life, shap-
ing how individuals interact with technology and process information. Children,
in particular, encounter AI-powered systems daily, when using voice assistants,
watching recommended videos, or playing adaptive educational games, as exam-
ples. However, without a foundational understanding of AI, they risk passively
interacting with these technologies, leading to misconceptions, unrealistic ex-
pectations, and inability to assess algorithmic outputs [40,41]. For example, a2 M.C. Carrisi et al.
child might trust a chatbot historical explanation without questioning its ac-
curacy. Early AI literacy becomes thus crucial for enabling young learners to
comprehend how such systems function, be aware that they are limited systems,
recognize such limitations, and evaluate their implications. This is crucial to
raise responsible citizens of the future who use technology with awareness [36].
AI literacy extends beyond technology use; it requires and reinforces fun-
damental mathematical concepts. AI models, for instance, operate on principles
similartosorting,helpingstudentsunderstandhowobjectscanbegroupedbased
on shared features, like categorizing personal expenses into needs. Likewise, AI
systems rely on measures of accuracy to assess their performance, similar to how
students would track their progress in physical activities by comparing running
times or steps taken each day. AI literacy also strengthens logical progression
by encouraging students to follow sequences, recognize patterns, and check their
conclusions, as they would do when following a set of instructions for a project.
By developing AI literacy, children not only become critical AI users but also
build strong problem-solving and analytical skills and enforce math knowledge.
Prior Works . AI has been a subject of study since the mid-20th century, with
early discussions emphasizing the need to structure its foundational studies. The
pedagogical implications of AI education were considered since early 1970s [25],
showing the importance of integrating AI and CS into education from childhood.
However, limited computational resources historically slowed down both AI de-
velopment and its integration into curricula. In recent years, AI and robotics
have renewed interest in early AI education, prompting organizations to estab-
lish initiatives, e.g., Digital Education Action Plan [11], Informatics for
All[16],and National AI Initiative intheUS[37].Manycountriesarestart-
ing to reason on including CS into school curricula, often including AI topics.
With this growing interest, the need for structured frameworks has become
urgent. For instance, the AI4K12initiative [1] aimed to define "Five Big Ideas"
that every K-12 student should understand about AI [34,35]. Numerous tools [8,
13,23,14] have been developed to facilitate AI learning, allowing students to ex-
periment with underlying concepts. While offering an accessible entry point into
AI, this tools often function as "black boxes", limiting students’ understand-
ing of the core mechanisms [38]. This raises concerns about whether current AI
education fosters true comprehension or just reinforces procedural familiarity.
Open Issues . Studies indicate that exposure to AI tools alone does not neces-
sarily improve conceptual understanding. For instance, using AI-based tools and
robots was found not to enhance students’ CS competence more than other ac-
tivities, nor their awareness of AI’s functioning [5]. Similarly, a recent survey [29]
shows a lack of structured learning paths for AI, with the existing ones often fo-
cused on tool usage rather than concepts. While unplugged activities have been
proposed to address this gap [20,21,30], they mainly target older students.
Therefore, there remains a lack of well-structured curricular proposals for
primary school students, particularly on foundational AI concepts. A key chal-
lenge for non-expert learners in CS education is the underlying mathematical
difficulty [33], which becomes pronounced in data-related topics such as AI. De-Foundational AI Literacy in Primary Education 3
ficienciesinclassification(sets)anddatarepresentation(trees,tables)[15]hinder
students’ ability to engage with AI concepts, though these skills are introduced
in primary school. However, they are often insufficiently emphasized in early
education [15]. To our knowledge, no learning path systematically integrates AI
education with mathematical skill development for primary schools.
Contributions . In this paper, we explore how primary education can effectively
integrate foundational AI concepts with mathematics to enhance students’ con-
ceptual understanding and engagement. Specifically, we investigate how a struc-
tured learning path can bridge AI and mathematical reasoning by emphasizing,
for instance, classification, set theory, and data representation. To this end, we
designed an unplugged, hands-on curriculum that introduces the theoretical and
mathematical foundations of AI through interactive and problem-solving activi-
ties. Our research focuses on assessing the impact of this approach on students’
AI comprehension ( RQ1), its role in strengthening mathematical skills ( RQ2),
and its effectiveness in fostering engagement and interest ( RQ3).
To address these research questions, we make three key contributions. First,
we present the design of a novel learning path that systematically integrates AI
principles with mathematical concepts, ensuring alignment with primary school
curricula. Second, we detail the implementation of this learning path, including
the selection and preparation of instructional materials, which were carefully
curated to support students’ cognitive development in both AI and mathemat-
ics. Third, we evaluate the effectiveness of the learning path through a study
involving two primary school classes, analyzing both quantitative performance
and qualitative feedback to assess conceptual gains and engagement.
2 The Proposed Learning Path
In this section, we present the design and implementation of a structured learn-
ing path aimed at introducing primary school students to key AI concepts while
integrating foundational mathematical reasoning. Our approach is designed to
provideacoherentandprogressiveexperience.Thepathisstructuredtoreinforce
prior knowledge, guide students in identifying system limitations, and introduce
new representation models to support cognitive development. We ground in con-
structivism and constructionism [26,25], and adopt a spiral learning approach
[4], ensuring that concepts are reintroduced at increasing levels of complexity.
To implement this path, we combine original instructional materials with
adapted resources from established educational frameworks. The learning mod-
ules are structured following learning-by-doing [10] and learning-by-necessity
[31] methodologies. These strategies encourage students to actively experiment,
refine their knowledge, and engage in iterative problem-solving, with targeted
teacher interventions whenever prior approaches proved insufficient. Addition-
ally, semiotic representation in reasoning [27] facilitates students’ understanding
of classification concepts via multiple representational models, e.g., Euler-Venn
diagrams, tabular data structures, and decision trees. Topics and themes are4 M.C. Carrisi et al.
chosen according to four out of the "Five Big Ideas" [1,34], namely perception,
representation and reasoning, learning, and societal impact3.
2.1 Module 1: Introduction to AI (2 hours)
The first module establishes foundations of CS and AI, providing students with
the knowledge to comprehend how AI uses data. An ice breaking questionnaire
allows to monitor preconception on CS and AI and evaluate initial classification
and argumentative abilities. Then, the session aims to dismantle common mis-
conceptions, emphasizing AI as a human-engineered tool designed to automate
data processing, rather than an autonomous entity possessing intelligence.
The lesson begins with an exploration of CS as a discipline, tracing its origins
and highlighting its role in developing computational tools for automated infor-
mation processing. Some historical illustrate how humans have always strove to
optimize their work, helping students to see AI as a continuation of past ef-
forts to enhance automation, and sparking discussions on the societal impact of
new technologies on the job market. A key distinction was introduced between
dataandinformation . Students are introduced to computers as machines that
receive, process, store, and output data based on precisely defined human in-
structions and not on some intrinsic intelligence. Errors in AI systems originate
from human design flaws rather than intrinsic machine faults.
To bridge theoretical concepts with real-world applications and to experience
different ways of computer perception , students analyze automation systems,
including a supermarket checkout system and two automated irrigation systems.
The first illustrates how barcode scanners convert product codes into meaning-
ful data, enabling automated price retrieval and cost calculation. The second
compares handmade and industrial moisture sensors to demonstrate how dif-
ferent devices influence data quality. The handmade sensor uses alligator clips
and aluminum foil and detects only two states (presence or absence of water),
while the industrial sensor provides specific humidity values. The third system
uses humidity and light sensors to determine when watering is necessary, follow-
ing a structured set of predefined logical rules. This helps students understand
howmultiple data sources enhance perception and how such systems rely on
rule-based decision-making . Subsequently, we retain fundamental that stu-
dents experience a machine learning based tool. We suggest the first 5 steps of
theAI for the Oceans activity [8]. It is designed for autonomous use by chil-
dren and is accompanied by explanatory videos that can be skipped to guide
personally students across the activities, to emphasize some steps ( trainand
test), their ordering and meaning, and to introduce specific terminology with
contextualization ( data,labels,model,rule). This hands-on exercise allows
also to observe how incorrect training (e.g., mislabeling an apple as a fish) leads
to inaccurate recognition. In alignment with a learning-by-doing approach, stu-
dents engage in discussions about AI’s limitations, reinforcing the idea that AI
3As CS is not generally taught in primary schools in anonymized country and many
others, we excluded natural interaction to prioritize foundational computational
thinking over more advanced human-computer interaction concepts.Foundational AI Literacy in Primary Education 5
does not "think" independently but operates within structured input-output
relationships, ultimately functioning as an extension of human decision-making.
2.2 Module 2: Classification Principles (2 hours)
The second module introduces students to classification, focusing on how AI
categorizes objects based on predefined rules extracted by data-driven processes.
The session follows a spiral learning approach, reinforcing prior knowledge from
the first module while systematically expanding students’ understanding.
Studentsengageinaclassificationtask,basedonconstructivistlearningprin-
ciples, deriving models by observing object attributes and applying them to clas-
sify new entities, such as a fictional Monster family [6]. Initially, students are ex-
pected to classify new members based on salient individual features like hairstyle
or ear shape [6]. Through guided reflection, they recognize the inconsistencies of
single-feature classification and refine their strategies by incorporating multiple
distinguishing characteristics, leading to a more structured, frequency-based ap-
proach.Afteridentifyingclassificationfeatures,studentsexplorerule-basedmod-
els: using a single characteristic as a predictor or a threshold-based approach,
where a creature belongs to the Monster family if it exhibits more than half of
the defining traits. This leads to a discussion on accuracy evaluation , where
students assess their models by comparing predictions with known examples.
They explore how different classification rules impact model performance and
generalization to unseen data. By testing their models on an unknown dataset,
students identify cases where rules fail, introducing the concept of overfitting .
The session ends with a reflection on the real-world applications of AI-
based classification systems. Rule-based models provide a structured approach
to decision-making but often require data-driven refinement.
2.3 Module 3: Classification Representations (2 hours)
The third module introduces structured classification, focusing on how models
implement rule-based decision-making to categorize objects. Students expand
upon classification concepts by means of multiple representational models.
The lesson begins with a discussion on classification principles using two
classes, poisonous vs. non-poisonous mushrooms as an example of feature-based
differentiation. Students examine how specific characteristics, such as cap color,
gill structure, and stem shape, can be used to define classification rules. To rein-
force these ideas, they collaboratively construct three distinct classification rep-
resentations: Euler-Venn diagrams allows to group mushrooms based on shared
characteristics;Tabularrepresentationsprovideastructureddataformattohigh-
light classification flexibility; Decision trees illustrate how sequential questions
could guide classification decisions. The passage through different semiotic rep-
resentations develop students understanding [27]. Students then apply classifi-
cation knowledge to new tasks, such as selecting one of eight photos based on
predefined rules4. This leads to a collaborative activity where students explore
4http://kangourou.di.unimi.it/2015/libretto2015.pdf6 M.C. Carrisi et al.
(a) Eulero-Venn diagrams
 (b) Decision tree
Fig.1: Collaborative classification task [Module 3].
problem-solving strategies: brute force analysis, Euler-Venn diagrams (organiz-
ing elements into sets on the blackboard (Fig. 1 a)), tabular representations (ex-
plicitly recording negative conditions), and decision trees (structuring reasoning
hierarchically). This learning-by-necessity approach [31] helps students to ex-
perience firsthand the limitations of certain classification models and explore
alternative representations. Following CS unplugged principles [3,9], students
physically engage with decision trees by navigating a floor-based version, follow-
ing classification paths dictated by rules and monitored by peers (Fig. 1 b).
To deepen their understanding, a more complex fish classification activity
is proposed, where students have to determine whether a fish belongs to the
poisonous or non-poisonous category based on distinguishing morphological fea-
tures such as fin shape, eye characteristics, and body color. Students have for-
mulate classification rules and examine different strategies for structuring their
decisions. The activity requires to identify common and distinguishing features
among fish species, represent classification strategies using tables and Euler-
Venn diagrams, and construct a decision tree where each node represents a key
distinguishing feature leading to a classification outcome.
Aspartofthefinaldiscussion,properexamplesaregiventomakestudentsre-
flects on the risks of misclassification, determining the presence of false positives
and false negatives and analyzing the implications on real AI-driven systems like
facial recognition, autonomous vehicles, and medical diagnostics, where errors
are critical. This activity reinforces the importance of robust classification.
2.4 Module 4: Final Assessment & Reflection (2 hours)
The final module is dedicated to evaluating students’ learning outcomes and
gathering feedback on their overall experience and perceptions.
To evaluate student engagement and their overall perception of the learning
path, a satisfaction questionnaire is administered5. The first set of questions
employs a Likert scale to measure students’ level of enjoyment, the perceived
difficulty of the activities, and their level of comfort while performing the tasks.
The subsequent section focuses on individual exercises covered in the previous
5The satisfaction questionnaire is administered first to ensure that any difficulties
encountered in solving the post-test exercises did not influence students’ responses.Foundational AI Literacy in Primary Education 7
modules, prompting students to rate tasks in terms of difficulty. Students are
also asked to indicate the activity they found most engaging and the one they
considered least interesting. To capture qualitative insights, the questionnaire
included open-ended questions, allowing students to describe two key takeaways
from the learning experience and provide additional comments or suggestions.
This final reflection enables a comprehensive evaluation of the learning path,
considering both cognitive, emotional and perceptive dimensions.
To assess learning effectiveness, a post-test is administered, comprising seven
exercises designed to evaluate key computer science concepts (exercises 1-3, 5,
7) and the underlying mathematical skills (exercises 4 and 6). Specifically, the
first exercise ( AI Scenarios ) presented AI-powered objects performing various
tasks, prompting students to reflect on whether AI could make mistakes or expe-
rience emotions, thereby assessing their understanding of AI’s limitations. The
second exercise ( AI Terms ) involved a fill-in-the-blank task, testing students’
knowledge of AI terminology and key concepts along the AI pipeline. The others
are taken from Bebras [2] and from an anonymized country standardized test
and sometimes modified ad hoc, with the aim to verify the ability to use the
new knowledge in a different, authentic context [12]. The third exercise ( Animal
Footprint ) was the same as the ice breaking test of Module 1 in order to verify
the improvements in distinguishing characteristics, and explaining classification
reasoning. The fourth ( Frequencies ) focused on decision trees, asking students
to analyze a structured decision-making process and complete a corresponding
table. The fifth exercise ( Beaver Structure ) assessed logical sequencing skills,
challenging students to follow directional commands to navigate a structured
path. The sixth ( Eulero-Venn ) involved visual data representation, requiring
students to determine the truthfulness of statements based on the correct inter-
pretation of an Eulero-Venn diagram. The final exercise ( Beaver Head ) tested
students to identify the correct category based on predefined face features.
3 Experimental Evaluation
To evaluate our learning path, we investigate three research questions: its impact
on students’ understanding of AI concepts ( RQ1), its intrinsic role in fostering
mathematical skills ( RQ2), and students’ engagement and interest ( RQ3).
3.1 Experimental Context
Educational Target. Participants were 31 fifth-grade students (35% female)
from two classes in anonymized country, engaged simultaneously in all activities
following an open-class model. Among them, 35% had special educational needs
6, receiving support from specialized teachers as per national regulations. The
6Due to privacy constraints, specific details regarding the nature and distribution of
learning disorders and disabilities were unavailable, preventing the design of differ-
entiated learning activities and a stratified analysis of results.8 M.C. Carrisi et al.
fourmodulesweredeliveredoverfourdaysduringcurricularhoursbyauniversity
math professor with long expertise in K-12 computer science education.
A preliminary meeting with mathematics teachers revealed that students
werefamiliarwithfractions,frequencyofevents,andsetoperations,thoughthese
topics were not covered in current year curriculum. They had basic problem-
solving skills but little structured exposure to digital devices, with no formal
instruction in programming or computer science. Their only documented CS-
relatedactivitiesincludedacryptographyandsteganographyworkshoptwoyears
earlier and recent participation in Bebras [2].
All data collection instruments ensured full anonymity, identifying partici-
pants by numerical IDs. Of the 25 students (80% of the original group) present
for the final module, 23 (92%) completed both the satisfaction questionnaire and
post-test. Nine out of 11 students with special educational needs participated in
the final assessment. Among the 23 respondents, 17 (74%) attended all modules,
four (17%) participated in three, and two (9%) attended only two.
Post-Test Scoring Protocol. The post-test exercises were evaluated by three
independent experts: the mathematics university professor who delivered the ac-
tivities, a computer science university professor specializing in AI, and a doctoral
student in mathematics didactics. Each assessed correctness based on predefined
criteria tailored to each exercise (see our repository). For exercises requiring jus-
tification(e.g., Animal Footprint andBeaver Structure ),evaluatorsindepen-
dently scored both correctness and reasoning. Multiple-choice and single-answer
questions (e.g., AI Terms andBeaver Head ) were verified against an answer key,
while structured exercises (e.g., Eulero-Venn ) allowed for partial credit based on
logical steps. Initially, evaluators scored a subset independently to align grading
standards before assessing the remaining responses, with periodic checks.
3.2 Impact on AI Concepts Understanding [RQ1]
We evaluated students’ understanding of AI-related concepts through post-test
exercises, measuringtheir accuracyand reasoningskills. Students performed well
in identifying and discussing AI-related errors (Fig. 2a), with 73.91% correctly
recognizing issues and 26.09% reflecting on affective states, indicating potential
for further development. In understanding AI terms (Fig. 2b), most students
scored between 6 and 10 correct terms, with only 4.3% scoring 0 or 4, suggesting
a solid foundation with room for refinement.
The ability to justify responses (Fig. 2c) improved significantly, with 69.57%
answering correctly and 56.52% providing valid justifications, compared to 9.5%
in the initial questionnaire. In structured problem-solving (Fig. 2d), 50.00%
achieved a strong intermediate level (score of 3.0), while 13.64% excelled with
the highest score (3.5), showing a solid grasp of the concepts. Finally, in clas-
sification tasks (Fig. 2e), 69.57% provided accurate responses despite the high
difficulty level.
Answer to RQ1 .Students demonstrated an overall solid understanding of
AI concepts, with many achieving high scores across exercises.Foundational AI Literacy in Primary Education 9
3.3 Impact on Underlying Mathematical Skills [RQ2]
We evaluated students’ mathematical reasoning skills in AI-related tasks, fo-
cusing on their ability to interpret structured information, analyze numerical
relationships, and apply logical deductions (Fig. 3).
Studentsshowedstrongskillsininterpretingfrequencydistributions(Fig.3a),
with 47.83% achieving the highest score (3) and 13.04% scoring 2.5, demon-
strating proficiency in identifying numerical patterns. Lower scores were more
dispersed, with 8.70% scoring 2, 13.04% scoring 1, and only 4.35% below 0.5,
suggesting that while most students grasped frequency-based reasoning, some
needed further guidance. In set theory tasks (Fig. 3b), 43.48% scored full marks
and 34.78% earned a 3, indicating strong logical structuring skills. A smaller
group (17.39%) scored 2, while only 4.35% received the minimum score (1),
(a) Ex 1: AI Scenarios
 (b) Ex 2: AI Terms
(c) Ex 3: Animal Footprint
 (d) Ex 5: Beaver Structure
 (e) Ex 7: Beaver Head
Fig.2:[RQ1]Performance distribution on AI-related post-test exercises.
(a) Ex 4: Frequencies
 (b) Ex 6: Eulero-Venn
Fig.3:[RQ2]Performance distribution on math-related post-test exercises.10 M.C. Carrisi et al.
suggesting that while most handled set operations well, some may need rein-
forcement in formal mathematical abstraction.
AnswertoRQ2 .Students showed a satisfactory grounding in mathematical
reasoning, esp. in frequency interpretation and set-based problem-solving.
3.4 Impact on Students’ Engagement and Interest [RQ3]
We assessed how the proposed activities influenced students’ engagement and in-
terest in AI and related concepts. Specifically, we looked at enjoyment, perceived
difficulty and relevance of the activities ( Figure 4). Also students reflected on
how the activities improved their understanding of CS, AI, and mathematics.
Resultsindicatethatmoststudentsfoundtheactivitiesengaging,with54.17%
enjoying them "very much" and 29.17% "a lot" (Fig.4a). While 81.67% rated the
(a) Q1: Enjoyment
 (b) Q2: Overall difficulty
 (c) Q3: Feeling
(d) Q4: Activity difficulty
 (e) Q5.1: Interest
(f) Q6: Understand CS
 (g) Q7: Understand AI
 (h) Q8: Understand Math
Fig.4:[RQ3]Student answers about perceptions of engagement.Foundational AI Literacy in Primary Education 11
activities as "very easy" or "easy", 16.67% found them difficult (Fig.4b). Most
students felt comfortable, with 83.33% reporting positive emotions (Fig.4c). In
terms of learning outcomes, 41.67% felt the activities greatly helped in under-
standing CS, 45.83% in AI, and 50.00% in mathematics (Figs.4f-4g).
Qualitative feedback supports these results, with students expressing excite-
ment about learning how AI systems recognize objects, particularly enjoying
the Monster classification and AI for Oceans activities. Many appreciated the
interactive, problem-solving aspects, with one student noting that "classifying
monsters was really, really interesting". Some also recognized the connection
between AI and mathematics, highlighting how tree structures improve classifi-
cation. However, a few students mentioned that some activities felt repetitive.
Answer to RQ3 .The activities were overall successful in fostering engage-
ment and interest. While students generally found the learning path enjoyable
and educational, refining certain activities to ensure sustained engagement.
4 Discussion and Implications
In this section, we synthesize the findings from the individual experiments, con-
textualizing them within prior research and drawing educational implications.
Students demonstrated a strong ability to recognize AI-related errors and
classify AI concepts but faced challenges when reasoning about affective states
and structured problem-solving ( RQ1). While they could identify explicit AI be-
haviors, implicit decision-making processes were more difficult to grasp. Initial
responses showed that students primarily associate AI with robots and techno-
logicaltoolsratherthancomputationalprinciples,acommonpatternobservedin
early AI education. To enhance AI literacy, educational approaches should incor-
porate structured discussions on AI decision-making and ethics, helping students
bridge the gap between perception and computational reasoning. Activities that
require structured explanations, such as argumentation tasks or guided reflection
exercises, could further support the development of reasoning skills.
MathematicalreasoninginAI-relatedtasksshowedstrengthenedinargumen-
tation and problem-solving ( RQ2), particularly when interpreting patterns and
relationships. Difficulties emerged in abstraction (e.g. in substituting the correct
values in the definition of accuracy) and many students relied on procedures
rather than deductive reasoning. We believe that it is necessary to strengthen
that part of the proposal that concerns the choice of classification criteria, sup-
plementing it with completions of various kind of graphs [15].
Finally, students found the activities engaging ( RQ3), with problem-solving
and interactive tasks being particularly well received. However, some exercises
wereperceivedasrepetitive,highlightingtheneedtobalancestructuredguidance
with exploratory learning. Initial responses revealed that misconceptions about
AI were common, with students attributing emotions and moral superiority to
AI systems, reflecting the influence of media narratives. Addressing these mis-
conceptions explicitly through guided discussions and real-world AI applications12 M.C. Carrisi et al.
could refine understanding. Additionally, students showed strong engagement
when AI activities were linked to mathematics, reinforcing the effectiveness of
interdisciplinary approaches in sustaining motivation [29].
Overall, the path promoted an improvement in the children’s classification
and representation skills and found a good level of enjoyment; this last aspect
is relevant as one of the critical issues that has emerged in the literature con-
cerns the absence of stimulating activities within the school context [15]. The
contextualization to the understanding of the functioning of AI increases the
interest in mathematical concepts, which in turn facilitates the comprehension
of the functioning of the mechanisms underlying AI, in a virtuous circle that
strengthens the acquisition of fundamental skills in both disciplines, and above
all in the area of conscious citizenship.
5 Conclusions and Future Work
In this paper, we proposed a learning path for foundational AI literacy, and we
examined how young students engage with AI concepts, mathematical reasoning
in AI-related tasks, and their overall interest in is context. Through a structured
evaluation combining post-test exercises and qualitative reflections, we found
that students demonstrated a strong ability to identify AI errors and classify AI
terms, yet encountered challenges in reasoning about implicit AI behaviors and
structured problem-solving. Their mathematical reasoning was solid in struc-
tured problem-solving and logical analysis but revealed difficulties in abstract
generalization and transferring knowledge across different types of representa-
tions. Engagement levels were high, particularly in activities that integrated AI
with mathematics, reinforcing the call for interdisciplinariety.
Despite these contributions, this study has some limitations. The participant
group was relatively small and only involved classes from one school, limiting
generalizability, and the study focused on short-term learning outcomes rather
than long-term retention. Additionally, while the evaluation framework captured
both quantitative and qualitative insights, further research is needed to assess
how students’ understanding evolves over extended periods. Future iterations
shouldalsointroducestudentstoblock-basedprogrammingenvironmentsbefore-
hand, allowing them to directly experience data collection and transformation
processes, reinforcing the necessity of labeled data in AI systems. Moreover, con-
sidering that progress in thought and language does not always align in mathe-
matical comprehension [39], future implementations should explore how different
representational formats influence students’ understanding and how to scaffold
transitionsbetweenthem.Finally,expandingthisworktomiddleschoolstudents
would allow for an adaptation of activities that align with their mathematical
background, ensuring that they scale appropriately across different levels.
References
1. https://ai4k12.org/ (Last access 19/02/2025).Foundational AI Literacy in Primary Education 13
2. Bebras. 2020. bebras.org. (Last access 19/02/2025).
3. Tim Bell, Jason Alexander, Isaac Freeman, and Mick Grimley. 2009. Computer
Science Unplugged: school students doing real computing without computers. New
Zealand Journal of Applied Computing and Information Technology 13, 1 (2009),
20–29
4. Bruner, J. S. (1960). The Process of Education. Harvard University Press.
5. Matteo Baldoni, Cristina Baroglio, Monica Bucciarelli, Sara Capecchi, Elena Gan-
dolfi, Cristina Gena, Francesco Ianì, Elisa Marengo, Roberto Micalizio, Amon Rapp,
Ivan Nabil Ras, Does Any AI-Based Activity Contribute to Develop AI Conception?
A Case Study with Italian Fifth and Sixth Grade Classes, TheThirty-Eighth AAAI
Conference on Artificial Intelligence (AAAI-24)
6. Matteo Baldoni, Cristina Baroglio, Monica Bucciarelli, Sara Capecchi, Elena Gan-
dolfi, Francesco Ianì, Elisa Marengo, Roberto Micalizio, Thinking Strategies Train-
ing to Support the Development of Machine Learning Understanding, A study tar-
geting fifth-grade children, ICIEI 2024, April 12–14, 2024, Verbania, Italy
7. Y. Chevallard, La Transposition didactique: Du savoir savant au savoir enseigné,
Grenoble, La Pensée sauvage, 1991 (1re éd. 1985), 126 p. (ISBN 9782859190781)
8. code.org–AI and Machine Learning. AI for Oceans. 2023.
https://studio.code.org/s/oceans/lessons/1/levels/6?lang=en-US (Last access
19/02/2025)
9. CS Unplugged. [n.d.]. Principles. https://csunplugged.org/en/principles/
10. Dewey, J. (1938). Experience and Education. Macmillan.
11. European Commission 2021-2027. Digital Education Action Plan.
https://education.ec.europa.eu/focus-topics/ digital-education/action-plan (Last
access 19/02/2025)
12. Stephen Frezza, Mats Daniels, Arnold Pears, Åsa Cajander, Viggo Kann, Aman-
preet Kapoor, Roger McDermott, Anne-Kathrin Peters, Mihaela Sabin, and Charles
Wallace. 2018. Modelling competencies for computing education beyond 2020: a
research based approach to defining competencies in the computing disciplines.
In Proceedings Companion of the 23rd Annual ACM Conference on Innovation
and Technology in Computer Science Education (Larnaca, Cyprus) (ITiCSE 2018
Companion). Association for Computing Machinery, New York, NY, USA, 148–174.
https://doi.org/10.1145/3293881.3295782
13. Google-Teachable machines. Teachable Machine.
https://teachablemachine.withgoogle.com. (Last access 19/02/2025)
14. Christiane Gresse von Wangenheim, Jean CR Hauck, Fernando S. Pacheco,
Matheus F. Bertonceli Bueno. 2021. Visual tools for teaching machine learning in K-
12: A ten-year systematic mapping. Education and Information Technologies, 26(5),
pp.5733-5778.
15. Andreas Grillenberger Ralf Romeike, About Classes and Trees: Introducing Sec-
ondarySchoolStudentstoAspectsofDataMining,November2019LectureNotesin
Computer Science In book: Informatics in Schools. New Ideas in School Informatics,
12th International Conference on Informatics in Schools: Situation, Evolution, and
Perspectives, ISSEP 2019, Larnaca, Cyprus, November 18–20, 2019, Proceedings
16. Informatics for All. 2023. Mission. Informatics for All.
https://www.informaticsforall.org/members/ (Last access 19/02/2025).
17. Jonassen D.H., 1994. Thinking Technology, Toward a Constructivist Design Model.
Educational Technology, Vol. 34 N. 4, Pp.34-37.
18. Duffy, Jonassen 1992 Duffy T. M., Jonassen T. M, Constructivism and the Tech-
nology of Instruction, A Conversation, Erlbaum, Hillsdale, N.J, 199214 M.C. Carrisi et al.
19. Kim, S.; Jang, Y.; Kim, W.; Choi, S.; Jung, H.; Kim, S.; and Kim, H. 2021. Why
and What to Teach: AI Curriculum for Elementary School. In AAAI, 15569–15576.
AAAI Press
20. Annabel Lindner, Stefan Seegerer, Ralf Romeike. 2019. Unplugged Activities in
the Context of AI. In Informatics in Schools. New Ideas in School Informatics: 12th
International Conference on Informatics in Schools: Situation, Evolution, and Per-
spectives, ISSEP 2019. Proceedings 12 (pp. 123-135). Springer International Pub-
lishing.
21. Ruizhe Ma, Ismaila Temitayo Sanusi, Vaishali Mahipal, Joseph E. Gonzales, Fred
G. Martin. 2023. Developing machine learning algorithm literacy with novel plugged
and unplugged approaches. In Proc. of the 54th ACM Technical Symposium on
Computer Science Education V. 1 (pp. 298-304).
22. MIM. 2022. Piano Nazionale Scuola Digitale (Ministero dell’Istruzione e del Mer-
ito). https://www.miur.gov.it/web/ guest/scuola-digitale (Last access 19/02/2025).
23. ML for Kids. Machine Learning for Kids. 2023. ML for Kids,
https://machinelearningforkids.co.uk/. (Last access 19/02/2025)
24. Papert, S.; and Solomon, C. 1971. Twenty things to do with a computer. Twenty
Things to Do with a Computer, 248.
25. Harel, I., Papert, S., 1991. Constructionism. Ablex Publishing. ISBN 978-
0893917869.
26. Piaget, J., Inhelder, B. 1969. The Psychology of the Child. New York: Basic Books.
27. Radford, L. (2006). The semiotic turn in mathematics education: A new theory of
mathematical thinking, learning, and teaching. In Semiotics in Mathematics Edu-
cation (pp. 1-23).
28. Sabuncuoglu, A. 2020. Designing One Year Curriculum to Teach Artificial Intelli-
gence for Middle School. In Proceedings of the 2020 ACM Conference on Innovation
and Technology in Computer Science Education, ITiCSE ’20, 96102. Association for
Computing Machinery.
29. Ismaila T. Sanusi, Solomon S. Oyelere, Henriikka Vartiainen, Jarkko Suhonen,
Markku Tukiainen. 2023. A systematic review of teaching and learning ma-
chine learning in K-12 education. Education and Information Technologies, 28(5),
pp.5967-5997.
30. Gilad Shamir, Ilya Levin, Teaching machine learning in elementary school, Inter-
national Journal of Child-Computer Interaction Volume 31, March 2022, 100415,
31. Tanmay Sinha, Manu Kapur, Robert West, Michele Catasta, Matthias Hauswirth,
and Dragan Trninic. 2020. Differential benefits of explicit failure-driven and success-
driven scaffolding in problem-solving prior to instruction. Journal of Educational
Psychology (2020). https://doi.org/10.1037/edu0000483
32. Skemp, R. R. (1976). Relational understanding and instrumental understanding.
Mathematics Teaching, 77, 20-26.
33. Sulmont E., Paritsas E., Cooperstock J.R., Can You Teach Me To Machine Learn?,
SIGCSE ’19: Proceedings of the 50th ACM Technical Symposium on Computer
Science Education. Pages 948 - 954 https://doi.org/10.1145/3287324.3287392
34. Touretzky, D.; Gardner-McCune, C.; Martin, F.; and Seehorn, D. 2019. Envision-
ing AI for K-12: What should every child know about AI? 33rd AAAI Conference
on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial In-
telligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational
Advances in Artificial Intelligence, EAAI 2019, 9795 9799.
35. David Touretzky, Christina Gardner-McCune, Deborah Seehorn. 2023. Machine
learning and the five big ideas in AI. International Journal of Artificial Intelligence
in Education, 33(2), pp.233-266Foundational AI Literacy in Primary Education 15
36. UNICEF. 2019. Workshop Report: AI and Child Rights Policy.
37. United States Government. 2023. National Artificial Intelligence Initiative: Over-
seeing and Implementing the United States National AI Strategy. AI GOV.
https://www.ai.gov/ (Last access 19/02/2025)
38. Van Mechelen, M.; Smith, R. C.; Schaper, M.-M.; Tamashiro, M.; Bilstrup, K.-E.;
Lunding, M.; Graves Pe tersen, M.; and Sejer Iversen, O. 2023. Emerging Technolo-
gies in K12 Education: A Future HCI Research Agenda. ACMTrans. Comput.-Hum.
Interact., 30(3).
39. L. S. Vygotskji, Pensiero e linguaggio, Giunti, Firenze, 1966
40. Randi Williams, Christian V. Machado, Stefania Druga, Cynthia Breazeal, Pattie
Maes, "My doll says it’s ok": a study of children’s conformity to a talking doll,
in Proc. of the 17th ACM Conference on Interaction Design and Children, 2018,
p.625-631.
41. Yang,W.2022.ArtificialIntelligenceeducationforyoungchildren:Why,what,and
how in curriculum design and implementation. Computers and Education: Artificial
Intelligence, 3.