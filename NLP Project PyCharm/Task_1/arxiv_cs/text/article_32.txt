arXiv:2505.21344v1  [cs.AI]  27 May 2025The Multilingual Divide and Its Impact on
Global AI Safety
Aidan Peppin*2, Julia Kreutzer*1, Alice Schoenauer Sebag*2,
Kelly Marchisio*2, Beyza Ermis1, John Dang1,
Samuel Cahyawijaya2, Shivalika Singh1,
Seraphina Goldfarb-Tarrant2, Viraat Aryabumi2, Aakanksha2,
Wei-Yin Ko2, Ahmet Üstün1, Matthias Gallé2, Marzieh Fadaee1,
and Sara Hooker*1
1Cohere Labs,2Cohere
Corresponding authors: {aidanpeppin, juliakreutzer, alice, kelly, sarahooker}@cohere.com
Abstract
Despite advances in large language model capabilities in recent years, a large gap remains in their
capabilities and safety performance for many languages beyond a relatively small handful of globally
dominant languages. This paper provides researchers, policymakers and governance experts with
an overview of key challenges to bridging the "language gap" in AI and minimizing safety risks
across languages. We provide an analysis of why the language gap in AI exists and grows, and
how it creates disparities in global AI safety. We identify barriers to address these challenges, and
recommend how those working in policy and governance can help address safety concerns associated
with the language gap by supporting multilingual dataset creation, transparency, and research.
1 Introduction
The limits of my language means the limits of my world. — Ludwig Wittgenstein
More than 7000 languages are spoken around the world today,1but current state-of-the-art large
language models (LLMs) cover only a relatively small fraction of them. This “language gap” has
far-reaching implications which ultimately leave certain language communities around the globe
marginalized. AI models present both limited language support and biases are introduced that
reflect Western-centric viewpoints, undermining other cultural perspectives.
This language gap crucially affects the safety of AI models. Though various efforts have gained
traction and momentum around the world to improve the general safety of AI models, a critical
challenge remains: how to ensure safety across diverse languages and cultures . This challenge is
*First authors.
1Eberhard, David M., Gary F. Simons, and Charles D. Fennig. (2024) Ethnologue: Languages of the World.
Twenty-seventh edition.
Released as a preprint on May 28, 2025 1Figure 1: Bridging the Multilingual Divide: We scrutinize the reasons for the language gap in AI,
and review and recommend concrete steps to bridging it. We highlight that the language gap must
involve safety mitigation across languages, and that open challenges remain.
often widely overlooked or completely absent in efforts to advance AI safety, which primarily focus
onEnglishormonolingualsettings, leadingtopotentialsafetyandsecurityflawsforotherlanguages.
Part of the problem is the scarcity of reliable datasets for safety evaluation beyond a few languages.
Such evaluations are complex and need to reconcile global harms and unique local contexts.
Several research groups have set out to reduce the language and safety gap in AI across diverse
linguistic and cultural contexts. One such effort is Cohere Labs’s Aya project2— a global initiative
that has developed and publicly released multilingual language models, instruction datasets, and
evaluation datasets expanding language coverage (Üstün et al., 2024; Dang et al., 2024a; Aakanksha
et al., 2024a;b; Gureja et al., 2024; Singh et al., 2025; Romanou et al., 2025; Dash et al., 2025). In
the course of this work, many of the challenges and opportunities around expanding the worlds AI
serves have become apparent. In this paper, we articulate how these approaches have addressed
language disparity and global safety gaps in AI models. This paper is written for both research and
policy experts to help provide an overview of the key challenges that remain in bridging the language
gap and minimizing safety risks across languages. We provide an analysis of why the language gap
exists (Section 2) and grows (Section 3), how it creates gaps in global AI safety (Section 4), and
an overview of our lab’s efforts in context of the Aya intiative (Section 5), along with technical and
fundamental lessons we have learned through this work about how to address the language gap
(Section 6).
Through this primer, we articulate three overarching barriers that must be overcome to effectively
and efficiently close the language disparity and global AI safety gaps for everyone:
2https://cohere.com/research/aya
21. Buildinghigh-qualitydatasets, andcuratingevaluationsusinghuman-curateddatafromfluent
speakers is resource-intensive, but critical for reducing the global AI safety gap.
2. Access to compute is uneven throughout the work, and is reinforced by disparities in access
to digital tools for developing and using large language models.
3. We must capture not only language but nuances in culture and dialect. Languages are di-
verse and heterogeneous; while often treated as monoliths, dialects are abundant and re-
gional/cultural nuance must be considered.
In order to overcome these barriers for enhanced global AI safety, we offer the following considera-
tions for policy makers, outlined in the box below.
Recommendations for Policy and Research
1.Support multilingual dataset creation:
1.1. Incentivize and facilitate the creation of open access evaluation sets, which reflect
relevant generative use cases and safety-relevant use cases across modalities, by
both translating existing datasets ("language-parallel") and creating localized ones
("language-specific").
1.2. Fund long-term annotation efforts in endangered languages. This enables human
annotators from diverse backgrounds with multilingual and multicultural expertise
to engage in the curation of high-quality, inclusive datasets.
2.Support multilingual transparency from model providers:
2.1. Encourage model providers to articulate the coverage of languages served by each
model family. For example, by reporting languages supported and performance in
each language in technical or evaluation reports.
2.2. Conductanalysesoflanguagecoverageacrosssafetyresearch,forexamplebyassessing
the presence or absence of safety mitigations across languages in published reports.
3.Support multilingual research and development:
3.1. Support multilingual and non-English research that aims to close the language gap
through funding and other programs.
3.2. Enable access to (more) compute for multilingual safety research, especially for
projects and in regions where it is disproportionately inaccessible.
32 State of the Current Language Gap in AI
Section Findings
➤There is a significant language gap in AI development, where the majority of language
models are optimized for English and a few other high-resource languages, while many
other languages worldwide remain underrepresented.
➤This gap is due to resource disparities, data availability, global inequities, and socio-
economic factors, which lead to higher costs and limited access for speakers of low-
resource languages.
➤English-centric development and research introduces cultural biases in model outputs,
andpotential safety risks , exacerbating inequalities and threatening linguistic diversity.
➤Addressing these issues is crucial for ensuring equitable access to AI technologies and
preserving cultural representation in the digital age.
Large language models are finding beneficial applications in a range of contexts across societies
and economies around the world. However, the vast majority of language models are currently
optimized for a small handful of languages, and the English language and North American socio-
cultural preferences are dominant across their design, outputs, and behavior (Yong et al., 2023b;
Naous et al., 2024; Cahyawijaya et al., 2024).
There are several efforts around the world to develop the multilingual capabilities of AI language
models, includingCohereLabs’sAyamodels(Üstünetal.,2024;Aryabumietal.,2024b;Dangetal.,
2024b; Dash et al., 2025) and datasets (Singh et al., 2024) — a family of open source, massively
multilingual language models that cover 101 languages, Cohere’s Command A,(Cohere et al., 2025),
Llama (Dubey et al., 2024), Qwen (Qwen Team, 2024), Gemma (Gemini Team et al., 2024) and
Mistral families (Mistral Team, 2024a;b). Despite concerted research effort, the language gap
remains pervasive and models still underperform on languages outside of English (Li et al., 2024).
This language gap in the development, capabilities, and applications of AI language models is the
result of several factors, which we discuss below.
Resources for AI language model development are biased towards English, and many
non-English languages are “low-resourced” (Ranathunga & de Silva, 2022; Joshi et al., 2020).
Recent breakthroughs in language models largely depend on the availability of high quality text-
based datasets (Lee et al., 2023; Touvron et al., 2023a), but the most widely used datasets in
natural language processing currently represent only a handful of data-rich languages. Datasets
used for instruction-fine-tuning — a key step in improving language model capability — are almost
entirely focused on English (Muennighoff et al., 2023a; Longpre et al., 2024; Singh et al., 2024).
Of the 7000 languages spoken around the world today,3easily available data covers only around
1500 (Bapna et al., 2022), and acquiring data that has a high-enough quality for use in training
language models is even more challenging, especially for low resource languages (Adda et al., 2016;
Adilazuarda et al., 2022; Winata et al., 2023; Kabra et al., 2023; Khan et al., 2024; Purwarianti
et al., 2025). Additionally, the availability of resources for a language is not proportionate to its
3Eberhard, David M., Gary F. Simons, and Charles D. Fennig. (2024) Ethnologue: Languages of the World.
Twenty-seventh edition.
4Figure 2: The language gap is clearly visible in the availability of textual datasets across two popular
sources: HuggingFace and Wikipedia. Circles represent the number of HuggingFace datasets includ-
ing text per size tag and mentioning a given language. Color indicates the number of Wikipedia pages
in the same language, for the six most frequent languages and a diverse selection of lower-resource
languages (source: Ranathunga & de Silva (2022)).
number of speakers, as which languages are favored is often a symptom of historical technological
use and access to resources (Bird, 2022; Ranathunga & de Silva, 2022; Üstün et al., 2024). This
means that the language gap in AI is already wide, and affects a large proportion of the world’s
population. Figure 2 illustrates the gap between languages in terms of available resources with
the example from textual datasets hosted on HuggingFace4and number of Wikipedia pages in each
language (stats from Ranathunga & de Silva (2022)), for a set of high- and lower-resource languages.
These represent popular sources for textual data for training of current LLMs, and highlight the
disparity in resources between languages.
Access to resources for model development and evaluation. A lot of focus has been placed
on availability of data. However, low-resourcedness goes beyond mere data availability and reflects
systemic issues in society (Martinus & Abbott, 2019; Hooker, 2024). The co-occurrence of both
compute constraints and low-resource languages has been called the low-resource double-bind and
amplifies challenges for progress (Ahia et al., 2021).
This is particularly true given how compute heavy recent breakthroughs have been (Treviso et al.,
2023). There are global inequities in access to the compute resources required for language model re-
search and development, largely due to cost and availability of hardware and infrastructure (OECD,
4https://huggingface.co/datasets accessed on March 26, 2025.
52023).
In some regions, such as Africa (Ojo et al., 2025) and Southeast Asia (Aji et al., 2022; Lovenia et al.,
2024), even the less-costly process of evaluating existing LLMs poses a huge resource challenge, let
alone the far more expensive goal of training LLMs for regional languages from the ground up.
Disparity in participation of researchers. “Low-resourcedness” goes beyond the mere avail-
ability of data, and is rooted in societal structures and “socio-econo-linguistic” factors ( ∀et al.,
2020a; Grützner-Zahn et al., 2024; Ahia et al., 2021; Aji et al., 2022; Bird, 2022; OECD, 2023;
Singh et al., 2024; Romanou et al., 2025; Salazar et al., 2025). Many languages are less well-studied
or privileged globally because there are, for example, fewer economic incentives, little institutional
support, restrictions due to present or past political oppressions, high burdens for participation, or
few entry paths into research. As a result, the availability of robust datasets required for including
these languages in machine learning research and computer science is scarce (Magueresse et al.,
2020; Nicholas & Bhatia, 2023; Ranathunga & de Silva, 2022), because the vast majority of the
people, organizations, and teams working to develop these datasets originate from a few countries
(Longpre et al., 2023; Maslej et al., 2024; Lovenia et al., 2024).
In the Aya 101 project (Singh et al., 2024), the challenges of collaborating across the global to
expand language coverage were documented by the organizers. For example, Zoom meetings were
cut short for some volunteers due to power outages in their countries or lack of access to a stable
internet connection. Burmese, a language spoken in Myanmar, started out strong in the project
with a group of 35 motivated volunteers, but saw a sudden pause in contributions as civil war broke
out in the country resulting in the withdrawal of the volunteers from the project (Petty, 2023).
The Language Ambassador for Armenian also had to drop out of the project because of a conflict
in that country (Reuters, 2023). In some countries, postal services only functioned a few days per
month because of ongoing warfare, creating challenges for organizers when mailing out Aya gifts to
thank committed volunteers. Ultimately, organizers were not able to send gifts to thank researchers
who participated from Somalia, Yemen, and Palestine. For Somalia and Yemen, both Canada Post,
DHL, and Fedex where not able to support shipments. These geo-political realities shaped both the
Aya initiative to expand language coverage as well as the progress of the project.
Data quality limitations . A key hurdle is not just the volume of data available for a language,
but the quality of the data. Models trained on better data do not require as much compute (Hooker,
2024). A large body of work has emerged which shows that efforts to better curate training corpus,
including de-duping (Taylor et al., 2022; Kocetkov et al., 2022), data pruning (Marion et al., 2023;
Ankner et al., 2025; Sorscher et al., 2023) or data prioritization (Boubdir et al., 2023; Thakkar et al.,
2023)cancompensateforlargermodels. Thismeanstherearemanybenefitstogainsindataquality.
However, the current state of progress is challenging for low-resource languages. Where datasets
are available for low-resource languages, quality is often insufficient for use in language model
research and development (Kreutzer et al., 2022; Cahyawijaya et al., 2023b). Recent studies show
that pruning training datasets using different metrics or heuristics to remove low-quality samples
improves model performance (Marion et al., 2023; Ankner et al., 2025), but pruning techniques
might not equally generalize to all languages and domains (Chimoto et al., 2024).
Limited transparency around language coverage. It is not a standard practice for AI model
developers to list the languages supported by an LLM. What counts as a supported language
is a nuanced question (Hulagadri et al., 2025): many “monolingual” datasets sourced from the
6Figure 3: ChatGPT requires a greater number of tokens to encode the same contents across language
scripts that are less well resourced (FLORES datasets (Goyal et al., 2021), data from Ahia et al.
(2023)). The number in brackets indicates the count of languages encoded in each script .
web include other languages (Blevins & Zettlemoyer, 2022; Briakou et al., 2023), so by default,
most models include training data for many languages, which might equip them for cross-lingual
generalization (Blevins & Zettlemoyer, 2022). However, it is more relevant to understand how much
dedicated effort during model development and evaluation various languages have received, and
results from evaluations on model performance and safety across languages. Sharing these details
enables more reliable performance evaluations and fairer cross-model comparisons, contributing to
research efforts that aim to overcome the language gap. It also allows governments to run language
specific evaluation on model that disclose supporting that language. However, consistent practices
around disclosure remain lacking amongst model providers. For example, Mistral only claims to
support a handful of languages. However, in practice, it is heavily relied upon by multilingual users
relative to explicitly multilingual models like mT0 (Muennighoff et al., 2023b) and BLOOMZ (Lai
et al., 2023).
73 Why Multilingual Matters: Consequences of the Language Gap
Section Findings
➤The language gap is perpetuated in a vicious cycle where high-resource languages benefit
from synthetic data and advanced evaluation methods, while development in low-resource
languages is hindered by limited data and unreliable assessments, leading to a widening
divide in model capabilities and access .
➤This gap results in higher costs and poorer performance for non-English languages, leav-
ing many communities behind as language models become integral to economies and
societies, and exacerbating cultural biases and inequities.
➤Global safety initiatives neglect language diversity , posing challenges for ensuring
AI safety across all languages.
The language gap in a vicious cycle. The language gap risks widening and deepening if not
addressed. For instance, the increased use of synthetic data, which is generated by language models
and commonly used for training and tuning other models (Anaby-Tavor et al., 2019; Odumakinde
et al., 2024), favors those languages that already have highly capable models. Such synthetic
data will be less likely available and of sufficient quality for lower-resource languages, which risks
deepening the existing gap. In addition, generative capabilities of LLMs are commonly evaluated
with other LLMs as judges (Zheng et al., 2023). For lower-resource languages, these judges are
likely less reliable due to lack of data and evaluations (Gureja et al., 2024) which, as a consequence,
leads to less reliable measurement of advances for each language. This divide is larger in multimodal
domains, where often data needs to exist across both domains such as audio, vision and language
(Dash et al., 2025).
Widening cost in access to technology. The language gap results in higher costs of using
languagemodel-basedtechnologiesforsomenon-Englishlanguages, astheymayrequiremoretokens
and incur higher latency for generations (Ahia et al., 2023; Ji et al., 2023b). Figure 3 illustrates this
effect: for non-Latin scripts, many more tokens are needed to encode the same text for ChatGPT,
thereby incurring a higher processing cost. Speakers of low-resource languages often do not have
the resources to improve NLP technology for their language due to limited access to compute, data,
and opportunity (Ahia et al., 2021; OECD, 2023; ∀et al., 2020a).
Many language speakers and communities risk being left behind. The obvious consequence
of the language gap is that as language models become increasingly integral across our economies
and societies, the people and communities whose languages are not covered will be left behind.
An extensive body of research demonstrates how poorly existing language models perform for low-
resource languages in comparison to high-resource languages (e.g. Adelani et al., 2024; Üstün et al.,
2024; Singh et al., 2024; 2025; Romanou et al., 2025; Arora et al., 2024), and as language models
becomemoreembeddedintheprovisionofservicesandproducts, thisperformancegapcouldworsen
existing inequities across global communities (e.g. Laurito et al., 2024).
Diversityacrosscultures, societies, andcommunitiescouldbereduced. Asmachinelearn-
ing models’ outputs can only reflect the world based on the data on which they have been trained
and given access, the majority of LLMs reflect an Anglo-centric and predominately North American
8Figure 4: Results from Shen et al. (2024): Lower-resource languages have a higher rate of harmful
and irrelevant generations by GPT-4 than higher-resource languages. (Zou et al., 2023).
viewpoint. This lack of linguistic diversity means that the abstract “concept space” that underpins
model functionality is more oriented towards English than to other languages (Cahyawijaya et al.,
2023b; Yong et al., 2023a; Wendler et al., 2024; Aakanksha et al., 2024a;b), and introduces biases
against languages and cultural perspectives seen rarely in model training (Schwartz et al., 2022;
Kunchukuttan et al., 2021; Kotek et al., 2023; Khandelwal et al., 2023; Naous et al., 2024). Many
existing language models fail to account for social factors, such as speaker perspective or sociocul-
tural norm, and this problem is amplified for low-resource languages (Hovy & Yang, 2021). This
means that users may receive responses from LLMs that do not reflect their cultural experience or
social history.
4 Challenges of AI Safety in a Global World
Section Findings
➤Addressing multilingual safety in AI is challenging due to the focus on English and
Western-centric datasets, leading to a lack of reliable safety evaluations and mitigation
strategies for most languages.
➤This gap results in models producing harmful or biased outputs in non-English languages,
disproportionately affecting non-English speakers and creating security risks.
➤Bothintentional exploitation of language-related vulnerabilities anduninten-
tional exposure to harm due to insufficient safeguards pose significant concerns, high-
lighting the urgent need for inclusive safety measures across all languages.
9Overall, addressing safety and performance issues in a multilingual context involves navigating
complex challenges. There are many ongoing commitments to address the safety risks posed by AI
models. Many of these are high-profile, international efforts. Examples include the Seoul Frontier
AI Safety Commitments, which were signed by 16 companies who collectively operate in almost
every country and territory around the world;5the inaugural meeting of the international network
of AI Safety Institutes, representing 11 countries and regions;6the enshrinement of the EU’s AI
Act and the process to draft the Act’s Code of Practice for General Purpose AI model providers,
focused on models that pose ‘systemic risk’;7efforts led by Singapore to build capacity for AI safety
testing across South East Asia;8and many more. However, ensuring safety across languages or
representation of multilingual and global context is not explicitly or prominently mentioned in any
oftheseefforts. Thisisahugeoversightgiventhatalackofcareformultilingualsettingsundermines
access, performance and safety for global users.
Lack of multilingual safeguards undermine safety for all users. A dearth of multilin-
gual safety testing and mitigation means that language models can produce harmful outputs when
prompted in languages for which they are not optimized or safety-tested (Anwar et al., 2024),
creating a sharp performance cliff which disproportionately amplifies risk for non-English speak-
ers (Khandelwal et al., 2023; Yong et al., 2023a; Üstün et al., 2024). For instance, models can show
stereotypical gender biases when translating into Bengali and Turkish (Ghosh & Caliskan, 2023),
and may exhibit unsafe behavior when prompted in low-resource languages (Yong et al., 2023a).
There can also be critical security and safety flaws for all users of languages outside of English,
where multilingual prompts can be used to subvert safety guardrails (Yong et al., 2023a; Deng
et al., 2024).
Efforts on safety overly focused on English. Successful mitigation of multilingual harms
involves reconciling differing global and local preferences. To date, efforts to ensure safety alignment
are primarily focused on homogeneous monolingual settings — predominantly English — or overfit
to types of harm common in Western-centric datasets (Sambasivan et al., 2021; Shen et al., 2024).
Approaches to remedying the generation of violent, biased, false, or toxic content (Weidinger et al.,
2021) are largely oriented towards English or monolingual settings, and there is a lack of reliable
datasets for safety evaluation outside of a small fraction of languages (Gehman et al., 2020; Talat
et al., 2022; Pozzobon et al., 2024). This includes the vast majority of work on language model
alignment (Stiennon et al., 2020; Christiano et al., 2017; Dai et al., 2024; Bai et al., 2022; Tunstall
et al., 2024), a core component of improving model safety.
Many multilingual safety harms do not require active intent to subvert guardrails.
Harms arising from gaps in multilingual safety might be intentional — e.g. malicious actors find
and exploit language gap-related “backdoors” to generate harmful output. Or harms may be unin-
tentional — e.g. users from underserved language communities being unknowingly exposed to harm
5Frontier AI Safety Commitments, AI Seoul Summit (2024), https://www.gov.uk/government/publications/f
rontier-ai-safety-commitments-ai-seoul-summit-2024/frontier-ai-safety-commitments-ai-seoul-summi
t-2024
6US Department of Commerce (2024), International Network of AI Safety Institutes at Inaugural Convening,
https://www.commerce.gov/news/fact-sheets/2024/11/fact-sheet-us-department-commerce-us-departmen
t-state-launch-international
7European Commission (2024), General-Purpose AI Code of Practice, https://digital-strategy.ec.europa.
eu/en/policies/ai-code-practice
8IMDA (2024), Singapore AI Safety Red Teaming Challenge, https://www.imda.gov.sg/activities/activitie
s-catalogue/singapore-ai-safety-red-teaming-challenge
10due to the lack of effective safeguards for their language (Shen et al., 2024; Deng et al., 2024; Yong
et al., 2023a). Such unintentional harms are elucidated by Figure 4, which summarizes the findings
of Shen et al. (2024): GPT-4 tends to produce more harmful content in low-resource languages,
while also following instructions less faithfully as compared to high-resource languages.
5 Closing the AI Language Gap & Extending Safety Guardrails
Section Findings
➤Key lessons from Cohere Labs’ Aya initiative, a global collaborative effort towards multi-
lingual AI, include the importance of combining human-curated and synthetically
generated data to increase volume and language coverage.
➤Building comprehensive evaluation sets alongside models is crucial, especially for open-
ended use. Cross-institutional collaboration , involving local communities and multi-
disciplinary experts, is essential for preserving cultural and linguistic nuances.
➤Technical innovations such as multilingual preference training, model merging, and
safety context distillation have improved model performance and safety across languages,
reducing harmful generations while maintaining output quality.
➤Addressing harmful content requires continuous adaptation as language modeling and
language model use evolve. Inclusive data collection, robust evaluation, and collaborative
innovation are key components in advancing multilingual AI capabilities and safety.
Despite the challenges, there are clear levers of progress for reducing the multilingual divide and
safety disparities. To center the discussion, we pull upon the concrete lessons we have learned as a
lab in our efforts to extend coverage of languages used in AI.
5.1 Background: Cohere Labs’s AyaInitiative
Aya9is a multi-year initiative leveraging best practices from open-source and crowd-sourced science
projects (Beck et al., 2022; Lenart-Gansiniec et al., 2023; Franzoni & Sauermann, 2014; Muennighoff
et al., 2023a), with the goal of increasing access to state-of-the-art AI models, regardless of language.
To our knowledge, Aya is the largest participatory machine learning research initiative to date,
involving 3000 independent collaborators across 119 countries.
The inaugural Aya 101 release doubled coverage of existing languages covered by AI and released
the largest ever collection of multilingual, instruction fine-tuning data , with 513 million
prompts and completions covering 114 languages (Singh et al., 2024; Üstün et al., 2024). The
Aya dataset includes over 200,000 rare, human-curated annotations in 65 languages, providing re-
searchers around the world with high-quality data for instruction fine-tuning. Following Aya 101,
we released state-of-art models that outperform proprietary options for a subset of languages —
Aya Expanse (Dang et al., 2024b) is a family of multilingual models covering 23 languages that
combines research breakthroughs from Cohere and Cohere Labs: strong multilingual base models10,
9https://cohere.com/research/aya
10https://cohere.com/blog/command-series-0824
11multilingual instruction-tuning, synthetic data generation (Aryabumi et al., 2024a), multilingual ar-
bitrage (Odumakinde et al., 2024), multilingual preference training (Dang et al., 2024a), and model
merging (Aakanksha et al., 2024b). Aya Vision (Dash et al., 2025), a family of vision-language
models covering 23 languages based on Aya Expanse, expands multimodal capabilities to languages
spoken by over half the world’s population. It incorporates robust multilingual multimodal evalua-
tion, multilingual multimodal synthetic annotation, and merging to outperform models more than
2x of its size.
The Aya models and dataset have been released publicly11, and are intended to contribute to
closing the language gap by providing resources for researchers and developers to further advance
multilingual capabilities and safety. Through these model releases, we have learned a considerable
amount about the challenges in mitigating the curse of multilinguality (Conneau et al., 2020), and
tractable directions to improve coverage. We share more context on these learnings below.
5.2 Lesson #1: Data availability is one of the most potent levers of progress.
Different sources of data can be beneficial for improving coverage. One of the most
formidable challenges is quality and quantity of data available. We have found it is better to
increase coverage of data by including both human, synthetic and translated data rather than solely
prioritizing human annotations. This contradicts some views within the field, where translation
is thought of as insufficiently high quality. While we also observe translationese in practice, the
volume added to rare languages outweighs trade-offs in quality. Aya 101 brought generative AI to
languages previously unseen, in major part by leveraging many sources of data that include both
a human-curated dataset and synthetically generated multilingual instructions through templates
or machine translation. Combining and carefully weighing multiple sources of varying quantity,
quality, and language coverage increased data volume. Combining human-curated datasets and
automaticallytranslateddatasetsfacilitatedwiderevaluation, asrelyingsolelyonhumanannotation
can be expensive.
5.3 Lesson #2: Build evaluation sets alongside models.
To motivate and quantify progress on a given capability, it is crucial to have trusted benchmarks
and evaluation suites. This is especially critical for multilingual research, where there are many
languages with no evaluation set available. Accordingly, there is a need to build evaluation sets.
One of our core recommendations is to complement
Language-parallel evaluation sets have benefits yet should be used with an understand-
ing of their limitations. Global-MMLU (Singh et al., 2025) is a language-parallel evaluation set:
the same questions are asked across languages. This allows for control of question difficulty and
topic, and results can be interpreted apples-to-apples across languages. However, it means that the
quality of the benchmark rests on the quality of translation by human annotators (in the case of
Global-MMLU) or automatic translation tools. Translation can introduce erroneous artifacts, and
nuances in the original language of the questions might not have direct equivalents in other lan-
guages (Vanmassenhove et al., 2021; Hartung et al., 2023; Savoldi et al., 2021; Ji et al., 2023a; Chen
et al., 2024; Choenni et al., 2024). This is particularly true for translated prompts used in safety
11The Aya models and dataset are available via the Cohere Labs HuggingFace page: https://huggingface.co/C
ohereForAI .
12evaluations, where they can lose their harmful intent or become meaningless through translation
errors (Agrawal et al., 2024). In general, we recommend that heavily relied upon evaluation sets
are not automatically translated but also undergo human post-edits. While this is more expensive,
it ensures evaluations do not present translationese. We invest in these human post-edits for both
Global-MMLU (Singh et al., 2025) and aya-human-annotated (Singh et al., 2024).
Ensure evaluation sets capture local nuances. While translation enables parallel comparisons
across languages, relying on translating an evaluation from a single language can fail to adequately
capture regional nuances and knowledge. Cultural biases in multitask datasets limit their utility as
global benchmarks. Biases arise not only from differences in language but also from the cultural
knowledge required to interpret and understand questions effectively. We analyzed the Massive
Multitask Language Understanding (MMLU) benchmark (Hendrycks et al., 2020) — a commonly
used benchmark for assessing LLM capability — and found significant Western-centric biases (Singh
et al., 2025); 28% of questions require culture-specific knowledge, while 84.9% of the geography-
related subset focuses exclusively on North American or European regions (see Figure 5). Our
findings underscore how existing benchmarks prioritize Western concepts, distorting evaluations of
multilingual models. In response, we developed Global-MMLU (G-MMLU), an enhanced multi-
lingual test set covering 42 languages which annotates both global and locally sensitive questions
(Singh et al., 2025).
Another approach is to complement parallel evaluations with in-language evaluation sets that cap-
ture concepts specific to a region. An example of a complementary in-language evaluation set is
INCLUDE, to focus on capturing regional and cultural knowledge across 44 languages (Romanou
et al., 2025). While the exams are not directly comparable since each is from a different region
and covers different questions, this exam provides context about how model perforance reflects local
nuance and context.
Furthermore, it is critical that safety evaluations don’t just evaluate for global concepts of safety,
but account for local context. To construct the Aya Red-teaming dataset (Aakanksha et al., 2024a),
we worked with compensated annotators with native language skills in 8 languages (English, Hindi,
French, Spanish, Russian, Arabic, Serbian, Filipino) to craft prompts around a list of harmful cat-
egories, provide corresponding English translations, identify categories of harm, and label whether
the harm is “global” (understood and recognized as harmful worldwide) or “local” (harm is tied to
specific cultural or historical contexts).
Evaluationsshouldreflectrelevantgenerativeusecasesacrossmodalities. Languagemod-
elshavehistoricallybeenevaluatedondiscriminativetasks, inwhichmodelshavetoanswermultiple-
choice questions (such as MMLU (Hendrycks et al., 2020)). As model capabilities have improved,
models have started to be used and evaluated for generative tasks (e.g. creative writing, translation,
summarization, coding, mathematical reasoning) (Tamkin et al., 2024). In the latter case, mod-
els are asked to generate diverse and longer responses — contrast answering “tell me if these
two sentences are different” with“write me a story about a princess in a tower.” In
fact, models that are best at discriminative tasks are not usually the ones that humans prefer to
interact with: this tension has been observed in multiple works (Üstün et al., 2024; Muennighoff
et al., 2023a). Extending this to multiple modalities, current multilingual and multimodal bench-
marks (Liu et al., 2021; Pfeiffer et al., 2022; Romero et al., 2025; Tang et al., 2024; Yue et al.,
2024; Lovenia et al., 2024) lack critical evaluation domains such as open-ended generations based
on multimodal input.
13Figure 5: Of examples in MMLU requiring cultural or regionally-specific knowledge to answer cor-
rectly, the majority are geographically tied to North America and dominated by Western culture
(from Singh et al. (2025))
One of the core recommendations is that evaluations should always include both some open-ended
tasksaswellasmoretraditionalacademicclassificationtasks. Forcriticalareassuchasmultilingual,
multimodal there are limited open-ended evaluations. To help address this gap, together with Aya
Vision models (Dash et al., 2025), we also released Aya Vision Bench12, constructed for evaluating
Vision-Language Model (VLM) performance on real-world applications from distinct task categories
and covering 23 languages. In contrast to discriminative benchmarks, this benchmark enables
evaluation of VLMs in a setting that is more aligned with human interaction in the wild.
5.4 Lesson #3: Collaborate cross-institutionally.
Languages are not monolithic: they contain dialect, regional, and cultural nuances. Many languages
are spoken across multiple regions of the world, resulting in cultural or regional dialects. Languages
in existing multilingual datasets, including our Aya dataset, have limited representation of regional
nuance, as often only a few human annotators are responsible for annotating the majority of any
one language dataset (Singh et al., 2024). This might mean that data for a particular language is
annotated in a way that represents the perspective of a particular contributor or cultural viewpoint.
For example, annotations in French might center on historical and cultral references of France, but
neglect other French-speaking communities in Québec or Senegal (Vigouroux, 2013).
Designinganddeliveringhighquality, diverseandlocallyrelevantdatasetsdemandalotofresources:
the cultural and linguistic knowledge itself, as well as how to build the best scaffolding for it —
knowinghowtoengagecommunities, whichdatatoacquireandwhichinfrastructuretobuild. Cross-
12https://huggingface.co/datasets/CohereForAI/AyaVisionBench
14institutional collaborations are crucial to join such diverse forces, and preserve local contexts. There
have recently been multiple successful open science collaborations. Examples include Masakhane, a
grassroots organization who has been working to strengthen natural language processing research
in African languages since 2020 ( ∀et al., 2020b), or NusaCrowd, a “collaborative initiative to
collect and unify existing resources for Indonesian languages (Cahyawijaya et al., 2023a),” with
connections to a collaboration of South-East Asian researchers (Lovenia et al., 2024; Cahyawijaya
et al., 2025). Aya 101 was organized as a global open science project dedicated to collecting high-
quality, human-annotatedinstruction-styledataandbuildingamodeltoserve101languages13. The
Aya initiative adopted a decentralized approach, empowering contributors—regardless of academic
orprofessionalbackground—toleadasLanguageAmbassadors. Thiscollaborativeeffortprioritized
the preservation and integration of underrepresented languages, such as Malagasy and Telugu’s
Sathakam poetry, setting a new standard for inclusive AI development.
These and many other ongoing efforts around the world — many of them grassroots community
initiatives — are working to broaden the capabilities of language models across a wider range of
languages. Successful efforts showcase the importance of (1) planning around local community
involvement, (2) involving multidisciplinary experts, ranging from community engagement to NLP
and (3) delivering open-source assets that can be shared and re-used widely. Many governments
and public bodies are creating initiatives to address the language gap in AI, such as the European
Commission’s “Common European Language Data Space”14or the South African Government’s
platform.15Given the challenges associated with building localized and high quality assets in
low resource languages, more incentives are needed to kickstart and, importantly, support cross-
institutional collaborations over time to ensure sustainable community building and asset delivery.
5.5 Lesson #4: Focus on improving multilingual performance.
Major gains in multilingual language processing were achieved throughout the Aya Initiative due to
technical breakthroughs. Supporting technical innovation, including multilingual learning efficiency,
is critical to bringing AI to the world. We detail some examples below.
Multilingual Preference Training. Preference optimization techniques have become a standard
final stage for training state-of-art LLMs providing models with human or AI feedback on their
outputs so they can learn to mimic high-quality output. To date, the vast majority of preference
optimization work has focused on globally dominant languages like English and Chinese. Recent
work has allowed for more focus on a multilingual setting (Dang et al., 2024a; Aakanksha et al.,
2024a), however it requires investment in both the type of feedback collected as well as differing
optimization protocols to make sure the models are aligned with global and local nuances.
Model Merging. Model merging combines the strengths of different specialized models to create
a more capable and balanced system, particularly for handling multiple languages. We explored
merging specialized models in a diverse multi-task setting, combining safety and general-purpose
tasks within a multilingual context (Aakanksha et al., 2024b; Cohere et al., 2025). Our findings
illustrate an important take-away for policymakers; merging can help build stronger and safer
13Cohere Labs. Aya Initiative Overview
14European Commission. The Common European Language Data Space.
15Government of South Africa (2019), ‘Government Establishes A New Digital Centre To Promote Indigenous
Languages’.
15Figure 6: Human ratings of harmfulness in model generations, before (Aya) and after safety mit-
igation (Aya Safe) (Üstün et al., 2024). Safety context distillation drastically reduces the ratio of
harmful generations for harmful prompts across languages.
multilingual systems, offering clear advantages for handling complex tasks in diverse languages.
This is an important achievement compared to earlier works, where the assumption was that safety
improvementswouldalwaysincuracost, andtherebybelessattractive. Mergingalsohasthebenefit
that it is a far cheaper optimization step than alternatives like finetuning or continued training.
Safety Context Distillation.
A core safety guardrail for language models is the ability to refuse to respond to potentially harmful
prompts. For example, when a model is prompted to produce hate speech, it will refuse to do so.
To develop the Aya 101 model and ensure its ability to refuse harmful prompts across different
languages, we used ‘safety context distillation’ (Askell et al., 2021; Ganguli et al., 2022; Touvron
et al., 2023b; Bianchi et al., 2024) to teach the model in which contexts refusals are appropriate
(Üstün et al., 2024). The core idea is to teach a model to generate safe responses for harmful
prompts as demonstrated by a teacher. We found this step reduced harmful generations from
adversarial prompts by 78–89% as judged by human experts, as illustrated in Figure 6 and is a
relatively straightforward protocol that yields large immediate benefits.
5.6 Lesson # 5: Tackle harmful content as it evolves.
Languages evolve naturally over time (Frermann & Lapata, 2016; Jaidka et al., 2018; Horn, 2021).
Considerableefforthasbeendedicatedtomitigatingtoxicity—thegenerationofoffensiveorharmful
text-content — but existing methods often require drastic modifications to model parameters or the
use of computationally intensive methods. This means that keeping toxicity safety guards up-to-
date as language evolves is onerous. For example, work on continual learning allows for state-of-art
toxicity mitigation while the distribution is changing (Pozzobon et al., 2023). Building on this,
toxicity mitigation has to expand to techniques beyond just traditional English-centric approaches
(Pozzobon et al., 2024). Recent work has expanded the languages covered, while establishing some
16of the complexities of multilingual toxicity mitigation (Pozzobon et al., 2024). Policymakers should
ask researchers what they are doing to ensure their models are up-to-date and evolve alongside
languages and cultural references.
5.7 Lesson #6: Access to technology matters and is as important as performance.
Expanding the languages covered by AI language models will rely on the input of language speakers
around the world. Fortunately, the global availability of internet-connected devices means that it is
possibletoconnectwith, engage, andcollaboratewithpeopleacrosscontinentsandtimezonesinreal
time. This was a key enabler for our Aya project, as it meant we could use online chat platforms
to coordinate input across our global community. Unfortunately, the availability of devices and
internet access is not equitable across the world (Avle et al., 2020). Desktop and laptop computers
with wired, high-speed internet are commonplace across households in more economically developed
nations, but in many other parts of the world, particularly the Global South, mobile devices and
cellular or satellite internet are more common. In our Aya project, approximately 54% of users
accessed our data collection platform via desktop browsers while 46% utilized mobile browsers
(Singh et al., 2024). To enable participation of a wide range of language speakers, language model
and dataset development requires the creation of tools that are accessible across different devices,
operating systems, and internet connectivities.
We have also spent considerable time making our models available in much more accessible ways,
such as at a lower more efficient parameter count of 8billion parameter models (fits on a single
GPU) or available via whatsapp given this is often the memory efficient app to download in certain
regions of the world.
6 Conclusion and recommendations for policy makers
The language gap in AI is a significant issue that risks excluding communities from the benefits of
languagemodels, underminingmodelsafety, andexacerbatingexistingsocial, linguistic, andcultural
inequalities, particularly for speakers of low-resource languages. Despite efforts across the machine
learning research community and global government initiatives, several barriers still exist that must
be addressed to close the AI language gap. We complete this primer with some recommendations
for policy makers to ensure progress continues on multilingual inclusion.
1.Support multilingual dataset creation:
1.1. Incentivize and facilitate the creation of open access evaluation sets, which reflect relevant
generative use cases and safety-relevant use cases across modalities, both by translating
existing datasets ("language-parallel") and creating localized ones ("language-specific").
1.2. Enable human annotators from diverse backgrounds with multilingual and multicultural
expertise to engage in the curation of high-quality, inclusive datasets.
2.Support multilingual transparency from model providers:
2.1. Encourage model providers to articulate the coverage of languages served by each model
family, for example through technical or evaluation reports.
172.2. Conduct analyses of language coverage across safety research, for example by assessing the
presence or absence of safety mitigations across languages in published reports.
3.Support multilingual research and development:
3.1. Ensure that diverse languages are represented across training programs that expand skill
sets for efficient community engagement, data collection and model training.
3.2. Support multilingual and non-English research that aims to close the language gap through
funding and other programs.
3.3. Enable access to (more) compute for multilingual safety research, especially for projects and
in regions where it is disproportionately inaccessible.
Acknowledgments
We thank Thomas Euyang for the visualization of the figures and diagrams, Madeline Smith for the
coordination, and Oreva Ahia for providing the raw data for Figure 3.
References
Aakanksha, Arash Ahmadian, Beyza Ermis, Seraphina Goldfarb-Tarrant, Julia Kreutzer, Marzieh
Fadaee, andSaraHooker. Themultilingualalignmentprism: Aligningglobalandlocalpreferences
to reduce harm. In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen (eds.), Proceedings of
the 2024 Conference on Empirical Methods in Natural Language Processing , pp. 12027–12049,
Miami, Florida, USA, November 2024a. Association for Computational Linguistics. doi: 10.186
53/v1/2024.emnlp-main.671. URL https://aclanthology.org/2024.emnlp-main.671/ .
Aakanksha, Arash Ahmadian, Seraphina Goldfarb-Tarrant, Beyza Ermis, Marzieh Fadaee, and
Sara Hooker. Mix data or merge models? optimizing for diverse multi-task learning, 2024b. URL
http://arxiv.org/abs/2410.10801 .
Gilles Adda, Sebastian Stüker, Martine Adda-Decker, Odette Ambouroue, Laurent Besacier, David
Blachon, Hélène Bonneau-Maynard, Pierre Godard, Fatima Hamlaoui, Dmitry Idiatov, Guy-Noël
Kouarata, Lori Lamel, Emmanuel-Moselly Makasso, Annie Rialland, Mark Van de Velde, François
Yvon, and Sabine Zerbian. Breaking the unwritten language barrier: The bulb project. Procedia
Computer Science , 81:8–14, 2016. ISSN 1877-0509. doi: https://doi.org/10.1016/j.procs.2016.0
4.023. URL https://www.sciencedirect.com/science/article/pii/S1877050916300370 .
SLTU-2016 5th Workshop on Spoken Language Technologies for Under-resourced languages 09-12
May 2016 Yogyakarta, Indonesia.
David Ifeoluwa Adelani, Jessica Ojo, Israel Abebe Azime, Jian Yun Zhuang, Jesujoba O. Alabi,
Xuanli He, Millicent Ochieng, Sara Hooker, Andiswa Bukula, En-Shiun Annie Lee, Chiamaka
Chukwuneke, Happy Buzaaba, Blessing Sibanda, Godson Kalipe, Jonathan Mukiibi, Salomon
Kabongo, Foutse Yuehgoh, Mmasibidi Setaka, Lolwethu Ndolela, Nkiruka Odu, Rooweither
Mabuya, Shamsuddeen Hassan Muhammad, Salomey Osei, Sokhar Samb, Tadesse Kebede Guge,
and Pontus Stenetorp. IrokoBench: A new benchmark for african languages in the age of large
language models, 2024. URL http://arxiv.org/abs/2406.03368 .
18Muhammad Farid Adilazuarda, Samuel Cahyawijaya, Genta Indra Winata, Pascale Fung, and Ayu
Purwarianti. IndoRobusta: Towards robustness against diverse code-mixed Indonesian local lan-
guages. In Kabir Ahuja, Antonios Anastasopoulos, Barun Patra, Graham Neubig, Monojit
Choudhury, Sandipan Dandapat, Sunayana Sitaram, and Vishrav Chaudhary (eds.), Proceed-
ings of the First Workshop on Scaling Up Multilingual Evaluation , pp. 25–34, Online, November
2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.sumeval-1.5. URL
https://aclanthology.org/2022.sumeval-1.5/ .
Ashish Sunil Agrawal, Barah Fazili, and Preethi Jyothi. Translation errors significantly impact low-
resource languages in cross-lingual learning, 2024. URL http://arxiv.org/abs/2402.02080 .
Orevaoghene Ahia, Julia Kreutzer, and Sara Hooker. The low-resource double bind: An empiri-
cal study of pruning for low-resource machine translation. In Marie-Francine Moens, Xuanjing
Huang, Lucia Specia, and Scott Wen-tau Yih (eds.), Findings of the Association for Compu-
tational Linguistics: EMNLP 2021 , pp. 3316–3333. Association for Computational Linguistics,
2021. doi: 10.18653/v1/2021.findings-emnlp.282. URL https://aclanthology.org/2021.find
ings-emnlp.282 .
Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David Mortensen, Noah Smith,
and Yulia Tsvetkov. Do all languages cost the same? tokenization in the era of commercial
language models. In Houda Bouamor, Juan Pino, and Kalika Bali (eds.), Proceedings of the
2023 Conference on Empirical Methods in Natural Language Processing , pp. 9904–9923. Asso-
ciation for Computational Linguistics, 2023. doi: 10.18653/v1/2023.emnlp-main.614. URL
https://aclanthology.org/2023.emnlp-main.614 .
Alham Fikri Aji, Genta Indra Winata, Fajri Koto, Samuel Cahyawijaya, Ade Romadhony, Rah-
mad Mahendra, Kemal Kurniawan, David Moeljadi, Radityo Eko Prasojo, Timothy Baldwin,
Jey Han Lau, and Sebastian Ruder. One country, 700+ languages: NLP challenges for un-
derrepresented languages and dialects in Indonesia. In Smaranda Muresan, Preslav Nakov,
and Aline Villavicencio (eds.), Proceedings of the 60th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers) , pp. 7226–7249, Dublin, Ireland, May
2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-long.500. URL
https://aclanthology.org/2022.acl-long.500/ .
Ateret Anaby-Tavor, Boaz Carmeli, Esther Goldbraich, Amir Kantor, George Kour, Segev Shlomov,
Naama Tepper, and Naama Zwerdling. Not enough data? deep learning to the rescue!, 2019.
URLhttps://arxiv.org/abs/1911.03118 .
Zachary Ankner, Cody Blakeney, Kartik Sreenivasan, Max Marion, Matthew L Leavitt, and Man-
sheej Paul. Perplexed by perplexity: Perplexity-based data pruning with small reference mod-
els. In The Thirteenth International Conference on Learning Representations , 2025. URL
https://openreview.net/forum?id=1GTARJhxtq .
Usman Anwar, Abulhair Saparov, Javier Rando, Daniel Paleka, Miles Turpin, Peter Hase,
Ekdeep Singh Lubana, Erik Jenner, Stephen Casper, Oliver Sourbut, Benjamin L. Edelman,
Zhaowei Zhang, Mario Günther, Anton Korinek, Jose Hernandez-Orallo, Lewis Hammond, Eric
Bigelow, Alexander Pan, Lauro Langosco, Tomasz Korbak, Heidi Zhang, Ruiqi Zhong, Seán Ó
hÉigeartaigh, Gabriel Recchia, Giulio Corsi, Alan Chan, Markus Anderljung, Lilian Edwards,
Yoshua Bengio, Danqi Chen, Samuel Albanie, Tegan Maharaj, Jakob Foerster, Florian Tramer,
He He, Atoosa Kasirzadeh, Yejin Choi, and David Krueger. Foundational challenges in assuring
alignment and safety of large language models, 2024. URL http://arxiv.org/abs/2404.09932 .
19Shane Arora, Marzena Karpinska, Hung-Ting Chen, Ipsita Bhattacharjee, Mohit Iyyer, and Eunsol
Choi. Calmqa: Exploring culturally specific long-form question answering across 23 languages,
2024. URL https://arxiv.org/abs/2406.17761 .
Viraat Aryabumi, John Dang, Dwarak Talupuru, Saurabh Dash, David Cairuz, Hangyu Lin, Bharat
Venkitesh, Madeline Smith, Jon Ander Campos, Yi Chern Tan, Kelly Marchisio, Max Bartolo, Se-
bastian Ruder, Acyr Locatelli, Julia Kreutzer, Nick Frosst, Aidan Gomez, Phil Blunsom, Marzieh
Fadaee, Ahmet Üstün, and Sara Hooker. Aya 23: Open weight releases to further multilingual
progress, 2024a. URL https://arxiv.org/abs/2405.15032 .
Viraat Aryabumi, John Dang, Dwarak Talupuru, Saurabh Dash, David Cairuz, Hangyu Lin, Bharat
Venkitesh, Madeline Smith, Jon Ander Campos, Yi Chern Tan, Kelly Marchisio, Max Bartolo, Se-
bastian Ruder, Acyr Locatelli, Julia Kreutzer, Nick Frosst, Aidan Gomez, Phil Blunsom, Marzieh
Fadaee, Ahmet Üstün, and Sara Hooker. Aya 23: Open weight releases to further multilingual
progress, 2024b. URL http://arxiv.org/abs/2405.15032 .
Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones,
Nicholas Joseph, Ben Mann, Nova DasSarma, et al. A general language assistant as a laboratory
for alignment. arXiv preprint arXiv:2112.00861 , 2021.
Seyram Avle, Emmanuel Quartey, David Hutchful, Seyram Avle, Emmanuel Quartey, and David
Hutchful. Research on mobile phone data in the global south: Opportunities and challenges, 2020.
URLhttps://academic.oup.com/edited-volume/34286/chapter/290662354 . Book Title:
The Oxford Handbook of Networked Communication ISBN: 9780190460518 Publisher: Oxford
University Press.
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones,
Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Olsson,
Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson,
Ethan Perez, Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile
Lukosuite, Liane Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova
DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec, Sheer El
Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly, Tom Henighan,
Tristan Hume, Samuel R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario Amodei, Nicholas
Joseph, Sam McCandlish, Tom Brown, and Jared Kaplan. Constitutional ai: Harmlessness from
ai feedback, 2022. URL https://arxiv.org/abs/2212.08073 .
Ankur Bapna, Isaac Caswell, Julia Kreutzer, Orhan Firat, Daan van Esch, Aditya Siddhant, Meng-
meng Niu, Pallavi Baljekar, Xavier Garcia, Wolfgang Macherey, Theresa Breiner, Vera Axel-
rod, Jason Riesa, Yuan Cao, Mia Xu Chen, Klaus Macherey, Maxim Krikun, Pidong Wang,
Alexander Gutkin, Apurva Shah, Yanping Huang, Zhifeng Chen, Yonghui Wu, and Macduff
Hughes. Building machine translation systems for the next thousand languages, 2022. URL
http://arxiv.org/abs/2205.03983 .
Susanne Beck, Carsten Bergenholtz, Marcel Bogers, Tiare Maria Brasseur, Marie Louise Conradsen,
Diletta Di Marco, Andreas P. Distel, Leonhard Dobusch, Daniel Dörler, Agnes Effert, Benedikt
Fecher, Despoina Filiou, Lars Frederiksen, Thomas Gillier, Christoph Grimpe, Marc Gruber, Car-
olin Haeussler, Florian Heigl, Karin Hoisl, Katie Hyslop, Olga Kokshagina, Marcel LaFlamme,
Cornelia Lawson, Hila Lifshitz-Assaf, Wolfgang Lukas, Markus Nordberg, Maria Theresa Norn,
Marion Poetz, Marisa Ponti, Gernot Pruschak, Laia Pujol Priego, Agnieszka Radziwon, Janet
20Rafner, Gergana Romanova, Alexander Ruser, Henry Sauermann, Sonali K. Shah, Jacob F. Sher-
son, Julia Suess-Reyes, Christopher L. Tucci, Philipp Tuertscher, Jane Bjørn Vedel, Theresa
Velden, Roberto Verganti, Jonathan Wareham, Andrea Wiggins, and Sunny Mosangzi Xu. The
open innovation in science research field: a collaborative conceptualisation approach. Industry
and Innovation , 29(2):136–185, 2022. ISSN 1366-2716. doi: 10.1080/13662716.2020.1792274.
Federico Bianchi, Mirac Suzgun, Giuseppe Attanasio, Paul Rottger, Dan Jurafsky, Tatsunori
Hashimoto, and James Zou. Safety-tuned LLaMAs: Lessons from improving the safety of large
language models that follow instructions. In The Twelfth International Conference on Learning
Representations , 2024. URL https://openreview.net/forum?id=gT5hALch9z .
Steven Bird. Local languages, third spaces, and other high-resource scenarios. In Proceedings of the
60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) ,
pp. 7817–7829. Association for Computational Linguistics, 2022. doi: 10.18653/v1/2022.acl-lon
g.539. URL https://aclanthology.org/2022.acl-long.539 .
Terra Blevins and Luke Zettlemoyer. Language contamination helps explains the cross-lingual
capabilities of English pretrained models. In Yoav Goldberg, Zornitsa Kozareva, and Yue
Zhang (eds.), Proceedings of the 2022 Conference on Empirical Methods in Natural Language
Processing , pp. 3563–3574, Abu Dhabi, United Arab Emirates, December 2022. Association
for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-main.233. URL https:
//aclanthology.org/2022.emnlp-main.233/ .
Meriem Boubdir, Edward Kim, Beyza Ermis, Marzieh Fadaee, and Sara Hooker. Which prompts
make the difference? data prioritization for efficient human llm evaluation, 2023.
Eleftheria Briakou, Colin Cherry, and George Foster. Searching for needles in a haystack: On the
role of incidental bilingualism in PaLM‘s translation capability. In Anna Rogers, Jordan Boyd-
Graber, and Naoaki Okazaki (eds.), Proceedings of the 61st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers) , pp. 9432–9452, Toronto, Canada, July
2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.524. URL
https://aclanthology.org/2023.acl-long.524/ .
Samuel Cahyawijaya, Holy Lovenia, Alham Fikri Aji, Genta Indra Winata, Bryan Wilie, Rah-
mad Mahendra, Christian Wibisono, Ade Romadhony, Karissa Vincentio, Fajri Koto, Jennifer
Santoso, David Moeljadi, Cahya Wirawan, Frederikus Hudi, Ivan Halim Parmonangan, Ika Al-
fina, Muhammad Satrio Wicaksono, Ilham Firdausi Putra, Samsul Rahmadani, Yulianti Oenang,
Ali Akbar Septiandri, James Jaya, Kaustubh D. Dhole, Arie Ardiyanti Suryani, Rifki Afina Pu-
tri, Dan Su, Keith Stevens, Made Nindyatama Nityasya, Muhammad Farid Adilazuarda, Ryan
Ignatius, Ryandito Diandaru, Tiezheng Yu, Vito Ghifari, Wenliang Dai, Yan Xu, Dyah Dama-
puspita, Cuk Tho, Ichwanul Muslim Karo Karo, Tirana Noor Fatyanosa, Ziwei Ji, Pascale Fung,
Graham Neubig, Timothy Baldwin, Sebastian Ruder, Herry Sujaini, Sakriani Sakti, and Ayu
Purwarianti. NusaCrowd: Open source initiative for indonesian NLP resources, 2023a. URL
http://arxiv.org/abs/2212.09648 .
Samuel Cahyawijaya, Holy Lovenia, Fajri Koto, Dea Adhista, Emmanuel Dave, Sarah Oktavianti,
Salsabil Akbar, Jhonson Lee, Nuur Shadieq, Tjeng Wawan Cenggoro, Hanung Linuwih, Bryan
Wilie, Galih Muridan, Genta Winata, David Moeljadi, Alham Fikri Aji, Ayu Purwarianti, and
Pascale Fung. NusaWrites: Constructing high-quality corpora for underrepresented and ex-
tremely low-resource languages. In Jong C. Park, Yuki Arase, Baotian Hu, Wei Lu, Derry
21Wijaya, Ayu Purwarianti, and Adila Alfa Krisnadhi (eds.), Proceedings of the 13th Interna-
tional Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-
Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers) , pp.
921–945, Nusa Dua, Bali, November 2023b. Association for Computational Linguistics. doi:
10.18653/v1/2023.ijcnlp-main.60. URL https://aclanthology.org/2023.ijcnlp-main.60/ .
Samuel Cahyawijaya, Delong Chen, Yejin Bang, Leila Khalatbari, Bryan Wilie, Ziwei Ji, Etsuko
Ishii, and Pascale Fung. High-dimension human value representation in large language models,
2024. URL https://arxiv.org/abs/2404.07900 .
Samuel Cahyawijaya, Holy Lovenia, Joel Ruben Antony Moniz, Tack Hwa Wong, Moham-
mad Rifqi Farhansyah, Thant Thiri Maung, Frederikus Hudi, David Anugraha, Muhammad
Ravi Shulthan Habibi, Muhammad Reza Qorib, Amit Agarwal, Joseph Marvin Imperial,
HiteshLaxmichandPatel, VickyFeliren, BahrulIlmiNasution, ManuelAntonioRufino, GentaIn-
dra Winata, Rian Adam Rajagede, Carlos Rafael Catalan, Mohamed Fazli Imam, Priyaranjan
Pattnayak, Salsabila Zahirah Pranida, Kevin Pratama, Yeshil Bangera, Adisai Na-Thalang, Pa-
tricia Nicole Monderin, Yueqi Song, Christian Simon, Lynnette Hui Xian Ng, Richardy Lobo’
Sapan, Taki Hasan Rafi, Bin Wang, Supryadi, Kanyakorn Veerakanjana, Piyalitt Ittichai-
wong, Matthew Theodore Roque, Karissa Vincentio, Takdanai Kreangphet, Phakphum Artkaew,
Kadek Hendrawan Palgunadi, Yanzhi Yu, Rochana Prih Hastuti, William Nixon, Mithil Bangera,
Adrian Xuan Wei Lim, Aye Hninn Khine, Hanif Muhammad Zhafran, Teddy Ferdinan, Audra Au-
rora Izzani, Ayushman Singh, Evan, Jauza Akbar Krito, Michael Anugraha, Fenal Ashokbhai
Ilasariya, Haochen Li, John Amadeo Daniswara, Filbert Aurelian Tjiaranata, Eryawan Presma
Yulianrifat, Can Udomcharoenchaikit, Fadil Risdian Ansori, Mahardika Krisna Ihsani, Giang
Nguyen, Anab Maulana Barik, Dan John Velasco, Rifo Ahmad Genadi, Saptarshi Saha, Cheng-
wei Wei, Isaiah Flores, Kenneth Ko Han Chen, Anjela Gail Santos, Wan Shen Lim, Kaung Si
Phyo, Tim Santos, Meisyarah Dwiastuti, Jiayun Luo, Jan Christian Blaise Cruz, Ming Shan
Hee, Ikhlasul Akmal Hanif, M. Alif Al Hakim, Muhammad Rizky Sya’ban, Kun Kerdthaisong,
Lester James V. Miranda, Fajri Koto, Tirana Noor Fatyanosa, Alham Fikri Aji, Jostin Jerico
Rosal, Jun Kevin, Robert Wijaya, Onno P. Kampman, Ruochen Zhang, Börje F. Karlsson, and
Peerat Limkonchotiwat. Crowdsource, crawl, or generate? creating sea-vl, a multicultural vision-
language dataset for southeast asia, 2025. URL https://arxiv.org/abs/2503.07920 .
Pinzhen Chen, Simon Yu, Zhicheng Guo, and Barry Haddow. Is it good data for multilingual
instruction tuning or just bad multilingual evaluation for large language models?, 2024. URL
http://arxiv.org/abs/2406.12822 .
Everlyn Asiko Chimoto, Jay Gala, Orevaoghene Ahia, Julia Kreutzer, Bruce A. Bassett, and Sara
Hooker. Critical learning periods: Leveraging early training dynamics for efficient data prun-
ing. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Findings of the Association
for Computational Linguistics: ACL 2024 , pp. 9407–9426, Bangkok, Thailand, August 2024.
Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.560. URL
https://aclanthology.org/2024.findings-acl.560/ .
Rochelle Choenni, Sara Rajaee, Christof Monz, and Ekaterina Shutova. On the evaluation practices
in multilingual NLP: Can machine translation offer an alternative to human translations?, 2024.
URLhttp://arxiv.org/abs/2406.14267 .
PaulFChristiano,JanLeike,TomBrown,MiljanMartic,ShaneLegg,andDarioAmodei. Deeprein-
forcement learning from human preferences. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach,
22R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing
Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/p
aper_files/paper/2017/file/d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf .
Team Cohere, Aakanksha, Arash Ahmadian, Marwan Ahmed, Jay Alammar, Yazeed Alnumay,
Sophia Althammer, Arkady Arkhangorodsky, Viraat Aryabumi, Dennis Aumiller, Raphaël Ava-
los, Zahara Aviv, Sammie Bae, Saurabh Baji, Alexandre Barbet, Max Bartolo, Björn Bebensee,
Neeral Beladia, Walter Beller-Morales, Alexandre Bérard, Andrew Berneshawi, Anna Bialas,
Phil Blunsom, Matt Bobkin, Adi Bongale, Sam Braun, Maxime Brunet, Samuel Cahyawijaya,
David Cairuz, Jon Ander Campos, Cassie Cao, Kris Cao, Roman Castagné, Julián Cendrero,
Leila Chan Currie, Yash Chandak, Diane Chang, Giannis Chatziveroglou, Hongyu Chen, Claire
Cheng, Alexis Chevalier, Justin T. Chiu, Eugene Cho, Eugene Choi, Eujeong Choi, Tim Chung,
Volkan Cirik, Ana Cismaru, Pierre Clavier, Henry Conklin, Lucas Crawhall-Stein, Devon Crouse,
Andres Felipe Cruz-Salinas, Ben Cyrus, Daniel D’souza, Hugo Dalla-Torre, John Dang, William
Darling, Omar Darwiche Domingues, Saurabh Dash, Antoine Debugne, Théo Dehaze, Shaan
Desai, Joan Devassy, Rishit Dholakia, Kyle Duffy, Ali Edalati, Ace Eldeib, Abdullah Elkady,
Sarah Elsharkawy, Irem Ergün, Beyza Ermis, Marzieh Fadaee, Boyu Fan, Lucas Fayoux, Yan-
nis Flet-Berliac, Nick Frosst, Matthias Gallé, Wojciech Galuba, Utsav Garg, Matthieu Geist,
Mohammad Gheshlaghi Azar, Seraphina Goldfarb-Tarrant, Tomas Goldsack, Aidan Gomez, Vic-
tor Machado Gonzaga, Nithya Govindarajan, Manoj Govindassamy, Nathan Grinsztajn, Nikolas
Gritsch, Patrick Gu, Shangmin Guo, Kilian Haefeli, Rod Hajjar, Tim Hawes, Jingyi He, Sebas-
tian Hofstätter, Sungjin Hong, Sara Hooker, Tom Hosking, Stephanie Howe, Eric Hu, Renjie
Huang, Hemant Jain, Ritika Jain, Nick Jakobi, Madeline Jenkins, JJ Jordan, Dhruti Joshi, Ja-
son Jung, Trushant Kalyanpur, Siddhartha Rao Kamalakara, Julia Kedrzycki, Gokce Keskin,
Edward Kim, Joon Kim, Wei-Yin Ko, Tom Kocmi, Michael Kozakov, Wojciech Kryściński, Ar-
nav Kumar Jain, Komal Kumar Teru, Sander Land, Michael Lasby, Olivia Lasche, Justin Lee,
Patrick Lewis, Jeffrey Li, Jonathan Li, Hangyu Lin, Acyr Locatelli, Kevin Luong, Raymond Ma,
Lukas Mach, Marina Machado, Joanne Magbitang, Brenda Malacara Lopez, Aryan Mann, Kelly
Marchisio, Olivia Markham, Alexandre Matton, Alex McKinney, Dominic McLoughlin, Jozef
Mokry, Adrien Morisot, Autumn Moulder, Harry Moynehan, Maximilian Mozes, Vivek Muppalla,
Lidiya Murakhovska, Hemangani Nagarajan, Alekhya Nandula, Hisham Nasir, Shauna Nehra,
Josh Netto-Rosen, Daniel Ohashi, James Owers-Bardsley, Jason Ozuzu, Dennis Padilla, Gloria
Park, Sam Passaglia, Jeremy Pekmez, Laura Penstone, Aleksandra Piktus, Case Ploeg, Andrew
Poulton, Youran Qi, Shubha Raghvendra, Miguel Ramos, Ekagra Ranjan, Pierre Richemond, Cé-
cile Robert-Michon, Aurélien Rodriguez, Sudip Roy, Laura Ruis, Louise Rust, Anubhav Sachan,
Alejandro Salamanca, Kailash Karthik Saravanakumar, Isha Satyakam, Alice Schoenauer Sebag,
Priyanka Sen, Sholeh Sepehri, Preethi Seshadri, Ye Shen, Tom Sherborne, Sylvie Chang Shi,
Sanal Shivaprasad, Vladyslav Shmyhlo, Anirudh Shrinivason, Inna Shteinbuk, Amir Shukayev,
Mathieu Simard, Ella Snyder, Ava Spataru, Victoria Spooner, Trisha Starostina, Florian Strub,
Yixuan Su, Jimin Sun, Dwarak Talupuru, Eugene Tarassov, Elena Tommasone, Jennifer Tracey,
Billy Trend, Evren Tumer, Ahmet Üstün, Bharat Venkitesh, David Venuto, Pat Verga, Maxime
Voisin, Alex Wang, Donglu Wang, Shijian Wang, Edmond Wen, Naomi White, Jesse Willman,
Marysia Winkels, Chen Xia, Jessica Xie, Minjie Xu, Bowen Yang, Tan Yi-Chern, Ivan Zhang,
Zhenyu Zhao, and Zhoujie Zhao. Command a: An enterprise-ready large language model, 2025.
URLhttps://arxiv.org/abs/2504.00698 .
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek,
Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. Unsuper-
23vised cross-lingual representation learning at scale. In Dan Jurafsky, Joyce Chai, Natalie Schluter,
and Joel Tetreault (eds.), Proceedings of the 58th Annual Meeting of the Association for Compu-
tational Linguistics , pp. 8440–8451, Online, July 2020. Association for Computational Linguistics.
doi: 10.18653/v1/2020.acl-main.747. URL https://aclanthology.org/2020.acl-main.747/ .
Josef Dai, Xuehai Pan, Ruiyang Sun, Jiaming Ji, Xinbo Xu, Mickel Liu, Yizhou Wang, and Yaodong
Yang. SafeRLHF:Safereinforcementlearningfromhumanfeedback. In The Twelfth International
Conference on Learning Representations , 2024. URL https://openreview.net/forum?id=TyFr
POKYXw.
John Dang, Arash Ahmadian, Kelly Marchisio, Julia Kreutzer, Ahmet Üstün, and Sara Hooker.
RLHF can speak many languages: Unlocking multilingual preference optimization for LLMs. In
Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen (eds.), Proceedings of the 2024 Conference
on Empirical Methods in Natural Language Processing , pp. 13134–13156, Miami, Florida, USA,
November 2024a. Association for Computational Linguistics. doi: 10.18653/v1/2024.emnlp-mai
n.729. URL https://aclanthology.org/2024.emnlp-main.729/ .
John Dang, Shivalika Singh, Daniel D’souza, Arash Ahmadian, Alejandro Salamanca, Madeline
Smith, Aidan Peppin, Sungjin Hong, Manoj Govindassamy, Terrence Zhao, Sandra Kublik, Meor
Amer, Viraat Aryabumi, Jon Ander Campos, Yi-Chern Tan, Tom Kocmi, Florian Strub, Nathan
Grinsztajn,YannisFlet-Berliac,AcyrLocatelli,HangyuLin,DwarakTalupuru,BharatVenkitesh,
David Cairuz, Bowen Yang, Tim Chung, Wei-Yin Ko, Sylvie Shang Shi, Amir Shukayev, Sam-
mie Bae, Aleksandra Piktus, Roman Castagné, Felipe Cruz-Salinas, Eddie Kim, Lucas Crawhall-
Stein, Adrien Morisot, Sudip Roy, Phil Blunsom, Ivan Zhang, Aidan Gomez, Nick Frosst, Marzieh
Fadaee, Beyza Ermis, Ahmet Üstün, and Sara Hooker. Aya expanse: Combining research break-
throughs for a new multilingual frontier, 2024b. URL https://arxiv.org/abs/2412.04261 .
Saurabh Dash, Yiyang Nan, John Dang, Arash Ahmadian, Shivalika Singh, Madeline Smith,
Bharat Venkitesh, Vlad Shmyhlo, Viraat Aryabumi, Walter Beller-Morales, Jeremy Pekmez, Ja-
son Ozuzu, Pierre Richemond, Acyr Locatelli, Nick Frosst, Phil Blunsom, Aidan Gomez, Ivan
Zhang, Marzieh Fadaee, Manoj Govindassamy, Sudip Roy, Matthias Gallé, Beyza Ermis, Ahmet
Üstün, and Sara Hooker. Aya vision: Advancing the frontier of multilingual multimodality, 2025.
Yue Deng, Wenxuan Zhang, Sinno Jialin Pan, and Lidong Bing. Multilingual jailbreak challenges
in large language models. In The Twelfth International Conference on Learning Representations ,
2024. URL https://openreview.net/forum?id=vESNKdEMGp .
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha
Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models.
arXiv preprint arXiv:2407.21783 , 2024.
∀, Wilhelmina Nekoto, Vukosi Marivate, Tshinondiwa Matsila, Timi Fasubaa, Taiwo Fagbo-
hungbe, Solomon Oluwole Akinola, Shamsuddeen Muhammad, Salomon Kabongo Kabenamualu,
Salomey Osei, Freshia Sackey, Rubungo Andre Niyongabo, Ricky Macharm, Perez Ogayo,
Orevaoghene Ahia, Musie Meressa Berhe, Mofetoluwa Adeyemi, Masabata Mokgesi-Selinga,
Lawrence Okegbemi, Laura Martinus, Kolawole Tajudeen, Kevin Degila, Kelechi Ogueji, Kath-
leen Siminyu, Julia Kreutzer, Jason Webster, Jamiil Toure Ali, Jade Abbott, Iroro Orife, Ig-
natius Ezeani, Idris Abdulkadir Dangana, Herman Kamper, Hady Elsahar, Goodness Duru,
Ghollah Kioko, Murhabazi Espoir, Elan van Biljon, Daniel Whitenack, Christopher Onyefu-
luchi, Chris Chinenye Emezue, Bonaventure F. P. Dossou, Blessing Sibanda, Blessing Bassey,
24Ayodele Olabiyi, Arshath Ramkilowan, Alp Öktem, Adewale Akinfaderin, and Abdallah Bashir.
Participatory research for low-resourced machine translation: A case study in African lan-
guages. In Trevor Cohn, Yulan He, and Yang Liu (eds.), Findings of the Association for
Computational Linguistics: EMNLP 2020 , pp. 2144–2160, Online, November 2020a. Associ-
ation for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.195. URL
https://aclanthology.org/2020.findings-emnlp.195/ .
∀, Iroro Orife, Julia Kreutzer, Blessing K. Sibanda, Daniel Whitenack, Kathleen Siminyu, Laura
Martinus, Jamiil Toure Ali, Jade Z. Abbott, Vukosi Marivate, Salomon Kabongo, Musie Meressa,
Espoir Murhabazi, Orevaoghene Ahia, Elan Van Biljon, Arshath Ramkilowan, Adewale Akin-
faderin, Alp Öktem, Wole Akin, Ghollah Kioko, Kevin Degila, Herman Kamper, Bonaventure
Dossou, ChrisEmezue, KelechiOgueji, andAbdallahBashir. Masakhane-machinetranslationfor
africa. In Kathleen Siminyu, Laura Martinus, and Vukosi Marivate (eds.), 1st AfricaNLP Work-
shop Proceedings, AfricaNLP@ICLR 2020, Virtual Conference, Formerly Addis Ababa Ethiopia,
26th April 2020 , 2020b. URL https://arxiv.org/abs/2003.11529 .
Chiara Franzoni and Henry Sauermann. Crowd science: The organization of scientific research in
open collaborative projects. Research Policy , 43(1):1–20, 2014. ISSN 0048-7333. doi: https:
//doi.org/10.1016/j.respol.2013.07.005. URL https://www.sciencedirect.com/science/arti
cle/pii/S0048733313001212 .
Lea Frermann and Mirella Lapata. A Bayesian model of diachronic meaning change. Transactions
of the Association for Computational Linguistics , 4:31–45, 2016. doi: 10.1162/tacl_a_00081.
URLhttps://aclanthology.org/Q16-1003/ .
Deep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben
Mann, Ethan Perez, Nicholas Schiefer, Kamal Ndousse, Andy Jones, Sam Bowman, Anna Chen,
Tom Conerly, Nova DasSarma, Dawn Drain, Nelson Elhage, Sheer El-Showk, Stanislav Fort,
Zac Hatfield-Dodds, Tom Henighan, Danny Hernandez, Tristan Hume, Josh Jacobson, Scott
Johnston, Shauna Kravec, Catherine Olsson, Sam Ringer, Eli Tran-Johnson, Dario Amodei, Tom
Brown, Nicholas Joseph, Sam McCandlish, Chris Olah, Jared Kaplan, and Jack Clark. Red
teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned.
arXiv, abs/2209.07858, 2022.
Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A. Smith. RealToxici-
tyPrompts: Evaluating neural toxic degeneration in language models. In Trevor Cohn, Yulan He,
and Yang Liu (eds.), Findings of the Association for Computational Linguistics: EMNLP 2020 ,
pp. 3356–3369, Online, November 2020. Association for Computational Linguistics. doi: 10.18653
/v1/2020.findings-emnlp.301. URL https://aclanthology.org/2020.findings-emnlp.301/ .
Gemma Gemini Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju,
Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay Kale, Juliette Love, et al. Gemma:
Open models based on gemini research and technology. arXiv preprint arXiv:2403.08295 , 2024.
Sourojit Ghosh and Aylin Caliskan. ChatGPT perpetuates gender bias in machine translation and
ignores non-gendered pronouns: Findings across bengali and five other low-resource languages,
2023. URL http://arxiv.org/abs/2305.10510 .
Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen, Guillaume Wenzek, Da Ju, San-
jana Krishnan, Marc’Aurelio Ranzato, Francisco Guzmán, and Angela Fan. The flores-101 eval-
uation benchmark for low-resource and multilingual machine translation. 2021.
25Annika Grützner-Zahn, Federico Gaspari, Maria Giagkou, Stefanie Hegele, Andy Way, and Georg
Rehm. Surveying the technology support of languages. In Federico Gaspari, Joss Moorkens, Itziar
Aldabe, Aritz Farwell, Begona Altuna, Stelios Piperidis, Georg Rehm, and German Rigau (eds.),
Proceedings of the Second International Workshop Towards Digital Language Equality (TDLE):
Focusing on Sustainability @ LREC-COLING 2024 , pp. 1–17, Torino, Italia, May 2024. ELRA
and ICCL. URL https://aclanthology.org/2024.tdle-1.1/ .
SrishtiGureja, LesterJamesV.Miranda, ShayekhBinIslam, RishabhMaheshwary, DrishtiSharma,
Gusti Winata, Nathan Lambert, Sebastian Ruder, Sara Hooker, and Marzieh Fadaee. M-
rewardbench: Evaluating reward models in multilingual settings, 2024. URL https://arxi
v.org/abs/2410.15522 .
Kai Hartung, Aaricia Herygers, Shubham Kurlekar, Khabbab Zakaria, Taylan Volkan, Sören
Gröttrup, and Munir Georges. Measuring sentiment bias in machine translation, 2023. URL
http://arxiv.org/abs/2306.07152 .
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob
Steinhardt. Measuring massive multitask language understanding. CoRR, abs/2009.03300, 2020.
URLhttps://arxiv.org/abs/2009.03300 .
Sara Hooker. On the limitations of compute thresholds as a governance strategy, 2024. URL
https://arxiv.org/abs/2407.05694 .
Franziska Horn. Exploring word usage change with continuously evolving embeddings. In Heng
Ji, Jong C. Park, and Rui Xia (eds.), Proceedings of the 59th Annual Meeting of the Association
for Computational Linguistics and the 11th International Joint Conference on Natural Language
Processing: System Demonstrations , pp. 290–297. Association for Computational Linguistics,
2021. doi: 10.18653/v1/2021.acl-demo.35. URL https://aclanthology.org/2021.acl-demo.
35.
Dirk Hovy and Diyi Yang. The importance of modeling social factors of language: Theory and prac-
tice. In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur, Iz Beltagy,
StevenBethard, RyanCotterell, TanmoyChakraborty, andYichaoZhou(eds.), Proceedings of the
2021 Conference of the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies ,pp.588–602.AssociationforComputationalLinguistics,2021. doi:
10.18653/v1/2021.naacl-main.49. URL https://aclanthology.org/2021.naacl-main.49 .
Adithya Venkatadri Hulagadri, Julia Kreutzer, Jian Gang Ngui, and Xian Bin Yong. Towards fair
and comprehensive multilingual llm benchmarking, 2025. URL https://cohere.com/blog/to
wards-fair-and-comprehensive-multilingual-and-multicultural-llm-benchmarking .
Kokil Jaidka, Niyati Chhaya, and Lyle Ungar. Diachronic degradation of language models: Insights
from social media. In Iryna Gurevych and Yusuke Miyao (eds.), Proceedings of the 56th Annual
Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) , pp. 195–
200. Association for Computational Linguistics, 2018. doi: 10.18653/v1/P18-2032. URL https:
//aclanthology.org/P18-2032 .
Meng Ji, Meng Ji, Pierrette Bouillon, and Mark Seligman. Cultural and Linguistic Bias of Neural
Machine Translation Technology , pp. 100–128. Studies in Natural Language Processing. Cam-
bridge University Press, 2023a.
26YunjieJi, YanGong, YongDeng, YipingPeng, QiangNiu, BaochangMa, andXiangangLi. Towards
better instruction following language models for chinese: Investigating the impact of training data
and evaluation, 2023b. URL http://arxiv.org/abs/2304.07854 .
Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury. The state and
fate of linguistic diversity and inclusion in the NLP world. In Dan Jurafsky, Joyce Chai, Natalie
Schluter, and Joel Tetreault (eds.), Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics , pp. 6282–6293, Online, July 2020. Association for Computational
Linguistics. doi: 10.18653/v1/2020.acl-main.560. URL https://aclanthology.org/2020.ac
l-main.560/ .
Anubha Kabra, Emmy Liu, Simran Khanuja, Alham Fikri Aji, Genta Winata, Samuel Cahyawijaya,
Anuoluwapo Aremu, Perez Ogayo, and Graham Neubig. Multi-lingual and multi-cultural figura-
tive language understanding. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (eds.),
Findings of the Association for Computational Linguistics: ACL 2023 , pp. 8269–8284, Toronto,
Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.finding
s-acl.525. URL https://aclanthology.org/2023.findings-acl.525/ .
Mohammed Safi Ur Rahman Khan, Priyam Mehta, Ananth Sankar, Umashankar Kumaravelan,
Sumanth Doddapaneni, Suriyaprasaad B, Varun G, Sparsh Jain, Anoop Kunchukuttan, Pratyush
Kumar, Raj Dabre, and Mitesh M. Khapra. IndicLLMSuite: A blueprint for creating pre-
training and fine-tuning datasets for Indian languages. In Lun-Wei Ku, Andre Martins, and
Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers) , pp. 15831–15879, Bangkok, Thailand, August
2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.843. URL
https://aclanthology.org/2024.acl-long.843/ .
Khyati Khandelwal, Manuel Tonneau, Andrew M. Bean, Hannah Rose Kirk, and Scott A. Hale.
Casteist but not racist? quantifying disparities in large language model bias between india and
the west. CoRR, abs/2309.08573, 2023. URL https://doi.org/10.48550/arXiv.2309.08573 .
Denis Kocetkov, Raymond Li, Loubna Ben Allal, Jia Li, Chenghao Mou, Carlos Muñoz Ferrandis,
Yacine Jernite, Margaret Mitchell, Sean Hughes, Thomas Wolf, Dzmitry Bahdanau, Leandro von
Werra, and Harm de Vries. The stack: 3 tb of permissively licensed source code, 2022.
Hadas Kotek, Rikker Dockum, and David Sun. Gender bias and stereotypes in large language
models. In Proceedings of The ACM Collective Intelligence Conference , CI ’23, pp. 12–24. ACM,
November 2023. doi: 10.1145/3582269.3615599. URL http://dx.doi.org/10.1145/3582269.3
615599.
JuliaKreutzer, IsaacCaswell, LisaWang, AhsanWahab, DaanvanEsch, NasanbayarUlzii-Orshikh,
Allahsera Tapo, Nishant Subramani, Artem Sokolov, Claytone Sikasote, Monang Setyawan,
Supheakmungkol Sarin, Sokhar Samb, Benoît Sagot, Clara Rivera, Annette Rios, Isabel Pa-
padimitriou, Salomey Osei, Pedro Ortiz Suarez, Iroro Orife, Kelechi Ogueji, Andre Niyongabo
Rubungo, Toan Q. Nguyen, Mathias Müller, André Müller, Shamsuddeen Hassan Muhammad,
Nanda Muhammad, Ayanda Mnyakeni, Jamshidbek Mirzakhalov, Tapiwanashe Matangira, Colin
Leong, Nze Lawson, Sneha Kudugunta, Yacine Jernite, Mathias Jenny, Orhan Firat, Bonaventure
F. P. Dossou, Sakhile Dlamini, Nisansa de Silva, Sakine Çabuk Ballı, Stella Biderman, Alessia
Battisti, Ahmed Baruwa, Ankur Bapna, Pallavi Baljekar, Israel Abebe Azime, Ayodele Awokoya,
Duygu Ataman, Orevaoghene Ahia, Oghenefego Ahia, Sweta Agrawal, and Mofetoluwa Adeyemi.
27Quality at a glance: An audit of web-crawled multilingual datasets. Transactions of the As-
sociation for Computational Linguistics , 10:50–72, 2022. doi: 10.1162/tacl_a_00447. URL
https://aclanthology.org/2022.tacl-1.4/ .
Anoop Kunchukuttan, Siddharth Jain, and Rahul Kejriwal. A large-scale evaluation of neural ma-
chine transliteration for indic languages. In Paola Merlo, Jorg Tiedemann, and Reut Tsarfaty
(eds.),Proceedings of the 16th Conference of the European Chapter of the Association for Com-
putational Linguistics: Main Volume , pp. 3469–3475. Association for Computational Linguistics,
2021. doi: 10.18653/v1/2021.eacl-main.303. URL https://aclanthology.org/2021.eacl-mai
n.303.
Viet Dac Lai, Chien Van Nguyen, Nghia Trung Ngo, Thuat Nguyen, Franck Dernoncourt, Ryan A.
Rossi, and Thien Huu Nguyen. Okapi: Instruction-tuned large language models in multiple
languages with reinforcement learning from human feedback, 2023. URL https://arxiv.org/
abs/2307.16039 .
Walter Laurito, Benjamin Davis, Peli Grietzer, Tomáš Gavenčiak, Ada Böhm, and Jan Kulveit. Ai
ai bias: Large language models favor their own generated content, 2024. URL https://arxiv.
org/abs/2407.12856 .
Alycia Lee, Brando Miranda, Sudharsan Sundar, and Sanmi Koyejo. Beyond scale: the diversity
coefficient as a data quality metric demonstrates LLMs are pre-trained on formally diverse data,
2023. URL http://arxiv.org/abs/2306.13840 .
Regina Lenart-Gansiniec, Wojciech Czakon, Łukasz Sułkowski, and Jasna Pocek. Understanding
crowdsourcing in science, 2023. ISSN 1863-6691. URL https://doi.org/10.1007/s11846-022
-00602-z .
ZihaoLi, YuchengShi, ZiruiLiu, FanYang, AliPayani, NinghaoLiu, andMengnanDu. Quantifying
multilingual performance of large language models across languages, 2024. URL http://arxiv.
org/abs/2404.11553 .
Fangyu Liu, Emanuele Bugliarello, Edoardo Maria Ponti, Siva Reddy, Nigel Collier, and Desmond
Elliott. Visually grounded reasoning across languages and cultures. In Marie-Francine Moens,
Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (eds.), Proceedings of the 2021 Conference
on Empirical Methods in Natural Language Processing , pp. 10467–10485, Online and Punta Cana,
Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653
/v1/2021.emnlp-main.818. URL https://aclanthology.org/2021.emnlp-main.818/ .
Shayne Longpre, Robert Mahari, Anthony Chen, Naana Obeng-Marnu, Damien Sileo, William
Brannon, Niklas Muennighoff, Nathan Khazam, Jad Kabbara, Kartik Perisetla, Xinyi Wu, Enrico
Shippole, Kurt Bollacker, Tongshuang Wu, Luis Villa, Sandy Pentland, and Sara Hooker. The
data provenance initiative: A large scale audit of dataset licensing & attribution in AI, 2023.
URLhttp://arxiv.org/abs/2310.16787 .
Shayne Longpre, Nikhil Singh, Manuel Cherep, Kushagra Tiwary, Joanna Materzynska, William
Brannon, Robert Mahari, Naana Obeng-Marnu, Manan Dey, Mohammed Hamdy, Nayan Saxena,
Ahmad Mustafa Anis, Emad A. Alghamdi, Vu Minh Chien, Da Yin, Kun Qian, Yizhi Li, Minnie
Liang, An Dinh, Shrestha Mohanty, Deividas Mataciunas, Tobin South, Jianguo Zhang, Ariel N.
Lee, Campbell S. Lund, Christopher Klamm, Damien Sileo, Diganta Misra, Enrico Shippole,
Kevin Klyman, Lester JV Miranda, Niklas Muennighoff, Seonghyeon Ye, Seungone Kim, Vipul
28Gupta, Vivek Sharma, Xuhui Zhou, Caiming Xiong, Luis Villa, Stella Biderman, Alex Pentland,
Sara Hooker, and Jad Kabbara. Bridging the data provenance gap across text, speech and video,
2024.
Holy Lovenia, Rahmad Mahendra, Salsabil Maulana Akbar, Lester James Validad Miranda, Jen-
nifer Santoso, Elyanah Aco, Akhdan Fadhilah, Jonibek Mansurov, Joseph Marvin Imperial,
Onno P. Kampman, Joel Ruben Antony Moniz, Muhammad Ravi Shulthan Habibi, Frederikus
Hudi, Jann Railey Montalan, Ryan Ignatius Hadiwijaya, Joanito Agili Lopo, William Nixon,
Börje F. Karlsson, James Jaya, Ryandito Diandaru, Yuze Gao, Patrick Amadeus Irawan, Bin
Wang, Jan Christian Blaise Cruz, Chenxi Whitehouse, Ivan Halim Parmonangan, Maria Khelli,
Wenyu Zhang, Lucky Susanto, Reynard Adha Ryanda, Sonny Lazuardi Hermawan, Dan John
Velasco, Muhammad Dehan Al Kautsar, Willy Fitra Hendria, Yasmin Moslem, Noah Flynn,
Muhammad Farid Adilazuarda, Haochen Li, Johanes Lee, R. Damanhuri, Shuo Sun, Muham-
mad Reza Qorib, Amirbek Djanibekov, Wei Qi Leong, Quyet V. Do, Niklas Muennighoff, Tan-
rada Pansuwan, Ilham Firdausi Putra, Yan Xu, Tai Ngee Chia, Ayu Purwarianti, Sebastian
Ruder, William Chandra Tjhi, Peerat Limkonchotiwat, Alham Fikri Aji, Sedrick Keh, Genta In-
dra Winata, Ruochen Zhang, Fajri Koto, Zheng Xin Yong, and Samuel Cahyawijaya. SEACrowd:
A multilingual multimodal data hub and benchmarksuite for SoutheastAsian languages. In Yaser
Al-Onaizan, Mohit Bansal, and Yun-Nung Chen (eds.), Proceedings of the 2024 Conference on
Empirical Methods in Natural Language Processing , pp. 5155–5203, Miami, Florida, USA, Novem-
ber 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.emnlp-main.296.
URLhttps://aclanthology.org/2024.emnlp-main.296/ .
Alexandre Magueresse, Vincent Carles, and Evan Heetderks. Low-resource languages: A review of
past work and future challenges, 2020. URL http://arxiv.org/abs/2006.07264 .
Max Marion, Ahmet Üstün, Luiza Pozzobon, Alex Wang, Marzieh Fadaee, and Sara Hooker. When
less is more: Investigating data pruning for pretraining LLMs at scale, 2023. URL http://arxi
v.org/abs/2309.04564 .
Laura Martinus and Jade Z. Abbott. A focus on neural machine translation for african languages.
CoRR, abs/1906.05685, 2019. URL http://arxiv.org/abs/1906.05685 .
Nestor Maslej, Loredana Fattorini, Raymond Perrault, Vanessa Parli, Anka Reuel, and Erik Bryn-
jolfsson. AI index report 2024, 2024. URL https://aiindex.stanford.edu/report/#individ
ual-chapters .
mistral team Mistral Team. Mistral.ai news: Ministraux, 2024a. URL https://mistral.ai/new
s/ministraux/ .
mistral team Mistral Team. Mistral.ai news: Ministraux, 2024b. URL https://mistral.ai/new
s/mixtral-8x22b/ .
Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven
Le Scao, M Saiful Bari, Sheng Shen, Zheng Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir
Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson,
Edward Raff, and Colin Raffel. Crosslingual generalization through multitask finetuning. In
Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (eds.), Proceedings of the 61st Annual
Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 15991–
16111. Association for Computational Linguistics, 2023a. doi: 10.18653/v1/2023.acl-long.891.
URLhttps://aclanthology.org/2023.acl-long.891 .
29Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le
Scao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir
Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson,
Edward Raff, and Colin Raffel. Crosslingual generalization through multitask finetuning, 2023b.
URLhttps://arxiv.org/abs/2211.01786 .
Tarek Naous, Michael J Ryan, Alan Ritter, and Wei Xu. Having beer after prayer? measuring
cultural bias in large language models. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar
(eds.),Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics
(Volume 1: Long Papers) , pp. 16366–16393, Bangkok, Thailand, August 2024. Association for
Computational Linguistics. doi: 10.18653/v1/2024.acl-long.862. URL https://aclanthology.o
rg/2024.acl-long.862/ .
Gabriel Nicholas and Aliya Bhatia. Lost in translation: Large language models in non-english
content analysis, 2023. URL https://arxiv.org/abs/2306.07377 .
Ayomide Odumakinde, Daniel D’souza, Pat Verga, Beyza Ermis, and Sara Hooker. Multilingual
arbitrage: Optimizing data pools to accelerate multilingual progress, 2024. URL https://arxi
v.org/abs/2408.14960 .
OECD. AI language models: Technological, socio-economic and policy considerations, 2023. URL
https://www.oecd-ilibrary.org/science-and-technology/ai-language-models_13d38f92
-en. Series: OECD Digital Economy Papers Volume: 352.
Jessica Ojo, Odunayo Ogundepo, Akintunde Oladipo, Kelechi Ogueji, Jimmy Lin, Pontus Stene-
torp, and David Ifeoluwa Adelani. Afrobench: How good are large language models on african
languages?, 2025. URL https://arxiv.org/abs/2311.07978 .
Martin Petty. Explainer: Why is Myanmar’s military holding an election?, 2023. URL https:
//www.reuters.com/world/asia-pacific/why-is-myanmars-military-holding-an-electio
n-2023-03-29/ . Accessed on Jan. 17, 2024.
Jonas Pfeiffer, Gregor Geigle, Aishwarya Kamath, Jan-Martin O. Steitz, Stefan Roth, Ivan Vulić,
and Iryna Gurevych. xGQA: Cross-lingual visual question answering. In Smaranda Muresan,
Preslav Nakov, and Aline Villavicencio (eds.), Findings of the Association for Computational
Linguistics: ACL 2022 , pp.2497–2511, Dublin, Ireland, May2022.AssociationforComputational
Linguistics. doi: 10.18653/v1/2022.findings-acl.196. URL https://aclanthology.org/2022.fi
ndings-acl.196/ .
Luiza Pozzobon, Beyza Ermis, Patrick Lewis, and Sara Hooker. Goodtriever: Adaptive toxicity
mitigation with retrieval-augmented models, 2023. URL http://arxiv.org/abs/2310.07589 .
Luiza Pozzobon, Patrick Lewis, Sara Hooker, and Beyza Ermis. From one to many: Expanding the
scope of toxicity mitigation in language models, 2024. URL http://arxiv.org/abs/2403.03893 .
Ayu Purwarianti, Dea Adhista, Agung Baptiso, Miftahul Mahfuzh, Yusrina Sabila, Aulia Adila,
Samuel Cahyawijaya, and Alham Fikri Aji. NusaDialogue: Dialogue summarization and genera-
tion for underrepresented and extremely low-resource languages. In Derry Wijaya, Alham Fikri
Aji, Clara Vania, Genta Indra Winata, and Ayu Purwarianti (eds.), Proceedings of the Second
Workshop in South East Asian Language Processing , pp. 82–100, Online, January 2025. Associa-
tion for Computational Linguistics. URL https://aclanthology.org/2025.sealp-1.8/ .
30qwen team Qwen Team. Qwen2.5: A party of foundation models, September 2024. URL https:
//qwenlm.github.io/blog/qwen2.5/ .
Surangika Ranathunga and Nisansa de Silva. Some languages are more equal than others: Probing
deeper into the linguistic disparity in the NLP world. In Yulan He, Heng Ji, Sujian Li, Yang
Liu, and Chua-Hui Chang (eds.), Proceedings of the 2nd Conference of the Asia-Pacific Chapter
of the Association for Computational Linguistics and the 12th International Joint Conference
on Natural Language Processing (Volume 1: Long Papers) , pp. 823–848, Online only, November
2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.aacl-main.62. URL
https://aclanthology.org/2022.aacl-main.62/ .
Reuters. Explainer: What is happening between Armenia and Azerbaijan over Nagorno-Karabakh?,
2023. URL https://www.reuters.com/world/what-is-happening-between-armenia-azerb
aijan-over-nagorno-karabakh-2023-09-19/ . Accessed on Jan. 17, 2024.
Angelika Romanou, Negar Foroutan, Anna Sotnikova, Sree Harsha Nelaturu, Shivalika Singh,
Rishabh Maheshwary, Micol Altomare, Zeming Chen, Mohamed A. Haggag, Snegha A, Al-
fonso Amayuelas, Azril Hafizi Amirudin, Danylo Boiko, Michael Chang, Jenny Chim, Gal Cohen,
Aditya Kumar Dalmia, Abraham Diress, Sharad Duwal, Daniil Dzenhaliou, Daniel Fernando Er-
azo Florez, Fabian Farestam, Joseph Marvin Imperial, Shayekh Bin Islam, Perttu Isotalo, Maral
Jabbarishiviari, Börje F. Karlsson, Eldar Khalilov, Christopher Klamm, Fajri Koto, Dominik
Krzemiński, Gabriel Adriano de Melo, Syrielle Montariol, Yiyang Nan, Joel Niklaus, Jekaterina
Novikova, JohanSamirObandoCeron, DebjitPaul, EstherPloeger, JebishPurbey, SwatiRajwal,
Selvan Sunitha Ravi, Sara Rydell, Roshan Santhosh, Drishti Sharma, Marjana Prifti Skenduli,
Arshia Soltani Moakhar, Bardia soltani moakhar, Ayush Kumar Tarun, Azmine Toushik Wasi,
Thenuka Ovin Weerasinghe, Serhan Yilmaz, Mike Zhang, Imanol Schlag, Marzieh Fadaee, Sara
Hooker, and Antoine Bosselut. INCLUDE: Evaluating multilingual language understanding with
regional knowledge. In The Thirteenth International Conference on Learning Representations ,
2025. URL https://openreview.net/forum?id=k3gCieTXeY .
David Romero, Chenyang Lyu, Haryo Wibowo, Santiago Góngora, Aishik Mandal, Sukannya
Purkayastha, Jesus-German Ortiz-Barajas, Emilio Cueva, Jinheon Baek, Soyeong Jeong, et al.
Cvqa: Culturally-diverse multilingual visual question answering benchmark. Advances in Neural
Information Processing Systems , 37:11479–11505, 2025.
Israfel Salazar, Manuel Fernández Burda, Shayekh Bin Islam, Arshia Soltani Moakhar, Shivalika
Singh, Fabian Farestam, Angelika Romanou, Danylo Boiko, Dipika Khullar, Mike Zhang, Do-
minik Krzemiński, Jekaterina Novikova, Luísa Shimabucoro, Joseph Marvin Imperial, Rishabh
Maheshwary, Sharad Duwal, Alfonso Amayuelas, Swati Rajwal, Jebish Purbey, Ahmed Ruby,
Nicholas Popovič, Marek Suppa, Azmine Toushik Wasi, Ram Mohan Rao Kadiyala, Olga Tsym-
boi, Maksim Kostritsya, Bardia Soltani Moakhar, Gabriel da Costa Merlin, Otávio Ferracioli Co-
letti, Maral Jabbari Shiviari, MohammadAmin farahani fard, Silvia Fernandez, María Grandury,
Dmitry Abulkhanov, Drishti Sharma, Andre Guarnier De Mitri, Leticia Bossatto Marchezi, Se-
tayesh Heydari, Johan Obando-Ceron, Nazar Kohut, Beyza Ermis, Desmond Elliott, Enzo Fer-
rante, Sara Hooker, and Marzieh Fadaee. Kaleidoscope: In-language exams for massively multi-
lingual vision evaluation, 2025. URL https://arxiv.org/abs/2504.07072 .
Nithya Sambasivan, Erin Arnesen, Ben Hutchinson, Tulsee Doshi, and Vinodkumar Prabhakaran.
Re-imagining algorithmic fairness in india and beyond, 2021. URL http://arxiv.org/abs/21
01.09995 .
31Beatrice Savoldi, Marco Gaido, Luisa Bentivogli, Matteo Negri, and Marco Turchi. Gender bias in
machine translation. Transactions of the Association for Computational Linguistics , 9:845–874,
2021. doi: 10.1162/tacl_a_00401. URL https://aclanthology.org/2021.tacl-1.51/ .
Reva Schwartz, Apostol Vassilev, Kristen K. Greene, Lori Perine, Andrew Burt, and Patrick Hall.
Towardsastandardforidentifyingandmanagingbiasinartificialintelligence, 2022-03-1504:03:00
2022. URL https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=934464 .
Lingfeng Shen, Weiting Tan, Sihao Chen, Yunmo Chen, Jingyu Zhang, Haoran Xu, Boyuan Zheng,
Philipp Koehn, and Daniel Khashabi. The language barrier: Dissecting safety challenges of LLMs
in multilingual contexts. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Findings
of the Association for Computational Linguistics: ACL 2024 , pp. 2668–2680, Bangkok, Thailand,
August 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.156.
URLhttps://aclanthology.org/2024.findings-acl.156/ .
Shivalika Singh, Freddie Vargus, Daniel Dsouza, Börje F. Karlsson, Abinaya Mahendiran, Wei-Yin
Ko, Herumb Shandilya, Jay Patel, Deividas Mataciunas, Laura OMahony, Mike Zhang, Ramith
Hettiarachchi, Joseph Wilson, Marina Machado, Luisa Souza Moura, Dominik Krzemiński,
Hakimeh Fadaei, Irem Ergün, Ifeoma Okoh, Aisha Alaagib, Oshan Mudannayake, Zaid Alyafeai,
Vu Minh Chien, Sebastian Ruder, Surya Guthikonda, Emad A. Alghamdi, Sebastian Gehrmann,
Niklas Muennighoff, Max Bartolo, Julia Kreutzer, Ahmet Üstün, Marzieh Fadaee, and Sara
Hooker. Aya dataset: An open-access collection for multilingual instruction tuning, 2024. URL
http://arxiv.org/abs/2402.06619 .
Shivalika Singh, Angelika Romanou, Clémentine Fourrier, David I. Adelani, Jian Gang Ngui, Daniel
Vila-Suero, PeeratLimkonchotiwat, KellyMarchisio, WeiQiLeong, YosephineSusanto, Raymond
Ng, Shayne Longpre, Wei-Yin Ko, Sebastian Ruder, Madeline Smith, Antoine Bosselut, Alice Oh,
Andre F. T. Martins, Leshem Choshen, Daphne Ippolito, Enzo Ferrante, Marzieh Fadaee, Beyza
Ermis, and Sara Hooker. Global mmlu: Understanding and addressing cultural and linguistic
biases in multilingual evaluation, 2025. URL https://arxiv.org/abs/2412.03304 .
Ben Sorscher, Robert Geirhos, Shashank Shekhar, Surya Ganguli, and Ari S. Morcos. Beyond neural
scaling laws: beating power law scaling via data pruning, 2023.
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Rad-
ford, Dario Amodei, and Paul F Christiano. Learning to summarize with human feedback. In
H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances in Neural In-
formation Processing Systems , volume 33, pp. 3008–3021. Curran Associates, Inc., 2020. URL
https://proceedings.neurips.cc/paper_files/paper/2020/file/1f89885d556929e98d3ef
9b86448f951-Paper.pdf .
Zeerak Talat, Aurélie Névéol, Stella Biderman, Miruna Clinciu, Manan Dey, Shayne Longpre, Sasha
Luccioni, Maraim Masoud, Margaret Mitchell, Dragomir Radev, Shanya Sharma, Arjun Subra-
monian, Jaesung Tae, Samson Tan, Deepak Tunuguntla, and Oskar Van Der Wal. You reap what
you sow: On the challenges of bias evaluation under multilingual settings. In Angela Fan, Suzana
Ilic, Thomas Wolf, and Matthias Gallé (eds.), Proceedings of BigScience Episode #5 – Workshop
on Challenges & Perspectives in Creating Large Language Models , pp. 26–41, virtual+Dublin,
May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.bigscience-1.3.
URLhttps://aclanthology.org/2022.bigscience-1.3/ .
32Alex Tamkin, Miles McCain, Kunal Handa, Esin Durmus, Liane Lovitt, Ankur Rathi, Saffron
Huang, Alfred Mountfield, Jerry Hong, Stuart Ritchie, Michael Stern, Brian Clarke, Landon
Goldberg, Theodore R. Sumers, Jared Mueller, William McEachen, Wes Mitchell, Shan Carter,
Jack Clark, Jared Kaplan, and Deep Ganguli. Clio: Privacy-preserving insights into real-world
ai use, 2024. URL https://arxiv.org/abs/2412.13678 .
Jingqun Tang, Qi Liu, Yongjie Ye, Jinghui Lu, Shu Wei, Chunhui Lin, Wanqing Li, Mohamad Fitri
Faiz Bin Mahmood, Hao Feng, Zhen Zhao, et al. Mtvqa: Benchmarking multilingual text-centric
visual question answering. CoRR, 2024.
RossTaylor, MarcinKardas, GuillemCucurull, ThomasScialom, AnthonyHartshorn, ElvisSaravia,
Andrew Poulton, Viktor Kerkez, and Robert Stojnic. Galactica: A large language model for
science, 2022.
Megh Thakkar, Tolga Bolukbasi, Sriram Ganapathy, Shikhar Vashishth, Sarath Chandar, and
Partha Talukdar. Self-influence guided data reweighting for language model pre-training, 2023.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée
Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Ar-
mand Joulin, Edouard Grave, and Guillaume Lample. LLaMA: Open and efficient foundation
language models, 2023a. URL http://arxiv.org/abs/2302.13971 .
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-
lay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher,
Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy
Fu, WenyinFu, BrianFuller, CynthiaGao, VedanujGoswami, NamanGoyal, AnthonyHartshorn,
Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel
Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee,
Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,
Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi,
Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh
Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov,
Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert
Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat
models.arXiv, abs/2307.09288, 2023b.
Marcos Treviso, Ji-Ung Lee, Tianchu Ji, Betty van Aken, Qingqing Cao, Manuel R. Ciosici, Michael
Hassid, Kenneth Heafield, Sara Hooker, Colin Raffel, Pedro H. Martins, André F. T. Martins,
Jessica Zosa Forde, Peter Milder, Edwin Simpson, Noam Slonim, Jesse Dodge, Emma Strubell,
Niranjan Balasubramanian, Leon Derczynski, Iryna Gurevych, and Roy Schwartz. Efficient meth-
ods for natural language processing: A survey. Transactions of the Association for Computa-
tional Linguistics , 11:826–860, 07 2023. ISSN 2307-387X. doi: 10.1162/tacl_a_00577. URL
https://doi.org/10.1162/tacl_a_00577 .
Lewis Tunstall, Edward Emanuel Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul,
Younes Belkada, Shengyi Huang, Leandro Von Werra, Clémentine Fourrier, Nathan Habib,
Nathan Sarrazin, Omar Sanseviero, Alexander M Rush, and Thomas Wolf. Zephyr: Di-
rect distillation of LM alignment. In First Conference on Language Modeling , 2024. URL
https://openreview.net/forum?id=aKkAwZB6JV .
33Ahmet Üstün, Viraat Aryabumi, Zheng Yong, Wei-Yin Ko, Daniel D’souza, Gbemileke Onilude,
Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne
Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, and Sara Hooker. Aya model: An
instruction finetuned open-access multilingual language model. In Lun-Wei Ku, Andre Martins,
and Vivek Srikumar (eds.), Proceedings of the 62nd Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers) , pp. 15894–15939, Bangkok, Thailand, August
2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.845. URL
https://aclanthology.org/2024.acl-long.845/ .
Eva Vanmassenhove, Dimitar Shterionov, and Matthew Gwilliam. Machine translationese: Ef-
fects of algorithmic bias on linguistic complexity in machine translation. In Paola Merlo, Jorg
Tiedemann, and Reut Tsarfaty (eds.), Proceedings of the 16th Conference of the European Chap-
ter of the Association for Computational Linguistics: Main Volume , pp. 2203–2213. Associa-
tion for Computational Linguistics, 2021. doi: 10.18653/v1/2021.eacl-main.188. URL
https://aclanthology.org/2021.eacl-main.188 .
Cécile B. Vigouroux. Francophonie, 2013. ISSN 0084-6570, 1545-4290. URL https://www.annual
reviews.org/doi/10.1146/annurev-anthro-092611-145804 .
Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang,
Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, Zac Kenton, Sasha Brown, Will
Hawkins, Tom Stepleton, Courtney Biles, Abeba Birhane, Julia Haas, Laura Rimell, Lisa Anne
Hendricks, William Isaac, Sean Legassick, Geoffrey Irving, and Iason Gabriel. Ethical and social
risks of harm from language models, 2021. URL https://arxiv.org/abs/2112.04359 .
ChrisWendler, VeniaminVeselovsky, GiovanniMonea, andRobertWest. Dollamasworkinenglish?
on the latent language of multilingual transformers, 2024. URL http://arxiv.org/abs/2402.1
0588.
Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya, Rahmad Mahendra, Fajri Koto, Ade
Romadhony, Kemal Kurniawan, David Moeljadi, Radityo Eko Prasojo, Pascale Fung, Timo-
thy Baldwin, Jey Han Lau, Rico Sennrich, and Sebastian Ruder. NusaX: Multilingual par-
allel sentiment dataset for 10 Indonesian local languages. In Andreas Vlachos and Isabelle
Augenstein (eds.), Proceedings of the 17th Conference of the European Chapter of the Asso-
ciation for Computational Linguistics , pp. 815–834, Dubrovnik, Croatia, May 2023. Associa-
tion for Computational Linguistics. doi: 10.18653/v1/2023.eacl-main.57. URL https:
//aclanthology.org/2023.eacl-main.57/ .
Zheng Xin Yong, Cristina Menghini, and Stephen Bach. Low-resource languages jailbreak GPT-4.
InWorkshopSocially Responsible Language Modelling Research , 2023a. URL https://openrevi
ew.net/forum?id=pn83r8V2sv .
Zheng Xin Yong, Ruochen Zhang, Jessica Forde, Skyler Wang, Arjun Subramonian, Holy Lovenia,
Samuel Cahyawijaya, Genta Winata, Lintang Sutawika, Jan Christian Blaise Cruz, Yin Lin Tan,
Long Phan, Long Phan, Rowena Garcia, Thamar Solorio, and Alham Fikri Aji. Prompting mul-
tilingual large language models to generate code-mixed texts: The case of south East Asian lan-
guages. In Genta Winata, Sudipta Kar, Marina Zhukova, Thamar Solorio, Mona Diab, Sunayana
Sitaram, Monojit Choudhury, and Kalika Bali (eds.), Proceedings of the 6th Workshop on Com-
putational Approaches to Linguistic Code-Switching , pp. 43–63, Singapore, December 2023b. As-
sociation for Computational Linguistics. URL https://aclanthology.org/2023.calcs-1.5/ .
34Xiang Yue, Yueqi Song, Akari Asai, Seungone Kim, Jean de Dieu Nyandwi, Simran Khanuja, Anjali
Kantharuban, Lintang Sutawika, Sathyanarayanan Ramamoorthy, and Graham Neubig. Pangea:
A fully open multilingual multimodal llm for 39 languages. arXiv preprint arXiv:2410.16153 ,
2024. URL https://arxiv.org/abs/2410.16153 .
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,
Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.
Judging LLM-as-a-judge with MT-bench and chatbot arena. In Thirty-seventh Conference on
Neural Information Processing Systems Datasets and Benchmarks Track , 2023. URL https:
//openreview.net/forum?id=uccHPGDlao .
AndyZou, ZifanWang, NicholasCarlini, MiladNasr, J.ZicoKolter, andMattFredrikson. Universal
and transferable adversarial attacks on aligned language models, 2023. URL https://arxiv.or
g/abs/2307.15043 .
35