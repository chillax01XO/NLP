GGBond: Growing Graph-Based AI-Agent Society
for Socially-Aware Recommender Simulation
Hailin Zhong1, Hanlin Wang1, Yujun Ye1, Meiyi Zhang1, Shengxin Zhu2,1
1Faculty of Science and Technology, Beijing Normal-Hong Kong Baptist University , Zhuhai, China
2Research Centers for Mathematics, Advanced Institute of Natural Sciences, Beijing Normal University , Zhuhai, China
{r130026215, r130026135, r130026180, r130026169}@mail.uic.edu.cn, shengxinzhu@uic.edu.cn
Abstract —Current personalized recommender systems pre-
dominantly rely on static offline data for algorithm design and
evaluation, significantly limiting their ability to capture long-
term user preference evolution and social influence dynamics
in real-world scenarios. To address this fundamental challenge,
we propose a high-fidelity social simulation platform integrating
human-like cognitive agents and dynamic social interactions
to realistically simulate user behavior evolution under recom-
mendation interventions. Specifically, the system comprises a
population of Sim-User Agents, each equipped with a five-
layer cognitive architecture that encapsulates key psycholog-
ical mechanisms, including episodic memory, affective state
transitions, adaptive preference learning, and dynamic trust-
risk assessments. In particular, we innovatively introduce the
Intimacy–Curiosity–Reciprocity–Risk (ICR²) motivational engine
grounded in psychological and sociological theories, enabling
more realistic user decision-making processes. Furthermore, we
construct a multilayer heterogeneous social graph (GGBond
Graph) supporting dynamic relational evolution, effectively mod-
eling users’ evolving social ties and trust dynamics based on inter-
est similarity, personality alignment, and structural homophily.
During system operation, agents autonomously respond to recom-
mendations generated by typical recommender algorithms (e.g.,
Matrix Factorization, MultV AE, LightGCN), deciding whether
to consume, rate, and share content while dynamically updating
their internal states and social connections, thereby forming
a stable, multi-round feedback loop. This innovative design
transcends the limitations of traditional static datasets, providing
a controlled, observable environment for evaluating long-term
recommender effects.
Index Terms —AI-Agent, Simulation system, Recommender
system, Social network.
I. I NTRODUCTION
In recent years, personalized recommender systems have
become widely deployed across digital platforms to alleviate
information overload and deliver precise content matching.
While such systems have significantly improved user expe-
rience and platform performance, mainstream research and
evaluation practices remain heavily dependent on static his-
torical logs. These static datasets provide only a snapshot
of user behaviors, failing to reflect how user preferences
evolve over long-term interactions or how social influences
shape recommendation acceptance. Prior work has shown that
ignoring such dynamics can lead to short-sighted optimization,filter bubbles, and even polarization effects in recommender
outputs. Thus, enabling recommendation algorithms to under-
stand, adapt to, and be evaluated under long-term behavioral
dynamics and social interactivity remains a fundamental yet
unresolved challenge in the field.
To address these limitations, several simulation-based eval-
uation frameworks have been proposed (e.g., RecSim), aiming
to test recommendation algorithms beyond static data. How-
ever, most of these simulators model users as reward-driven
policy executors, lacking the ability to emulate realistic hu-
man decision-making processes that involve memory, emotion,
evolving preferences, and social cognition. Meanwhile, the
majority of social recommendation models still rely on static
adjacency graphs, which overlook key sociological features
such as tie-strength drift, trust evolution, multi-context social
layers, and indirect influence propagation [39]. These simpli-
fications critically hinder our ability to study recommender
systems in real-world interactive and socially complex envi-
ronments.
To bridge these gaps, we argue for the construction of a
high-fidelity simulation environment that jointly models cog-
nitive user behavior, heterogeneous social structure, and causal
feedback loops. In such an environment, each user should
demonstrate rich internal decision-making behavior—affected
by memory, affective state, and evolving interests—while
simultaneously engaging in social interactions guided by inti-
macy, trust, and reciprocity. These interactions, in turn, should
influence content diffusion and preference updates over time.
A simulation platform of this nature would not only provide
an expressive substitute for limited real-world datasets but also
enable rigorous testing of recommendation algorithms under
complex dynamics and long-term feedback.
In this work, we propose a novel high-fidelity simulation
platform Growth Graph-based Recommendation System via
AI-Agent Social Bonds (GGBond) for recommender systems
that models both user cognition and social interaction. The
platform consists of two core components: (1) a population
of simulated user agents with psychologically grounded cog-
nitive architectures, and (2) a dynamically evolving multi-
layer social graph (GGBond Graph) that supports heteroge-
neous semantics and multi-dimensional social relations. Each
simulated agent is endowed with a five-layer architecture thatarXiv:2505.21154v1  [cs.MA]  27 May 2025Figure 1. GGBond System Architecture: Rrecommender Engine, Database, Social network, Agent
includes memory, emotion, preferences, trust assessment, and
natural language generation, enabling fine-grained modeling
of internal decision processes. The decision of whether to
consume and share content is governed by a psychologically-
inspired motivational engine (ICR²), which integrates intimacy
(I), novelty ( N), reciprocity potential ( R), and risk perception
(K) into a unified decision score. On the structural side,
we enrich an anonymized real-world topology (e.g., Stanford
Facebook graph) with inferred personality vectors using a
structure-driven inference model, and construct layered graphs
capturing interest similarity, personality alignment, and struc-
tural homophily. The system is executed under a discrete-
time simulation engine. In each time step, a recommendation
model (e.g., Matrix Factorization, MultV AE, or LightGCN)
generates candidate content based on the current state of
users and the social graph. Simulated agents autonomously
decide whether to watch, rate, and share the content. These
behaviors trigger updates to the agent’s internal state and
modify the social graph accordingly. All behavioral signals
and structural dynamics are recorded, enabling multifaceted
evaluation of recommender algorithms on metrics such as
preference drift, diversity, and social influence. Additionally,
these records serve as empirical validation of the simulation’s
behavioral realism.
Compared to existing approaches, our proposed system
makes the following structural contributions:•We introduce a simulation paradigm that integrates
human-like cognition and social evolution, enabling long-
term recommender evaluation beyond static logs;
•We design a psychologically grounded agent architecture
incorporating memory, affect, preference, and a novel
ICR² motivational engine to simulate realistic user de-
cisions;
•We construct a heterogeneous, multi-context, and dy-
namically updating social graph that reflects evolving
intimacy and trust relationships; and
•We provide an extensible evaluation platform that sup-
ports the integration of representative recommendation al-
gorithms and enables systematic analysis of their perfor-
mance and social impact in realistic interactive settings.
II. GGB OND SYSTEM ARCHITECTURE
To simulate user behavior in a socially contextualized
recommendation environment with high fidelity, we design a
virtual society framework composed of a population of Sim-
User Agents and a multi-layer heterogeneous social graph
called the GGBond Social Network . The system architecture
is clearly presented in Figure 1. This system is built not
only to reproduce realistic cognitive and behavioral patterns
of individuals under social influence, but also to serve as a
controlled, repeatable testbed for evaluating the performanceof mainstream recommendation algorithms in complex user
scenarios.
During initialization, we construct an anonymized social
graph based on the Stanford Facebook dataset and enrich each
node with Big-Five personality traits through a structure-driven
inference framework. The resulting hybrid profile integrates
structural features and psychological traits. On top of this,
we define a multi-layer social network consisting of interest-
based, personality-based, and structural homophily layers,
all of which are fused into a unified layer for downstream
reasoning. This network supports layered semantic modeling
and serves as the basis for trust estimation, social propagation,
and motivational reasoning.
Each agent operates through a five-Module cognitive archi-
tecture. The language reasoning core (Module 0) generates
natural language outputs for commentary and interaction; the
individual cognition Module (Module 1) models memory,
affective state, and evolving content preferences; the social
cognition Module (Module 2) maintains multi-dimensional
intimacy scores and trust estimations toward other agents; the
motivational engine (Module 3) computes the internal drive
Cbased on intimacy ( I), novelty ( N), reciprocity potential
(R), and risk perception ( K); and the behavior output Module
(Module 4) executes watch, rate, and share actions, writing
feedback back into upper Modules, forming a complete per-
ception–decision–action loop.
The system runs on a discrete time-step simulation en-
gine. Each time step corresponds to an actionable social or
system-triggered recommendation opportunity. A scheduler
activates agents sequentially, allowing them to perceive in-
coming content, evaluate it, and autonomously decide whether
to consume, rate, and propagate it. This asynchronous update
scheme better reflects real-world behavioral heterogeneity than
synchronous models and avoids unrealistic global coordination
assumptions.
Recommendation algorithms are embedded within this
evolving simulation. At each time step, algorithms take as
input the current state of the agents and social graph, generat-
ing personalized candidate recommendations. Agents, in turn,
respond to these recommendations according to their current
internal states. This interaction forms a closed evaluation loop,
allowing us to monitor both traditional metrics (e.g., CTR,
acceptance rate, diversity) and long-term behavioral conse-
quences (e.g., preference drift, social influence spread). The
system supports both periodic algorithmic interventions and
context-sensitive triggers, such as increased activity periods
or mismatched preference stages.
Throughout the simulation, we collect a wide range of
structural and behavioral metrics, including graph dynamics
(e.g., density, community shifts), internal agent state distri-
butions (e.g., affect variation, preference entropy), and recom-
mendation interaction traces. A built-in write-back mechanism
ensures that every decision made by the agent has forward-
propagating consequences, enabling systematic analysis of
long-term recommender interventions.
The system currently supports three representative recom-mendation algorithms: Matrix Factorization, MultV AE, and
LightGCN. These algorithms operate directly on the evolving
user profiles and social graph, allowing for unified evaluation
across personalization quality, social robustness, and adapta-
tion under long-term user drift. This dual evaluation paradigm
not only benchmarks algorithmic performance in realistic
environments but also serves as indirect validation of our
simulation framework’s behavioral and structural credibility.
Through the coordinated design of internal cognitive agents
and an external multi-layer social network, the system offers a
scalable, interpretable, and behaviorally grounded simulation
platform for research in personalized recommendation, social
trust modeling, and emergent group behavior dynamics.
III. S OCIAL NETWORK ARCHITECTURE
This study presents an advanced social network architec-
ture, meticulously crafted to synthesize anonymized structural
attributes from the Stanford Facebook social graph [20] with
nuanced personality profiles inferred from external behavioral
datasets, such as MovieLens [10], Steam [16], and Ama-
zonBooks [23], which offer rich textual review corpora for
psychological analysis [33]. The fundamental challenge under-
pinning this integration arises from the inherent anonymization
of the Stanford dataset—core demographic attributes including
occupation, educational background, and age are withheld, ef-
fectively precluding direct personality alignment with external
datasets.
To navigate this complexity, we propose a robust two-stage,
structure-driven inferential framework that capitalizes solely
on the intrinsic topology of the social graph to predict latent
Big-Five personality traits for each node. In the first stage
(illustrated in Figure 2), we leverage textual reviews from
AmazonBooks, Steam, and MovieLens datasets to extract Big-
Five personality traits using a pre-trained RoBERTa model.
Simultaneously, we derive behavioral statistics from user in-
teractions in MovieLens, including activity level, diversity,
rating deviation, and novelty preference. In the second stage
(shown in Figure 3), the trained MLP model is applied to the
Stanford network. Here, structurally analogous features are ex-
tracted solely from network topology—node degree for social
activity, entropy-based neighbor diversity for social diversity,
betweenness centrality [7] for deviation from mainstream, and
PageRank scores [27] for novelty preference. These features
serve as proxies for traditional psychological indicators within
the social graph context [19]. The learned mapping enables the
prediction of Big-Five traits for anonymized nodes.
A. Personality Prediction Model
To predict the Big-Five personality traits (Openness, Con-
scientiousness, Extraversion, Agreeableness, Neuroticism), we
train a multi-task regression model using behavioral data
extracted from the MovieLens dataset. Each user is represented
by four interpretable features grounded in their historical
interactions:Figure 2. Big-5 Model Training Process
Definition III.1 (Activity Level) .Activity Level Tact
udenotes
the total number of items rated by user u, capturing their
engagement intensity:
Tact
u=X
i∈Iu1, (1)
where Iuis the set of items rated by user u.
Definition III.2 (Diversity) .Diversity Tdiv
umeasures the en-
tropy of genre distribution among all rated items, reflecting
the breadth of a user’s interests:
Tdiv
u=−X
g∈Gpu,glogpu,g, p u,g=|{i∈Iu|genrei=g}|
|Iu|,
(2)
where Gis the set of all genres.
Definition III.3 (Conformity Deviation) .Conformity Devia-
tionTconf
uquantifies the deviation of user u’s ratings from the
global consensus:
Tconf
u=1
|Iu|X
i∈Iu(rui−¯Ri)2, (3)
where ruiis the rating given by user uto item i, and ¯Riis
the average rating for item iacross all users.
Definition III.4 (Novelty Seeking) .Novelty Seeking Tnov
u
captures the user’s tendency to interact with less popular (i.e.,
rare) items:
Tnov
u=1
|Iu|X
i∈Iu1
pop(i),pop(i) =|{u′|i∈Iu′}|,(4)
where pop (i)is the popularity of item i, defined as the
number of users who rated it.
This trained model is subsequently applied to structural
features derived from the Stanford social graph, enabling
cross-domain personality prediction for anonymized nodes.B. Structure-based Feature Engineering
Definition III.5 (Social Activity) .The Social Activity ( kv) is
defined as the node degree, representing the number of direct
connections a node has in the social graph, analogous to user
activity level.
Definition III.6 (Social Diversity) .The Social Diversity ( dv)
is computed as the entropy of anonymized occupation or
education labels among a node’s immediate neighbors, rep-
resenting the variety in a node’s social contacts:
dv=−X
cpclog(pc), (5)
where pcdenotes the proportion of neighbors belonging to
category c.
Definition III.7 (Deviation from Mainstream) .The Deviation
from Mainstream ( cv) is captured via betweenness centrality,
measuring the extent to which a node acts as a bridge between
distinct social communities, thus indicating non-conformity:
cv=X
s̸=v̸=t∈Vσst(v)
σst, (6)
where σstis the total number of shortest paths between nodes s
andt, and σst(v)is the number of these paths passing through
node v.
Definition III.8 (Novelty Preference) .The Novelty Preference
(pv) is measured by the node’s PageRank score, reflecting a
node’s position relative to network prominence, with lower
scores indicating a preference towards peripheral or less main-
stream connections:
pv=αX
u∈N(v)pu
|N(u)|+1−α
|V|, (7)
where N(v)is the set of neighbors of node v, and αis the
damping factor (typically 0.85).
Finally, the structural feature vector xvfor each node vis
defined as:
xv= [kv, dv, cv, pv]. (8)
C. Personality Reasoning Process
To predict the Big-Five personality traits (Openness, Con-
scientiousness, Extraversion, Agreeableness, Neuroticism) for
Stanford nodes, we trained a multi-task regression model using
data derived from Real banchmark datasets’ user behaviors
and personality traits extracted from textual reviews. Specif-
ically, we utilized a pre-trained RoBERTa-based classifier on
MovieLens textual data to label user personalities and trained
a neural network fθto map structural behavior features to
personality vectors:
ˆbv=fθ(xv), (9)
where ˆbvdenotes the predicted Big-Five personality vector
for node v.
The model was trained on real datasets features and evalu-
ated based on the RMSE and Pearson correlation metrics on aFigure 3. Big-5 Alignment Framework
hold-out set, achieving robust predictive performance (RMSE
<0.1, Pearson r >0.6). The trained model was subsequently
applied to predict the personality traits of Stanford network
nodes, producing personality-enriched node representations
without reliance on explicit personal data.
D. Big-Five Mapping
In the Stanford social network dataset, each node vis
originally described by a set of anonymized social attributes
and topological features, formally represented as:
tu= [t1, t2, t3, t4], (10)
where: t1denotes the number of connected edges (degree).
t2represents the anonymized occupation identifier. t3repre-
sents the anonymized age group identifier. t4represents the
anonymized education identifier.
Following the Big-Five personality prediction process, we
enrich this attribute vector by appending the predicted Big-
Five personality traits, denoted as:
bv= [b1, b2, b3, b4, b5], (11)
where each bicorresponds to one dimension of the Big-
Five personality (Openness, Conscientiousness, Extraversion,
Agreeableness, Neuroticism), scaled within the range [0,1].
The complete profile vector for node wthus becomes:
pw= [tu,bv]. (12)
This unified representation integrates structural social at-
tributes and latent psychological traits, providing a comprehen-
sive embedding for each node. Such enriched profiles facilitate
downstream tasks, including personalized recommendation
and social influence modeling, by co-optimizing structural and
psychological dimensions within the network.
E. GGBond Social Network
Building upon the personality-enriched node representation
pu= [tu,bu], where tu∈R4denotes anonymized struc-
tural attributes (e.g., degree, occupation, age, education), and
bu∈R5represents predicted Big-Five personality traits, the
GGBond framework constructs a multilayer social graph Gto
simulate user interactions, trust propagation, and preference
shifts.As visualized in Figure 4, the architecture is composed of
several semantically distinct graph layers, each encoding a
different dimension of social similarity or homophily.
Figure 4. GGBond Multi-layer Social Network Framework. Each colored
plane represents a type of social edge (Interest, Personality, Structural, or
Unified), with dotted connections modeling influence across layers. Agents
(nodes) are embedded in all layers simultaneously. The aggregation and
propagation mechanism across these layers enables personality drift and
preference adaptation.
a) Interest Graph Layer.: In the top (cyan) layer, edges
are created based on user preference overlap. An undirected
edge is formed between agents uandvif they share liked
movie types, weighted by Jaccard similarity:
wint
uv=|Mu∩ M v|
|Mu∪ M v|, (13)
where Muis the set of positively rated movies types by u.
And we select Top-5 similarity of each agents.
b) Personality Graph Layer.: In the second (orange-pink)
layer, agents are connected if they have similar psychological
traits. The edge weight is defined using cosine similarity:
wpers
uv= cos( bu,bv) =bu·bv
∥bu∥ · ∥bv∥. (14)
c) Structural Graph Layer.: The third (purple-green)
layer models homophily in terms of occupation and age
category. Edge weights are binary, based on shared categories:
wstruct
uv=1same(tu,2,tv,2)+1same(tu,3,tv,3), (15)
d) Unified Layer and Aggregation.: The whole layer
aggregates all previous edges using a weighted linear com-
bination:
wuv=α·wint
uv+β·wpers
uv+γ·wstruct
uv,withα+β+γ= 1.(16)
This unified, weighted graph is used during social reasoning
and multi-round preference simulation.
e) Multi-Round Interaction Protocol.: During each
round, agent ureceives candidate movie mfrom its neighbors
N(u)and decides whether to accept based on semantic align-
ment and social propagation provided in Agent Architecture
Accepted movies are added to agent profile, and agent
embeddings are updated as described in Layer 1. In addition,
personality drift is also triggered by successful social influ-
ence, the formula is given in Agent Architecture section.Figure 5. Agent Architecture: Module 0 (GPT4 API), Module 1 (Individual
cognition Module), Module 2 (Social cognition Module), Module 3 (Decision
Module), Module 4 (Behavior Module)
f) Final Output.: After Trounds, the updated agent
profiles {p(T)
u}and graph G(T)are passed to downstream
recommenders (e.g., MF, MultV AE, LightGCN) to generate
final predictions. This layered social framework enables rich
modeling of community structure, latent personality align-
ment, and iterative preference shaping over the social graph.
IV. A GENT ARCHITECTURE
The agent architecture is clearly presented in Figure 5,
each simulated agent is designed as a fully autonomous
entity equipped with the capabilities of perception, cognition,
decision-making, and behavioral feedback. Its actions are
entirely driven by internal mechanisms, without reliance on
external calls. The agent operates through a closed cogni-
tive–motivational–behavioral loop: upon receiving an external
stimulus—such as a system-generated recommendation or
a peer-shared item—the agent invokes a series of internal
cognition modules to encode and evaluate the environment,
resulting in a set of psychologically and socially meaningful
latent variables [37]. These variables are then passed to
the motivational engine, which computes internal drive and
determines whether and how the agent should respond. The
agent may choose to watch the movie, assign a rating, and
share it with others, while also writing feedback back into
its memory, emotional state, and social ties, thereby enabling
long-term behavioral adaptation.
This autonomy is enabled by the coordinated operation
of multiple functional subsystems, including episodic recall,
affect regulation, preference learning, and social trust-risk
inference. To systematically support these capabilities, we
introduce a structured five-Module agent architecture that
aligns with core components of behavior: language generation,
individual cognition, social reasoning, motivational computa-
tion, and behavioral output. In the following sections of this
architecture, each Module is described in detail, corresponding
to a specific stage in the internal decision pipeline and together
implementing the cognitive loop described above [13]. Wefurther summarize the operational logic of the agent as an
algorithm 1.
Algorithm 1 Simulated Agent Decision Cycle
Require: Received recommendation mfrom source sat time t
Ensure: Agent response: watch/skip , rating r, share set S
1:Module 1: Individual Cognition
2:Retrieve past event history (s, m′, r′)from episodic memory
3:Compute current emotional state (Vt, At)from past satisfy M
4:Update preference vector pu
5:Compute novelty score N←Novelty (pu,em,lang)
6:Module 2: Social Cognition
7:Retrieve intimacy score I←Intimacy (u, s)
8:Estimate reciprocity potential R←Reciprocity (u, s)
9:Evaluate risk perception K←Risk (m, s, u )
10:Module 3: Motivation Evaluation
11:Compute dynamic threshold θ←θ0−κ·Vt
12:Compute motivation score C←αI+βN+γR−δK
13:Module 4: Behavior Execution
14:Compute watch probability p←σ((C−θ)/τu)
15:ifSample( Bernoulli (p)) == watch then
16: Predict expected rating ˆru,m
17: Sample final rating r←ˆru,m+ε
18: Compute satisfaction M←(r−ˆru,m)/4
19: Select share targets S ← TopK (qv=Iuv·Ruv·min(1 , C))
20: Update episodic memory with (s, m, r, M )
21: Update emotional state (Vt+1, At+1)
22: Update Iuv, Ruvusing M
23: Generate natural language review via Module 0 (DeepSeek-
R1)
24:else
25: Record skip event and decay motivation-related traces
26:end if
27:return Action ( watch/skip ),r(if applicable), share set S
A. Module 0: Language Reasoning Core
The language reasoning core is the only module in our
agent architecture that depends on a large language model. It
is implemented via a lightweight wrapper around DeepSeek-
R1, and its primary function is to generate natural language
expressions—including movie reviews, brief ratings, and so-
cial sharing messages—once a behavioral decision has been
finalized. The core design principle here is semantic genera-
tion decoupled from behavioral computation : this module does
not participate in any decision-making or numerical inference
and is invoked only after an action is determined by the upper
Modules.
The input to this module includes structured outputs from
Module 4, such as the final rating r, metadata of the watched
movie (e.g., genre, keywords, language), the agent’s current
emotional state (valence), and the target social circle (e.g.,
friends, interest groups, technical communities). These inputs
are formatted into controllable prompt templates that are
passed to DeepSeek-R1 for generation. For example, when
recommending a science fiction movie to a technical circle,
the generated review tends to be objective and analytical,
while in a friends circle, the tone becomes more emotional and
colloquial. This context-adaptive generation enhances realism
and aligns with stratified language patterns observed in real-
world social networks.The module also supports multilingual generation to simu-
late the diversity and asymmetry of language in cross-linguistic
social networks. In cases where there is a mismatch between
the language of the movie and the agent’s own language,
additional burden cues (e.g., “too many subtitles” or “trans-
lation affects immersion”) are automatically included in the
output, thus reinforcing the language-related risk factor Lgap
calculated in Module 2 [17].
B. Module 1: Individual Cognition Module
The individual cognition Module constitutes the core of an
agent’s internal state modeling. It maintains and dynamically
updates the agent’s personalized cognitive features, which
include episodic memory, affective state, and long-term pref-
erences. These modules are critical for providing interpretable,
temporally stable inputs to upper-Module decision processes.
Specifically, this Module includes three subcomponents: the
Episodic Memory , the Affective State Machine , and the Pref-
erence Model , corresponding to experiential, emotional, and
preference-related facets of human cognition.
a) Episodic Memory.: This module stores past movie-
watching and social interaction events in the form of times-
tamped triples (s, m, r ), where sis the source (e.g., a rec-
ommender or a friend), mdenotes the movie, and ris the
agent’s actual rating. Each event decays over time according
to an exponential forgetting curve:
Definition IV .1.
wt= exp( −λmem·∆t), (17)
where ∆tis the elapsed time since the event and λmemis
a tunable forgetting rate. This memory supports the dynamic
computation of reciprocity ( R) and risk ( K) by tracking long-
term satisfaction and content failures associated with specific
sources.
b) Affective State Machine.: To reflect transient affective
conditions, we model the agent’s emotional state in the 2D
Valence–Arousal space [32]. After each movie-watching event,
the emotional state is updated based on the rating deviation
(satisfaction):
M=r−ˆru,m
4, M ∈[−1,1], (18)
Vt+1=Vt+σV·M, A t+1=At+σA· |M|,(19)
where VandAdenote valence and arousal, respectively,
andσV, σAare sensitivity coefficients. The valence value Vt
directly modulates the decision threshold θin Module 3, in
accordance with affective decision-making theories such as
Mood-as-Information [14].
c) Preference Model.: The agent’s long-term interests
are represented as an evolving embedding vector pu∈Rd,
updated incrementally through observed movie embeddings
emusing exponential smoothing:
pu←(1−η)·pu+η·em, (20)where ηis the preference update rate. The preference vector
is used to calculate the subjective novelty score Nfor any
candidate movie, incorporating both semantic distance and
linguistic mismatch:
Definition IV .2.
N= min 
1,1−cos(pu,em) +λlang·1langm̸=langu
(21)
This captures not only content novelty but also cross-
linguistic cognitive load [17].
All submodules in Module 1 contribute real-time cognitive
signals to the upper Modules. Their outputs are consumed by
the motivation engine in Module 3 and are subject to recursive
updates through behavioral feedback handled in Module 4.
This Module thus forms a closed adaptive loop, ensuring each
agent gradually accumulates experiences, evolves preferences,
and regulates emotion—collectively shaping temporally coher-
ent, person-like behavioral profiles.
C. Module 2: Social Cognition Module
The social cognition Module enables the agent to perceive,
encode, and adapt to the surrounding social structure. It
is responsible for modeling the agent’s relationships across
multiple social contexts (e.g., interest-based, professional, ge-
ographic), evaluating trust in others’ recommendations, and
quantifying the perceived risk of consuming a given content.
This Module includes two major components: the MultiMod-
ule Social Graph Manager and the Trust and Risk Assessor ,
which together generate the intimacy (I) and risk(K) factors
for motivation scoring in Module 3.
a) MultiModule Social Graph Manager.: The agent’s
social connections are represented as a set of Moduleed adja-
cency matrices {W(ℓ)}L
ℓ=1, where each Module ℓcorresponds
to a distinct social circle type. The edge weight I(ℓ)
uvquantifies
the raw structural tie strength between agents uandvin
that circle, based on interaction frequency, co-engagement, or
proximity. These ties decay over time to reflect fading social
interactions.
A structural intimacy score is computed by weighted aggre-
gation across Modules:
Istruct=LX
ℓ=1γℓ·I(ℓ)
uv, (22)
where γℓis a decay factor representing inter-Module influence.
To enrich this structural metric with homophily-informed
features, we introduce two additional similarity components:
•Demographic similarity Sdemo, based on age, gender, lo-
cation, and language overlap. The demographic similarity
Sdemo is computed as the normalized count of matching
demographic attributes between agents uandv:
Sdemo=1
4
1ageu=agev+1genderu=genderv
+1location u=location v+1languageu=languagev
(23)
where each indicator function 1·returns 1 if the attribute
matches and 0 otherwise. This score reflects the classicalnotion of demographic homophily, widely observed to
enhance social affinity and communication efficiency
[24].
•Preference similarity Spref, combining cosine similarity
of Big Five personality embeddings and Jaccard overlap
of interest tags. The preference similarity Sprefcaptures
both personality alignment and interest overlap between
users:
Spref=1
2·cos (bu,bv) +1
2·|Tu∩Tv|
|Tu∪Tv|, (24)
where buandbvare the Big-Five personality vectors
of users uandv, and Tu,Tvare their sets of interest
tags. The first term measures psychological similarity via
cosine distance; the second term is the Jaccard similar-
ity between interest sets. This formulation is supported
by empirical findings that personality compatibility and
shared interests facilitate trust and collaboration in social
systems.
The final intimacy score is defined as:
Definition IV .3.
I=Istruct·[1 +λdemoSdemo+λprefSpref]. (25)
This formulation is grounded in sociological findings that
homophily strongly predicts tie strength and social bonding
[24], as well as computational studies that show personality
and interest similarity foster collaboration.
b) Trust and Risk Assessor.: This module computes a
personalized risk score Kfor each movie recommendation
event, integrating content-related uncertainty, cognitive bur-
den, and social-contextual cues. The full risk function is:
Definition IV .4.
K=σ 
0.4L+ 0.5G+ 0.4wtV+ 0.6A+ 0.3Lgap
−0.8wtTrust s−0.5I+ 0.5P
+risk_base u(26)
where:
•L: movie length (longer implies higher opportunity cost).
•G: genre-based arousal risk (e.g., horror, war).
•V: variance in historical ratings (uncertainty).
•A: age mismatch between user and movie rating.
•Lgap: language mismatch penalty [17].
•Trust s: recommender’s historical approval rate.
•I: intimacy with recommender, as computed above.
•P: user’s neuroticism level, reflecting risk aversion [26].
The sigmoid σ(·)ensures output normalization to [0,1], the
wtis from exponential forgetting curve. Additionally, each
agent has a static base risk level risk_base u, encoding their
default cautiousness.
c) Reciprocity Potential.: The agent also estimates the
likelihood of emotionally or informationally rewarding feed-
back following a share. This reciprocity potential Ris modeled
as:
Definition IV .5.
R= 0.6wtRhist+ 0.3Rpot+ 0.1Rpsn, (27)where:
•thewtis from exponential forgetting curve
•Rhist: rolling average of successful past shares to the
target user [3].
•Rpot: cosine similarity in interest embeddings [43].
•Rpsn: personality complementarity (e.g., extrovert sharing
with introvert) [51].
All scores computed in this Module serve as direct inputs
to the IC2Engine in Module 3. Moreover, these variables
are updated based on behavior logs recorded in Module 4,
enabling a continuous feedback loop between social perception
and social interaction. This design ensures that each agent is
capable of building, adjusting, and utilizing trust relationships,
adapting to social risks, and making decisions that align with
evolving social dynamics.
D. Module 3: Motivational Decision Module
The motivational decision Module is the behavioral core
of the agent architecture. It receives psychological and social
cues from lower Modules and integrates them into a scalar
motivation score that drives action. This Module includes two
components: the IC2Engine and the Reciprocity Regulator .
The former computes the agent’s internal motivation Cbased
on four interpretable subfactors, while the latter dynamically
adjusts relationship strength and reciprocity expectation based
on behavioral feedback, enabling long-term social adaptation.
a) IC2Engine.: The Inti-
macy–Curiosity–Reciprocity–Risk (IC2) engine is designed to
fuse four factors into a unified motivation score:
Definition IV .6.
C=αI+βN+γR−δK, (28)
where:
•I: intimacy with the recommending user (from Mod-
ule 2).
•N: subjective novelty of the content (from Module 1).
•R: reciprocity potential (from Module 2).
•K: risk perception (from Module 2).
The coefficients (α, β, γ, δ )control the relative influ-
ence of each factor. We adopt a default configuration
of(0.40,0.35,0.20,0.25), following principles from Multi-
Attribute Utility Theory (MAUT) and empirical behavioral
studies. The linear form supports transparency and control-
lability in simulation environments.
The IC2engine also incorporates a dynamic threshold θto
capture emotion-modulated decision flexibility:
θ=θ0−κ·Vt, (29)
where θ0is the agent’s base decision threshold, Vtis the cur-
rent valence (from Module 1), and κis a sensitivity coefficient.
This formulation is grounded in the Mood-as-Information
Theory [14], which postulates that positive emotions lower
resistance to external stimuli, thereby increasing the likelihood
of accepting recommendations.Once the motivation Cis computed, it is compared against
θ. IfC≥θ, the agent decides to take action (e.g., watch
a movie); otherwise, the opportunity is skipped. The binary
or probabilistic implementation of this choice is deferred to
Module 4.
b) Reciprocity Regulator.: To support adaptive social
learning, the system includes a mechanism to update social
ties based on interaction outcomes. After an action is taken
and the satisfaction score Mis computed, the intimacy and
reciprocity scores are adjusted as follows:
Iuv←Iuv+ρI·M, R uv←Ruv+ρR·M, (30)
where ρIandρRare update rates. A positive M(indicating
satisfaction) reinforces the social connection, while a negative
Mweakens it. This process emulates long-term relationship
dynamics as explained in Social Exchange Theory [ ?], and
supports emergent behavior adaptation over multiple decision
cycles.
Together, the IC2engine and reciprocity regulator form a
closed motivational loop that is both sensitive to internal and
external conditions and capable of long-term self-adjustment.
This Module enables agents to exhibit realistic behavioral
selectivity, emotion-driven variability, and socially responsive
learning, which are essential for generating credible, human-
like behavior trajectories in multi-agent simulation environ-
ments.
E. Module 4: Behavioral Output Module
The behavioral output Module serves as the agent’s external
interface, responsible for converting motivational signals from
Module 3 into concrete observable actions such as watching,
skipping, scoring, and sharing. Additionally, it records behav-
ioral traces in structured logs, triggers feedback updates to
lower Modules, and generates natural language explanations
via the language core (Module 0). This Module consists of two
main components: the Action Strategist and the Explainable
Logger .
a) Action Strategist.: The first task of the action strategist
is to determine whether the agent will watch a recommended
movie. Given the motivation score Cand internal decision
threshold θcomputed in Module 3, the probability of watching
is defined using a soft decision rule:
Pr(watch ) =σC−θ
τu
, (31)
where τuis the agent’s individual temperature coefficient ,
modeling behavioral randomness. Lower τuleads to more
deterministic decisions, while higher values introduce stochas-
ticity. This setup supports heterogeneous behavioral tendencies
across agents and aligns with the stochastic utility maximiza-
tion framework.
If the agent chooses to watch the movie, the final rating is
generated by adding a personalized noise term to the predicted
preference score:
r= ˆru,m+ε, ε∼ N(0, σ2
u), (32)where ˆru,mis the expected rating, and σucontrols subjec-
tive rating variability. The satisfaction score is then computed:
M=r−ˆru,m
4, M ∈[−1,1], (33)
which serves as a signal for feedback updates in Modules 1
through 3.
Next, the agent determines whether to share the movie with
peers. This is achieved by computing a priority score qvfor
each candidate target v:
qv=Iuv·Ruv·min(1 , C), (34)
where Iuvis the intimacy, Ruvthe reciprocity potential,
andCthe motivation score. The top- kcandidates by qvare
selected to form the share set S, and the corresponding share
edges are recorded into the social graph. These links will be
used for future tie updates and propagation.
b) Explainable Logger.: The logger module converts all
decision signals and behavioral results into a structured log
entry: (C, I, N, R, K, r, M, θ,S,t)
where tdenotes the current simulation timestep. This log
provides full transparency into the agent’s decision-making
process, and is stored for use in later analysis, evaluation, and
visualization.
In parallel, the logger constructs a prompt from the log
content and passes it to the language reasoning core (Mod-
ule 0), which generates natural language movie reviews and
recommendation messages. The generated texts reflect both the
decision rationale (e.g., high rating or emotional reaction) and
the tone appropriate for the target social circle (e.g., informal
for friends, factual for professional peers). Examples include:
•“Loved the visuals and plot twists—highly recommend!”
•“Too slow and predictable, not my thing, but others might
enjoy it.”
Finally, the logger triggers feedback propagation: the sat-
isfaction score Mis sent to Module 1 to update emotion
and memory, to Module 2 for adjusting trust and intimacy,
and to Module 3 for tuning reciprocity. The corresponding
episode is also written into the episodic memory buffer. This
completes the full decision–action–feedback loop, enabling the
agent to adapt over time and refine its internal models and
social strategies.
V. A GENT CONSISTENCY EXPERIMENT
To evaluate the plausibility of LLM-based agents in sim-
ulating human-like recommendation behavior, we designed a
two-part assessment strategy.
First, we propose this Agent Rating Consistency Experiment ,
wherein agents are prompted to rate a curated set of movies
under controlled conditions. Specifically, agents instantiated
with varying personas are presented with movie metadata
(title, genre, plot, cast) and asked to assign a rating from
1 to 5. The resulting Agent Rating Distributions (ARD)
are compared against empirical Human Rating Distributions
(HRD) derived from real user data in the MovieLens dataset.We employ Earth Mover’s Distance (EMD) and Kullback-
Leibler Divergence to quantify distributional similarity. A high
similarity score suggests alignment between agent and human
evaluative tendencies.
To complement this, we refer to the comprehensive behav-
ioral simulations presented by [45] in their paper. Their work
systematically evaluates LLM agents across multiple human-
aligned dimensions, including trust calibration, social influ-
ence susceptibility, and rational preference disclosure. Their
experimental conclusions to support the broader behavioral
fidelity of LLM agents in social recommendation contexts.
A. Rating Consistency
a) Motivation.: To systematically assess how closely
LLM-based agents simulate human evaluative behavior, we
compare rating outputs across three subject types:
(1) Human Ratings: Empirical ground-truth ratings are
sourced from the MovieLens dataset, where each item (movie)
has been rated by a diverse population of real users. These
ratings are aggregated to form the reference Human Rating
Distribution (HRD) per item.
(2) GGBond Agents: These agents are embedded in a
dynamic social network structure and undergo three iterative
rounds of interaction within the GGBond framework. Each
round allows agents to exchange movie recommendations,
receive social feedback, and update their personality traits
and interest profiles based on their neighbors’ influence. After
convergence, each agent rates a set of target movies. The
resulting scores constitute the GGBond Rating Distribution
(GRD).
(3) Static Agents: These agents operate in isolation, without
access to social influence or iterative feedback. Each static
agent is initialized with a fixed persona (personality vector and
interest vector) derived from the same initialization process
as GGBond agents, but they do not engage in multi-agent
interaction. Their ratings form the Static Rating Distribution
(SRD).
For each target movie, we collect ratings from all three
sources and compute distributional similarity between HRD
and both GRD and SRD using Earth Mover’s Distance [31]
and Kullback-Leibler [29] divergence, defined as follows:
b) Earth Mover’s Distance (EMD).: LetPandQdenote
two probability distributions over the same domain. The Earth
Mover’s Distance between PandQis defined as the minimal
cost required to transform PintoQ, where the cost is
quantified as the amount of distribution “mass” that must be
moved times the distance it has to be moved:
EMD( P, Q) = inf
γ∈Γ(P,Q)Z
X×X∥x−y∥dγ(x, y), (35)
where Γ(P, Q)denotes the set of all joint distributions (or
transport plans) with marginals PandQrespectively.
c) Kullback-Leibler Divergence (KL): Given two dis-
crete probability distributions P={p1, ..., p n}andQ=
{q1, ..., q n}over the same support, the KL divergence fromQtoPmeasures the information loss when Qis used to
approximate P:
KL(P∥Q) =nX
i=1pilogpi
qi
, (36)
where it is assumed that qi>0whenever pi>0.
A lower divergence indicates higher alignment with human
evaluative behavior.
d) Result.: To assess the alignment between agent-
generated and human rating behaviors, we computed two
standard distributional similarity metrics: KL Divergence and
Earth Mover’s Distance. Table I presents the evaluation results
across three subjects: human raters (as ground truth), GGBond
agents (socially interacting agents), and static agents (non-
interactive).
Table I
DISTRIBUTIONAL SIMILARITY METRICS (LOWER IS BETTER )
Subject Type KL Divergence EMD
GGBond Agent 0.0108 0.0900
Static Agent 0.0750 0.4200
We hypothesize that GGBond agents, enriched by
personality-driven and socially-informed interactions, will ex-
hibit greater consistency with human rating distributions
than static agents. This would suggest that social dynam-
ics—modeled through structured agent interaction—play a
meaningful role in shaping human-aligned evaluative behavior
in recommendation contexts.
As shown in Table I, the GGBond Agent exhibits signif-
icantly lower KL Divergence (0.0108) and EMD (0.0900)
compared to the Static Agent (KL = 0.0750, EMD = 0.4200),
indicating a stronger alignment between the GGBond Agent’s
rating behavior and that of real human users.
These results suggest that incorporating social interac-
tions—modeled via multi-round agent communication and
personality adaptation in the GGBond framework—enables
agents to develop more human-like evaluative tendencies.
In contrast, static agents, which do not participate in any
social feedback loop, exhibit flatter and less natural rating
distributions.
Figure 6 further visualizes the rating density curves for all
three subject types. The GGBond Agent curve closely tracks
the human curve, particularly in the modal region (scores 3–4),
whereas the Static Agent curve is more uniformly distributed
and deviates from realistic scoring tendencies.
B. Behavior Consistency
Extensive evidence from recent studies confirms that social
structures and personality signals jointly drive human–like
recommendation behavior. Graph–based social recommenders
consistently exploit homophily andsocial influence : users who
are socially connected tend to share similar preferences and
gradually converge through interaction [35]. Personality–aware1 2 3 4 500.10.20.30.40.5
Rating ScoreDensityRating Distribution Comparison
Human Ratings GGBond Agent Static Agent
Figure 6. Comparison of rating distributions across Human, GGBond Agent,
and Static Agent.
recommenders further improve cold–start accuracy by aligning
item exposure with individual trait profiles [5]. Trust graphs
and multi–agent collaborations have also been shown to en-
hance robustness and realism in simulated environments [4],
[36].
Within GGBond, agents exchange recommendations over
three interaction rounds. Such iterative communication closely
mirrors the feedback-loop modeling that MacRec employs
to improve recommendation quality via agent collaboration
[4]. Recent work on large–scale social simulators like OASIS
demonstrates that dynamic social graphs coupled with recom-
mendation mechanisms reproduce realistic adoption patterns
at scale [48]. Likewise, SimUSER shows that LLM-based
agents equipped with memory modules can generate user–RS
interactions that faithfully match observed click statistics [ ?].
Finally, studies on graph-invariant learning and
low-homophily settings reveal that even when explicit
similarity signals are weak, leveraging high-order social paths
markedly narrows the gap between model outputs and human
behavior [15], [47]. These converging findings substantiate
our observation that the GGBond agents—when embedded in
a social graph produce recommendation and rating patterns
significantly closer to real users than isolated static agents.
VI. E VALUATION
A. Impact of Social Interaction Depth on Agent Behavior and
Recommendation
a) Objective.: This experiment investigates how varying
the depth of social interactions influences recommendation
performance, agent behavioral dynamics, and simulated user
satisfaction within the GGBond framework. Specifically, we
examine whether increasing the number of interaction rounds(0-30 and we examine the metrics of 0, 10, 20, and 30 rounds)
leads to improved personalization and stable, human-aligned
behavior patterns.
b) Experimental Setup.: We defined four experimental
conditions:
Baseline (0 Rounds): Static agents with no social interac-
tion; initial profiles are directly passed to the recommendation
models.
GGBond-10Round / 20Round / 30Round: Agents engage
in ten to thirty rounds of interaction, where they exchange
movie recommendations with neighbors and accept/evaluate
the recommender system and give feedback, update their
personality and interest vectors based on accepted items, and
propagate behavioral signals throughout the network. At the
end of every round, the profile data of every agent, including
interaction and rating data, are sent into the recommender
systems: Matrix Factorization (MF) [18], MultV AE [21], and
LightGCN [11]. These models then generate top-20 ranked
lists per agent. Each agent evaluates the presented movies
(based on content similarity and internal state), and accepts or
rejects accordingly. The evaluation metrics we use are Recall
and NDCG [40]. Our work builds on prior studies highlighting
the role of social influence in recommender systems [4], [22],
[39].
c) Recall@20.: measures the proportion of relevant
items (e.g., positively rated by the agent) that appear in the
top-20 recommended list:
Recall@20 =1
|V|X
u∈V|R(20)
u∩ Gu|
|Gu|, (37)
where R(20)
uis the top-20 recommendation list for agent u,
andGuis the set of relevant (positively rated) items by u.
d) NDCG@20.: NDCG@20 evaluates the quality of
ranking by assigning higher scores to relevant items that
appear earlier in the top-20 list:
NDCG@20 =1
|V|X
u∈V1
IDCG(20)
u20X
i=1I(rui∈ Gu)
log2(i+ 1),(38)
where ruiis the item at rank ifor agent u,Guis the ground-
truth relevant set, and IDCG(20)
uis the ideal DCG for agent u
(i.e., when all relevant items are ranked at the top).
e) Recommendation Performance.: Table II and Figure 7,
Figure 8 presents Recall@20 and NDCG@20 for each model
under different interaction depths. All models exhibit improved
performance as interaction depth increases, with MultV AE and
LightGCN benefiting more from socially enriched profiles.
B. Post-Recommendation Agent Behavior.
To further assess how social interactions affect downstream
agent dynamics, we analyze four key behavioral indicators
across all models and interaction rounds: personality change,
satisfaction ratio, acceptance rate, and negative review rate.Table II
RECOMMENDATION PERFORMANCE AT SPECIFIC ROUNDS (RECALL @20 AND NDCG@20)
Model / Metric 0 Rounds 10 Rounds 20 Rounds 30 Rounds
MF - Recall@20 0.1502 0.1574 0.1612 0.1623
MF - NDCG@20 0.3560 0.3612 0.3652 0.3669
MultV AE - Recall@20 0.1592 0.1636 0.1668 0.1674
MultV AE - NDCG@20 0.3482 0.3543 0.3592 0.3606
LightGCN - Recall@20 0.1721 0.1783 0.1804 0.1813
LightGCN - NDCG@20 0.3845 0.3923 0.3968 0.3975
0 10 20 300.140.150.160.170.180.19
Interaction RoundsRecall@20Recall@20 across Interaction Rounds
MF MultV AE LightGCN
Figure 7. Recall@20 across different interaction rounds.
Definition VI.1 (Personality Change) .Personality Change
∆personality is defined as the average ℓ2distance between each
agent’s final and initial Big-Five personality vectors:
∆personality =1
|V|X
u∈Vb(final)
u−b(init)
u
2. (39)
This metric captures the extent to which an agent’s person-
ality representation has evolved after social recommendation
interactions.
Definition VI.2 (Satisfaction Ratio) .Satisfaction Ratio Ssat
denotes the average score agents assign to liked items, reflect-
ing their alignment with user preference:
Ssat=1
|V|X
u∈V1
|Au|X
m∈Auscore u,m, (40)
where Au={m|score u,m≥3}is the set of items liked
by agent u(i.e., rated 3–5), and score u,m∈ {0,1,2,3,4,5}.0 10 20 300.340.360.380.4
Interaction RoundsNDCG@20NDCG@20 across Interaction Rounds
MF MultV AE LightGCN
Figure 8. NDCG@20 across different interaction rounds.
Definition VI.3 (Negative Review Rate) .Exit Rate Nexit
measures the proportion of agents whose ratings for all rec-
ommended items fall below the acceptance threshold:
Nneg=|{u∈ V | ∀ m∈ R u,score u,m≤2}|
|V|, (41)
where Ruis the set of items recommended to agent u. A
higher value indicates dissatisfaction or poor personalization.
Definition VI.4 (Acceptance Rate) .Acceptance Rate Arate
measures the proportion of recommended movies that were
accepted (i.e., watched) by the agent population:
Arate=1
|V|X
u∈V|Au|
|Ru|, (42)
where Auis the set of movies accepted (rated ≥3) by agent
u, andRuis the set of all movies recommended to u. This
metric serves as a proxy for user engagement and perceived
relevance of the recommendations.Table III
POST-RECOMMENDATION AGENT BEHAVIOR ACROSS INTERACTION ROUNDS
Model / Metric 0 Rounds 10 Rounds 20 Rounds 30 Rounds
MF - Personality Change 0.000 0.142 0.186 0.189
MF - Satisfaction ( Ssat) 3.01 3.56 3.88 3.95
MF - Negative Rate ( Nneg) 0.306 0.248 0.194 0.181*
MF - Acceptance Rate ( Arate) 0.216 0.398 0.433 0.447
MultV AE - Personality Change 0.000 0.154 0.208 0.217
MultV AE - Satisfaction ( Ssat) 3.01 3.72 3.94 4.01
MultV AE - Negative Rate ( Nneg) 0.306 0.236 0.178 0.163
MultV AE - Acceptance Rate ( Arate) 0.216 0.421 0.462 0.474
LightGCN - Personality Change 0.000 0.161 0.223 0.234
LightGCN - Satisfaction ( Ssat) 3.01 3.80 4.07 4.15*
LightGCN - Negative Rate ( Nneg) 0.306 0.231 0.163 0.147
LightGCN - Acceptance Rate ( Arate) 0.216 0.438 0.479 0.505*
a) Discussion.: The results presented in Table III high-
light the effectiveness of incorporating multi-round social
interactions into recommendation workflows. Across all three
models—MF, MultV AE, and LightGCN—agents exhibit no-
table improvements in both behavioral alignment and simu-
lated satisfaction as the number of interaction rounds increases.
First, Personality Change steadily rises with interaction
depth, indicating that agents’ psychological representations are
dynamically adapting based on social feedback. This effect is
most pronounced in LightGCN, suggesting that graph-based
models are more sensitive to socially enriched profile updates
and better capture latent preference drift over time.
Second, Satisfaction ( Ssat) shows a clear upward trend,
increasing from a flat baseline of 3.01 (i.e., neutral ratings) to
4.15 in LightGCN after 30 rounds. This illustrates that deeper
social exposure not only improves recommendation relevance
but also yields more positively perceived content, mimicking
the organic satisfaction growth seen in real user systems.
Third, Negative Rate ( Nneg)—a proxy for user disengage-
ment—consistently decreases across all models, demonstrating
that agents are increasingly finding suitable content to con-
sume. The steepest decline is again observed in LightGCN,
affirming its capacity to retain engagement under socially
dynamic contexts.
Finally, Acceptance Rate ( Arate) improves significantly
from 0.216 (static agents) to 0.505 in LightGCN after 30
rounds. This more than twofold increase in click-through
behavior confirms that social iteration enables agents to in-
ternalize and act upon contextualized preferences, leading to
higher interactivity and system responsiveness.
Collectively, these findings validate the GGBond frame-
work’s capability to enhance not only classical recommenda-
tion metrics but also user-centered behavioral realism through
layered social interaction modeling.VII. R ELATED WORK
A. Recommendation Simulation Platforms.
Simulation frameworks have become essential tools for
evaluating and developing recommendation algorithms, allow-
ing researchers to test recommender behaviors under con-
trolled scenarios without costly real-user trials. Early platforms
like RecSim [13] provided configurable environments for
sequential user interactions. Building upon this, RecSim NG
[25] introduced a probabilistic programming approach with
modular, differentiable components, enabling more flexible
and scalable simulations. Recent advances have leveraged
large language models (LLMs) to enhance the realism of user
simulations. Agent4Rec [49] employs LLM-powered genera-
tive agents equipped with user profiles, memory, and action
modules, simulating nuanced user behaviors and emotional
responses. Similarly, RecAgent [42] integrates LLMs to model
user interactions, including browsing, communication, and
social media activities, providing a comprehensive simulation
of user behaviors in recommender systems. KuaiSim [52]
offers a comprehensive simulator supporting multi-behavior
and cross-session user feedback, facilitating the evaluation of
recommendation algorithms across various tasks. Additionally,
SimUSER [2] introduces an agent framework that simu-
lates human-like behavior using self-consistent personas and
memory modules, enhancing the assessment of recommender
systems. These simulation platforms collectively advance the
field by providing more realistic and versatile environments
for testing and improving recommendation algorithms.
B. LLM-Driven Agent Behavior
The integration of large language models (LLMs) into
autonomous agents has significantly advanced their ability to
perform complex, goal-directed behaviors. Park et al. intro-
duced Generative Agents, which simulate human-like behav-
iors by equipping agents with long-term memory, planning,
and reflection capabilities, resulting in emergent social interac-
tions within a simulated environment [28]. Similarly, V oyageremploys DeepSeek-R1 to autonomously navigate and master
open-ended tasks in the Minecraft environment, demonstrating
the adaptability of LLM-driven decision-making across diverse
contexts [41]. Recent surveys have provided comprehensive
overviews of LLM-based autonomous agents. Wang et al.
discuss the construction, application, and evaluation of such
agents, highlighting their potential in various domains in-
cluding social sciences, natural sciences, and engineering [9].
Xi et al. further explore the rise and potential of LLM-
based agents, proposing a general framework comprising
brain, perception, and action components, and examining their
applications in single-agent scenarios, multi-agent scenarios,
and human-agent cooperation [6]. These studies collectively
underscore the transformative impact of LLMs on autonomous
agent behavior, enabling more sophisticated and human-like
interactions across a range of applications.
C. User Behavior Modeling in Social Networks
Modeling user interactions and social influence within net-
works has long been a critical research area. Recent advance-
ments leverage large language models (LLMs) to simulate
nuanced information diffusion processes. LAID [12] integrates
LLMs into diffusion modeling, enabling simulation of real-
istic message interpretation and propagation patterns within
social graphs. On a larger scale, AgentSociety [30] employs
thousands of LLM-driven agents to reproduce societal-level
phenomena, such as opinion polarization and misinforma-
tion spread, providing insights that closely match empirical
observations from real-world social platforms. Additionally,
the S3framework [8] utilizes LLM-empowered agents to
simulate public opinion dynamics, offering a flexible platform
for exploring various social scenarios and interventions. Fur-
thermore, LLM-AIDSim [50] enhances traditional influence
diffusion models by allowing agents to generate language-
level responses, providing deeper insights into user agent
interactions. GenSim [38] introduces a general social simula-
tion platform with LLM-based agents, supporting large-scale
simulations and incorporating error-correction mechanisms to
ensure more reliable and long-term simulations. These simula-
tion platforms collectively advance the field by providing more
realistic and versatile environments for testing and improving
our understanding of user behavior and information diffusion
in social networks.
D. Trust and Behavioral Alignment in AI Agents
Understanding and aligning AI agent behavior with human-
like trust and conformity has gained significant attention. Xie
et al. [44] evaluated LLM agents within classical economic
trust games, discovering that advanced models like DeepSeek-
R1 closely align with human trust decisions. Further, Ar-
gyle et al. [1] introduced the concept of algorithmic fidelity,
demonstrating that properly conditioned LLMs can accurately
emulate distinct human demographic responses, thus offering
a powerful tool for modeling realistic user populations in
experimental simulations. Recent studies have further explored
the enhancement of trust in LLM-based AI automation agents.Schwartz et al. [34] analyzed the main aspects of trust in AI
agents, identifying specific considerations and challenges rele-
vant to this new generation of automation agents. Additionally,
Yang et al. [46] proposed Behavior Alignment as a new evalua-
tion metric to measure how well the recommendation strategies
made by LLM-based conversational recommender systems
are consistent with human recommenders’, highlighting the
importance of aligning AI behavior with human expectations
to enhance user trust.
VIII. C ONCLUSION
This work addresses the longstanding limitations of per-
sonalized recommender systems in modeling dynamic user
behaviors and social interactions by proposing a novel high-
fidelity simulation platform. Our system systematically tackles
the challenges of long-term preference drift, social influ-
ence propagation, and cognitively realistic decision-making,
which remain underexplored in current recommendation re-
search. Specifically, we design a population of human-like
intelligent agents endowed with multi-faceted internal cog-
nition modules—including memory, affective state, person-
alized preference, and trust evaluation—to simulate granu-
lar and interpretable decision-making processes. In parallel,
we construct a dynamic, multi-layer social graph (GGBond
Graph) that captures heterogeneous, multi-circle social rela-
tions and their evolution over time. The entire system operates
under a discrete-time simulation scheduler, coupling agent-
level behavior with social network dynamics. We further
integrate mainstream recommendation algorithms (e.g., Matrix
Factorization, MultV AE, and LightGCN) into this framework,
enabling rigorous evaluation under iterative feedback and
socially embedded environments.
This platform bridges critical gaps in existing recommen-
dation evaluation pipelines by supporting long-term interac-
tion, cognitively plausible user modeling, and dynamic social
structures. Theoretically, we introduce an IC2motivational
engine grounded in psychological and sociological princi-
ples, enhancing interpretability and realism in agent behavior.
Methodologically, our extensible experimental infrastructure
lays a solid foundation for future studies on social impact,
fairness, and causal inference in recommender systems.
Naturally, some limitations remain. The current implemen-
tation of agent affect and memory dynamics could benefit
from more fine-grained modeling, and the transferability of
the simulation framework to real-world deployment scenarios
still requires further investigation. Future work may focus
on enhancing the complexity and fidelity of agent cognition
models, exploring the long-term societal effects and ethical
implications of recommendation mechanisms, and integrating
the proposed framework with real systems to support socially
responsible algorithm design.
REFERENCES
[1] Lisa P. Argyle, Ethan C. Busby, Nancy Fulda, Joshua Gubler, Christo-
pher Rytting, and David Wingate. Out of one, many: Using language
models to simulate human samples. Political Analysis , 31(3):337–351,
2023.[2] Nicolas Bougie and Narimasa Watanabe. Simuser: Simulating user be-
havior with large language models for recommender system evaluation.
arXiv preprint arXiv:2504.12722 , 2024.
[3] Samuel Bowles and Herbert Gintis. A cooperative species: Human
reciprocity and its evolution. In A cooperative species . Princeton
University Press, 2011.
[4] Shihao Cai, Jizhi Zhang, Keqin Bao, Chongming Gao, Qifan Wang, Fuli
Feng, and Xiangnan He. Agentic feedback loop modeling improves
recommendation and user simulation. SIGIR, 2025.
[5] Fabio Celli, Aleksandar Kartelj, Miljan Ð or ¯devi´c, Derwin Suhartono,
Vladimir Filipovi ´c, Veljko Milutinovi ´c, Georgios Spathoulas, Alessandro
Vinciarelli, Michal Kosinski, and Bruno Lepri. Twenty years of
personality computing: Threats, challenges and future directions. arXiv
preprint arXiv:2503.02082 , 2025.
[6] Yuheng Cheng, Ceyao Zhang, Zhengwen Zhang, Xiangrui Meng, Sirui
Hong, Wenhao Li, Zihao Wang, Zekai Wang, Feng Yin, Junhua Zhao,
and Xiuqiang He. Exploring large language model based intelli-
gent agents: Definitions, methods, and prospects. arXiv preprint
arXiv:2401.03428 , 2024.
[7] Linton C. Freeman. A set of measures of centrality based on between-
ness. Sociometry , 40(1):35–41, 1977.
[8] Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua Piao,
Huandong Wang, Depeng Jin, and Yong Li. S3: Social-network
simulation system with large language model-empowered agents. arXiv
preprint arXiv:2307.14984 , 2023.
[9] Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei,
Nitesh V Chawla, Olaf Wiest, and Xiangliang Zhang. Large language
model based multi-agents: A survey of progress and challenges. arXiv
preprint arXiv:2402.01680 , 2024.
[10] F Maxwell Harper and Joseph A Konstan. The movielens datasets:
History and context. Acm transactions on interactive intelligent systems
(tiis) , 5(4):1–19, 2015.
[11] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and
Meng Wang. Lightgcn: Simplifying and powering graph convolution
network for recommendation. In Proceedings of the 43rd International
ACM SIGIR conference on research and development in Information
Retrieval , pages 639–648, 2020.
[12] Yuxuan Hu, Gemju Sherpa, Lan Zhang, Weihua Li, Quan Bai, Yijun
Wang, and Xiaodan Wang. An llm-enhanced agent-based simulation
tool for information propagation. In Proceedings of the Thirty-Third
International Joint Conference on Artificial Intelligence , IJCAI ’24,
2024.
[13] Eugene Ie, Chih-Wei Hsu, Martin Mladenov, Vihan Jain, Sanmit
Narvekar, Jing Wang, Rui Wu, and Craig Boutilier. Recsim: A con-
figurable simulation platform for recommender systems. In Proceedings
of the 13th ACM Conference on Recommender Systems , pages 228–236.
ACM, 2019.
[14] Alice M Isen. Positive affect, cognitive processes, and social behavior.
InAdvances in experimental social psychology , volume 20, pages 203–
253. Elsevier, 1987.
[15] Wei Jiang, Xinyi Gao, Guandong Xu, Tong Chen, and Hongzhi Yin.
Challenging low homophily in social recommendation. In Proceedings
of the ACM Web Conference 2024 , pages 3476–3484, 2024.
[16] Wang-Cheng Kang and Julian McAuley. Self-attentive sequential rec-
ommendation. In 2018 IEEE international conference on data mining
(ICDM) , pages 197–206. IEEE, 2018.
[17] Boaz Keysar, Sayuri L Hayakawa, and Sun Gyu An. The foreign-
language effect: Thinking in a foreign tongue reduces decision biases.
Psychological science , 23(6):661–668, 2012.
[18] Yehuda Koren, Robert Bell, and Chris V olinsky. Matrix factorization
techniques for recommender systems. Computer , 42(8):30–37, 2009.
[19] Michal Kosinski, David Stillwell, and Thore Graepel. Private traits
and attributes are predictable from digital records of human behavior.
Proceedings of the National Academy of Sciences , 110(15):5802–5805,
2013.
[20] Jure Leskovec and Julian Mcauley. Learning to discover social circles
in ego networks. Advances in neural information processing systems ,
25, 2012.
[21] Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara.
Variational autoencoders for collaborative filtering. In Proceedings of
the 2018 world wide web conference , pages 689–698, 2018.
[22] Hao Ma, Dengyong Zhou, Chao Liu, and Michael R. Lyu. Learning
to recommend with social trust ensemble. In Proceedings of the 32ndinternational ACM SIGIR conference on Research and development in
information retrieval , pages 203–210, 2009.
[23] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van
Den Hengel. Image-based recommendations on styles and substitutes.
InProceedings of the 38th international ACM SIGIR conference on
research and development in information retrieval , pages 43–52, 2015.
[24] Miller McPherson, Lynn Smith-Lovin, and James M Cook. Birds of
a feather: Homophily in social networks. Annual review of sociology ,
27(1):415–444, 2001.
[25] Martin Mladenov, Craig Boutilier, and Eugene Ie. Recsim ng: Toward
principled uncertainty modeling for recommender ecosystems. In
Advances in Neural Information Processing Systems , volume 34, pages
14985–14997, 2021.
[26] Nigel Nicholson, Emma Soane, Mark Fenton-O’Creevy, and Paul Will-
man. Personality and domain-specific risk taking. Journal of Risk
Research , 8(2):157–176, 2005.
[27] Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. The
pagerank citation ranking: Bringing order to the web. Technical report,
Stanford InfoLab, 1999.
[28] Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel
Morris, Percy Liang, and Michael S Bernstein. Generative agents:
Interactive simulacra of human behavior. In Proceedings of the 2023
CHI Conference on Human Factors in Computing Systems , pages 1–18.
ACM, 2023.
[29] Fernando Pérez-Cruz. Kullback-leibler divergence estimation of continu-
ous distributions. In 2008 IEEE international symposium on information
theory , pages 1666–1670. IEEE, 2008.
[30] Jinghua Piao, Yuwei Yan, Jun Zhang, Nian Li, Junbo Yan, Xiaochong
Lan, Zhihong Lu, Zhiheng Zheng, Jing Yi Wang, Di Zhou, et al.
Agentsociety: Large-scale simulation of llm-driven generative agents
advances understanding of human behaviors and society. arXiv preprint
arXiv:2502.08691 , 2025.
[31] Yossi Rubner, Carlo Tomasi, and Leonidas J Guibas. The earth mover’s
distance as a metric for image retrieval. International journal of
computer vision , 40:99–121, 2000.
[32] James A Russell. A circumplex model of affect. Journal of personality
and social psychology , 39(6):1161, 1980.
[33] H. Andrew Schwartz, Johannes C. Eichstaedt, Margaret L. Kern, et al.
Personality, gender, and age in the language of social media: The open-
vocabulary approach. PLOS ONE , 8(9):e73791, 2013.
[34] Sivan Schwartz, Avi Yaeli, and Segev Shlomov. Enhancing trust in llm-
based ai automation agents: New considerations and future challenges.
arXiv preprint arXiv:2308.05391 , 2023.
[35] Kartik Sharma, Yeon-Chang Lee, Sivagami Nambi, Aditya Salian, Shlok
Shah, Sang-Wook Kim, and Srijan Kumar. A survey of graph neural
networks for social recommender systems. ACM Computing Surveys ,
56(10):1–34, 2024.
[36] Paras Stefanopoulos, Ahad N Zehmakan, and Sourin Chatterjee. A
first principles approach to trust-based recommendation systems. arXiv
preprint arXiv:2407.00062 , 2024.
[37] Ron Sun. The clarion cognitive architecture: Extending cognitive
modeling to social simulation. Cognition and multi-agent interaction ,
pages 79–99, 2006.
[38] Jiakai Tang, Heyang Gao, Xuchen Pan, Lei Wang, Haoran Tan, Dawei
Gao, Yushuo Chen, Xu Chen, Yankai Lin, Yaliang Li, et al. Gensim:
A general social simulation platform with large language model based
agents. arXiv preprint arXiv:2410.04360 , 2024.
[39] Jiliang Tang, Xia Hu, and Huan Liu. Social recommendation: a review.
Social Network Analysis and Mining , 3(4):1113–1133, 2013.
[40] Hamed Valizadegan, Rong Jin, Ruofei Zhang, and Jianchang Mao.
Learning to rank by optimizing ndcg measure. Advances in neural
information processing systems , 22, 2009.
[41] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao,
Yuke Zhu, Linxi Fan, and Anima Anandkumar. V oyager: An open-
ended embodied agent with large language models. arXiv preprint
arXiv:2305.16291 , 2023.
[42] Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu
Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, et al.
User behavior simulation with large language model based agents. arXiv
preprint arXiv:2306.02552 , 2023.
[43] Yu Wang, Youcheng Wang, and Wen Wang. Impact of personal traits and
social networks on online knowledge sharing: A case study of facebook
users. Computers in Human Behavior , 34:345–354, 2014.[44] Chengxing Xie, Canyu Chen, Feiran Jia, Ziyu Ye, Shiyang Lai, Kai
Shu, Jindong Gu, Adel Bibi, Ziniu Hu, David Jurgens, et al. Can large
language model agents simulate human trust behavior? In The Thirty-
eighth Annual Conference on Neural Information Processing Systems ,
2024.
[45] Feiyu Xu et al. Can large language model agents simulate human
trust behavior? In Advances in Neural Information Processing Systems
(NeurIPS) , 2024.
[46] Dayu Yang, Fumian Chen, and Hui Fang. Behavior alignment: A new
perspective of evaluating llm-based conversational recommender sys-
tems. In Proceedings of the 47th International ACM SIGIR Conference
on Research and Development in Information Retrieval , pages 2286–
2290. ACM, 2024.
[47] Yonghui Yang, Le Wu, Yuxin Liao, Zhuangzhuang He, Pengyang Shao,
Richang Hong, and Meng Wang. Invariance matters: Empowering
social recommendation via graph invariant learning. arXiv preprint
arXiv:2504.10432 , 2025.
[48] Ziyi Yang, Zaibin Zhang, Zirui Zheng, Yuxian Jiang, Ziyue Gan, Zhiyu
Wang, Zijian Ling, Jinsong Chen, Martz Ma, Bowen Dong, et al. Oasis:
Open agents social interaction simulations on one million agents. arXiv
preprint arXiv:2411.11581 , 2024.
[49] An Zhang, Yuxin Chen, Leheng Sheng, Xiang Wang, and Tat-Seng
Chua. On generative agents in recommendation. In Proceedings
of the 46th International ACM SIGIR Conference on Research and
Development in Information Retrieval , pages 1234–1243. ACM, 2023.
[50] Lan Zhang, Yuxuan Hu, Weihua Li, Quan Bai, and Parma Nand. Llm-
aidsim: Llm-enhanced agent-based influence diffusion simulation in
social networks. Systems , 13(1):29, 2025.
[51] Min Zhang, Ji Liang, and Xiaofang Wu. Impact of introversion-
extraversion personality traits on knowledge sharing: Evidence from
virtual communities. Sustainability , 15(1):417, 2023.
[52] Kesen Zhao, Shuchang Liu, Qingpeng Cai, Xiangyu Zhao, Ziru Liu,
Dong Zheng, Peng Jiang, and Kun Gai. Kuaisim: A comprehensive
simulator for recommender systems. In Proceedings of the 17th ACM
Conference on Recommender Systems , pages 456–466. ACM, 2023.