arXiv:2505.21140v1  [cs.LG]  27 May 2025HeteroBA: A Structure-Manipulating Backdoor Attack on
Heterogeneous Graphs
Honglin Gao
School of Electrical and Electronic Engineering
Nanyang Technological University
Singapore
honglin001@e.ntu.edu.sgXiang Li
School of Electrical and Electronic Engineering
Nanyang Technological University
Singapore
xiang002@e.ntu.edu.sg
Lan Zhao
School of Electrical and Electronic Engineering
Nanyang Technological University
Singapore
zhao0468@e.ntu.edu.sgGaoxi Xiao
School of Electrical and Electronic Engineering
Nanyang Technological University
Singapore
egxxiao@ntu.edu.sg
Abstract
Heterogeneous graph neural networks (HGNNs) have recently
drawn increasing attention for modeling complex multi-relational
data in domains such as recommendation, finance, and social net-
works. While existing research has been largely focusing on en-
hancing HGNNsâ€™ predictive performance, their robustness and se-
curity, especially under backdoor attacks, remain underexplored.
In this paper, we propose a novel Heterogeneous Backdoor Attack
(HeteroBA) framework for node classification tasks on heteroge-
neous graphs. HeteroBA inserts carefully crafted trigger nodes with
realistic features and targeted structural connections, leveraging
attention-based and clustering-based strategies to select influential
auxiliary nodes for effective trigger propagation, thereby causing
the model to misclassify specific nodes into a target label while
maintaining accuracy on clean data. Experimental results on three
datasets and various HGNN architectures demonstrate that Heter-
oBA achieves high attack success rates with minimal impact on the
clean accuracy. Our method sheds light on potential vulnerabilities
in HGNNs and calls for more robust defenses against backdoor
threats in multi-relational graph scenarios.
CCS Concepts
â€¢Do Not Use This Code â†’Generate the Correct Terms for
Your Paper ;Generate the Correct Terms for Your Paper ; Generate
the Correct Terms for Your Paper; Generate the Correct Terms for
Your Paper.
Keywords
Heterogeneous Graph, Backdoor Attack, Heterogeneous Graph
Neural Networks
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
Conference acronym â€™XX, Woodstock, NY
Â©2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-XXXX-X/2018/06
https://doi.org/XXXXXXX.XXXXXXXACM Reference Format:
Honglin Gao, Xiang Li, Lan Zhao, and Gaoxi Xiao. 2018. HeteroBA: A
Structure-Manipulating Backdoor Attack on Heterogeneous Graphs. In
Proceedings of Make sure to enter the correct conference title from your rights
confirmation email (Conference acronym â€™XX). ACM, New York, NY, USA,
11 pages. https://doi.org/XXXXXXX.XXXXXXX
1 Introduction
Graph data is prevalent in various applications, including social
networks [ 10,12], signal processing [ 36], biological networks [ 14],
and knowledge graphs [ 28]. Unlike homogeneous graphs, heteroge-
neous graphs (HGs) contain multiple node and edge types, making
them particularly effective for modeling complex real-world rela-
tionships. For instance, an academic graph comprises researchers,
papers, and institutions connected through authorship, citation, and
collaboration links. Such structural flexibility allows heterogeneous
graphs to serve as the backbone for various domains, including
recommendation systems and financial risk modeling [ 16,19], etc.
Heterogeneous Graph Neural Networks (HGNNs) extend GNNs
to incorporate diverse relational information, making them well-
suited for tasks like node classification [ 30,31] and link predic-
tion [ 15,26]. In financial applications, HGNNs have been utilized
for fraud detection and risk assessment [ 21,24], while in recom-
mender systems, they enhance personalized recommendations by
capturing cross-domain interactions [ 4,27]. Despite these advan-
tages, research has primarily focused on improving HGNN per-
formance, leaving their security vulnerabilities relatively underex-
plored. Recent studies highlight their susceptibility to adversarial
threats [ 6,32], among which backdoor attacks pose a particularly
severe risk due to their stealthiness and potential impact on critical
decision-making [22].
Backdoor attacks aim to manipulate a modelâ€™s behavior under
specific input conditions by intentionally altering its training data.
While traditional backdoor attacks have been extensively studied
in domains such as computer vision [ 9,11] and natural language
processing [ 2,17], research on backdoor attacks in HGNNs remains
scarce. Unlike homogeneous graphs, heterogeneous graphs cap-
ture richer structural and semantic information through diverse
node types and relationships. HGNNs leverage these heterogeneous
connections to learn comprehensive feature representations forConference acronym â€™XX, June 03â€“05, 2018, Woodstock, NY Trovato et al.
downstream tasks. However, the complexity and diversity of het-
erogeneous graphs also introduce new vulnerabilities, providing
attackers with opportunities to embed backdoors by carefully mod-
ifying the graph structure or feature representations in a targeted
manner. Once a backdoor is successfully implanted, an attacker can
exploit specific trigger patterns to mislead the model into producing
incorrect outputs, potentially leading to severe security risks. For
example, in financial systems, an attacker can introduce a fake bank
account under a customerâ€™s identity into the network. By creating
hidden connections between the fraudulent account and transac-
tion history, the attacker can manipulate the systemâ€™s judgment,
potentially evading detection.
Existing backdoor attack methods primarily focus on homoge-
neous graphs. Dai et al. argue that trigger insertion disrupts the
message-passing process between nodes, thereby compromising the
modelâ€™s integrity [ 3]. To address this, they propose Unnoticeable
Graph Backdoor Attack (UGBA), which leverages a bi-level opti-
mization framework to execute backdoor attacks under a limited
attack budget while minimizing detectability. In contrast, Xing et al.
introduce Clean-Label Graph Backdoor Attack (CGBA) [ 25], which
injects triggers into node feature representations without altering
node labels or graph structure. By selecting triggers from existing
node features with high similarity to their neighbors, CGBA en-
hances attack stealthiness and avoids structural modifications, mak-
ing it more resistant to defense mechanisms. However, these meth-
ods of backdoor attacks on node classification tasks overlook the
diversity of edge relationships and node types. To address this limi-
tation and exploit potential vulnerabilities in HGNNs, we propose a
novel Hetero geneous Backdoor Attack (HeteroBA) method specifi-
cally designed for node classification in heterogeneous graphs.
Unlike existing node classification backdoor attack methods,
HeteroBA represents a novel and targeted approach specifically
engineered for heterogeneous graphs. By strategically injecting
minimally invasive triggers, HeteroBA effectively achieves supe-
rior attack performance while maintaining exceptional invisibility,
setting a new standard in graph-based adversarial techniques.
Specifically, when the targeted nodes of the attack have been
selected, new trigger nodes are introduced into the graph to carry
out the attack. These trigger nodes are strategically connected to
the targeted nodes and some highly influential nodes, i.e., those
nodes that can significantly impact information propagation within
the graph, forming subtle but effective perturbations. The features
of the trigger nodes are constructed based on the statistical prop-
erties of nodes of the same type, ensuring consistency with the
existing graph structure and enhancing stealthiness. Finally, after
modifying the labels of the targeted nodes, the poisoned graph,
embedded with these adversarial triggers and connections, ensures
that when the backdoored model encounters similar trigger patterns
during inference, it misclassifies the targeted nodes as belonging to
a specific wrongful class as intended by the attacker. Note that the
proposed attack can lead to misclassification of multiple targeted
nodes into the same wrongful class (hereafter termed as designated
target class ).
The main contribution of this paper is as follows:
â€¢We propose HeteroBA, the first dedicated backdoor attack
on heterogeneous graphs for the node classification task,achieving high attack success rates across various models
and datasets.
â€¢HeteroBA effectively manipulates the graph structure to
enhance the attack while maintaining efficiency in execution.
â€¢Extensive experiments on multiple benchmark datasets vali-
date the effectiveness of HeteroBA, outperforming baselines
in multiple cases and demonstrating strong attack capability.
We also propose a method to calculate the stealthiness score
for node injection-based backdoor attacks.
The remainder of this paper is structured as follows: Section 2
provides a brief review of related work. Section 3 introduces the
necessary preliminaries and definitions. Our proposed methodology
is presented in detail in Section 4. To evaluate its effectiveness, we
conduct extensive experiments and analyses on multiple benchmark
datasets and models in Section 5. Finally, Section 6 concludes the
paper. Our code has been open-sourced and is publicly available1.
2 Related Work
2.1 Heterogeneous Graph Neural Networks
HGNNs have evolved significantly in recent years [ 5,7,37,38], with
various architectures designed to effectively capture heterogeneous
relationships. Among them, the most representative models include
a few as follows. HAN [ 20] introduces meta-path-based attention
to selectively aggregate information along predefined relational
paths, providing interpretability in node representations. HGT [ 8]
extends this approach by leveraging a transformer-based architec-
ture to dynamically model heterogeneous interactions. Meanwhile,
SimpleHGN [ 13] optimizes message passing by simplifying the het-
erogeneity modeling process, making it computationally efficient
while maintaining strong performance.
While these methods significantly improve learning on hetero-
geneous graphs, their robustness under malicious manipulation has
received limited attention. The unique characteristics of HGNNs,
such as diverse node and edge types and advanced attention mech-
anisms, present both opportunities and challenges for potential
attackers, making them an important area for further exploration.
2.2 Backdoor Attack on Homogeneous Graph
Backdoor attacks on graph neural networks (GNNs) embed hidden
triggers during training, allowing adversaries to control outputs
under specific conditions. Existing attacks on homogeneous graphs
are classified by their trigger injection strategies.
Feature-based Backdoor Attacks introduce malicious triggers
by modifying node attributes while keeping the graph structure
unchanged. NFTA (Node Feature Target Attack) [ 1] injects fea-
ture triggers without requiring knowledge of GNN parameters,
disrupting the feature space and confusing model predictions. It
also introduces an adaptive strategy to balance feature smoothness.
Xing et al. [ 25] selected trigger nodes with high similarity to neigh-
bors, ensuring stealthiness without modifying labels or structure.
However, both methods rely solely on feature manipulation, mak-
ing them less effective when structural changes significantly impact
message passing.
1https://anonymous.4open.science/r/HeteroBA-EEAFHeteroBA: A Structure-Manipulating Backdoor Attack on Heterogeneous Graphs Conference acronym â€™XX, June 03â€“05, 2018, Woodstock, NY
Structure-based Backdoor Attacks manipulate the graph topol-
ogy by adding or removing edges to implant triggers. Zhang et al.
[34] introduced a subgraph-based trigger to mislead graph clas-
sification models while maintaining high attack success rates. Xi
et al. [ 23] extended this concept by generating adaptive subgraph
triggers that dynamically tailor the attack for different inputs. Dai
et al. [ 3] employed a bi-level optimization strategy to modify graph
structures under an attack budget, maximizing stealthiness while
ensuring effectiveness.
Although these methods demonstrate the feasibility of backdoor
attacks on homogeneous graphs, their reliance on uniform graph
structures and simple node relationships limits their applicability
to the more complex heterogeneous graph setting.
2.3 Attacks on Heterogeneous Graph Neural
Networks
Heterogeneous graphs have shown vulnerabilities under adversar-
ial attacks, and several studies have explored this area. Zhang et
al. [33] proposed RoHe, a robust HGNN framework that defends
against adversarial attacks by pruning malicious neighbors using
an attention purifier. Zhao et al. [ 35] introduced HGAttack, the first
grey-box evasion attack specifically targeting HGNNs, which lever-
ages a semantic-aware mechanism and a novel surrogate model to
generate perturbations. These works highlight the susceptibility
of HGNNs to adversarial manipulations and the progress made in
addressing these threats.
However, while adversarial attacks on heterogeneous graphs
and backdoor attacks on homogeneous graphs have been explored,
no prior work has investigated backdoor vulnerabilities in HGNNs.
Our research addresses this gap by proposing a novel backdoor
attack method specifically designed for heterogeneous graphs, lever-
aging their unique structural properties to embed triggers while
maintaining high attack success rates and stealthiness.
3 Preliminaries and problem formulation
In this section, we introduce the preliminaries of backdoor attacks
on heterogeneous graphs and define the problem. Table 1 summa-
rizes the notation used throughout this section for clarity.
3.1 Preliminaries
Definition 3.1 (Heterogeneous graph) A heterogeneous graph
is defined as ğº={V,E,ğ‘‹}, whereV={ğ‘£1,ğ‘£2,...,ğ‘£ğ‘›}is the node
set, andğ‘‹âˆˆR|V|Ã—ğ‘‘is a node feature matrix with ğ‘‘being the
dimension of each node feature.
The setT={ğ‘¡1,ğ‘¡2,...,ğ‘¡ğ‘‡}representsğ‘‡different node types,
where each node ğ‘£âˆˆ V belongs to one specific type ğ‘¡âˆˆ T .
Nodes for each type ğ‘¡is represented by the subset Vğ‘¡, and its
size is denoted asâˆ¥Vğ‘¡âˆ¥. The set of edge types is denoted as R=
ğ‘Ÿğ‘¡ğ‘,ğ‘¡ğ‘|ğ‘¡ğ‘,ğ‘¡ğ‘âˆˆT,ğ‘¡ğ‘â‰ ğ‘¡ğ‘	
where each edge type ğ‘Ÿğ‘¡ğ‘,ğ‘¡ğ‘represents
connections between nodes of type ğ‘¡ğ‘and nodes of type ğ‘¡ğ‘. For each
pair of node types(ğ‘¡ğ‘,ğ‘¡ğ‘), we maintain an adjacency matrix ğ´ğ‘¡ğ‘,ğ‘¡ğ‘âˆˆ
{0,1}|Vğ‘¡ğ‘|Ã—Vğ‘¡ğ‘, whereğ´ğ‘¡ğ‘,ğ‘¡ğ‘ ğ‘£ğ‘–,ğ‘£ğ‘—=1indicates an edge be-
tween node ğ‘£ğ‘–âˆˆVğ‘¡ğ‘and nodeğ‘£ğ‘—âˆˆVğ‘¡ğ‘. We then define the edge
setEas the union of all such edges, recorded as triples ğ‘£ğ‘–,ğ‘£ğ‘—,ğ‘Ÿğ‘¡ğ‘,ğ‘¡ğ‘:
E=Ã
ğ‘Ÿğ‘¡ğ‘,ğ‘¡ğ‘âˆˆR ğ‘£ğ‘–,ğ‘£ğ‘—,ğ‘Ÿğ‘¡ğ‘,ğ‘¡ğ‘|ğ‘£ğ‘–âˆˆVğ‘¡ğ‘,ğ‘£ğ‘—âˆˆVğ‘¡ğ‘,ğ´ğ‘¡ğ‘,ğ‘¡ğ‘ ğ‘£ğ‘–,ğ‘£ğ‘—=1	
Figure 1: Overall Backdoor Attack Process on a Heteroge-
neous Graph.
Hence, each adjacency matrix ğ´ğ‘¡ğ‘,ğ‘¡ğ‘describes the connectivity be-
tween nodes of types ğ‘¡ğ‘andğ‘¡ğ‘, and each nonzero entry in ğ´ğ‘¡ğ‘,ğ‘¡ğ‘
corresponds to an edge in E. A heterogeneous graph satisfies the
conditionğ‘‡+|R| >2.
Definition 3.2 (Primary type, trigger type and auxiliary
type) We define three key types. The primary type ğ‘¡ğ‘âˆˆT refers
to the type of nodes for classification. The trigger type ğ‘¡ğ‘¡ğ‘ŸâˆˆT
denotes the type of nodes added as backdoor triggers. The auxiliary
type comprises node types ğ‘¡ğ‘âˆˆ T that can be reached from a
primary-type node ğ‘£ğ‘¡ğ‘âˆˆVğ‘¡ğ‘via a trigger-type node ğ‘£ğ‘¡ğ‘¡ğ‘ŸâˆˆVğ‘¡ğ‘¡ğ‘Ÿ
in exactly two hops. Formally, Taux=
ğ‘¡ğ‘âˆˆTâˆƒğ‘£ğ‘¡ğ‘âˆˆVğ‘¡ğ‘,ğ‘£ğ‘¡ğ‘¡ğ‘Ÿâˆˆ
Vğ‘¡ğ‘¡ğ‘Ÿ,ğ‘£ğ‘¡ğ‘âˆˆVğ‘¡ğ‘:(ğ‘£ğ‘¡ğ‘,ğ‘£ğ‘¡ğ‘¡ğ‘Ÿ,ğ‘Ÿğ‘¡ğ‘,ğ‘¡ğ‘¡ğ‘Ÿ)âˆˆE,(ğ‘£ğ‘¡ğ‘¡ğ‘Ÿ,ğ‘£ğ‘¡ğ‘,ğ‘Ÿğ‘¡ğ‘¡ğ‘Ÿ,ğ‘¡ğ‘)âˆˆE	
.
Definition 3.3 (Designated target class and non-target classes)
LetYdenote the set of class labels in the classification task. The des-
ignated target class is defined as ğ‘¦ğ‘¡âˆˆY, representing the label to
which the attacker aims to misclassify certain nodes. The non-target
classes are given by YÂ¬ğ‘¡=Y\{ğ‘¦ğ‘¡}. In a heterogeneous graph, clas-
sification is performed on nodes of the primary type ğ‘¡ğ‘, whose
node set is denoted as Vğ‘¡ğ‘. Based on their ground-truth labels, we
define:Vğ‘¦ğ‘¡=n
ğ‘£âˆˆVğ‘¡ğ‘|ğ‘¦ğ‘£=ğ‘¦ğ‘¡o
,VÂ¬ğ‘¦ğ‘¡=n
ğ‘£âˆˆVğ‘¡ğ‘|ğ‘¦ğ‘£â‰ ğ‘¦ğ‘¡o
.
By definition,Vğ‘¦ğ‘¡âˆªVÂ¬ğ‘¦ğ‘¡=Vğ‘¡ğ‘andVğ‘¦ğ‘¡âˆ©VÂ¬ğ‘¦ğ‘¡=âˆ….
3.2 Problem definition
Given a heterogeneous graph ğº=(V,E,ğ‘‹)and a node clas-
sification model ğ‘“ğœƒ:Vğ‘¡ğ‘â†’ Y trained on the primary node
typeVğ‘¡ğ‘âŠ† V , a backdoor attack alters ğºto construct a poi-
soned graph eğº=(eV,eE,eğ‘‹), ensuring that after training on eğº, the
model misclassifies specific target nodes while preserving overall
classification accuracy. To construct eğº, the attacker introduces a
set of new trigger nodes V(new)
ğ‘¡ğ‘¡ğ‘Ÿwith feature matrix ğ‘‹(new)and
new edgesE(ğ‘›ğ‘’ğ‘¤)connecting them to existing nodes, resulting
ineV=VâˆªV(new)
ğ‘¡tr,eE=EâˆªE(new), andeğ‘‹=ğ‘‹
ğ‘‹(new)
.
Specifically, the attacker selects a subset of primary-type nodes,
denoted asV(ğ‘)âŠ†Vğ‘¡ğ‘, as targeted nodes, and aims to enforce
their wrongful classification into a designated target class ğ‘¦ğ‘¡dur-
ing inference, i.e., ğ‘“ğœƒ(eğº,ğ‘£)=ğ‘¦ğ‘¡,âˆ€ğ‘£âˆˆV(ğ‘). Meanwhile, for theConference acronym â€™XX, June 03â€“05, 2018, Woodstock, NY Trovato et al.
Table 1: Notation and Definitions
Symbol Meaning
ğº=(V,E,ğ‘‹) Heterogeneous graph
V,E,ğ‘‹ Nodes, edges, feature matrix
T,R Node/edge type sets
ğ‘¡ğ‘,ğ‘¡ğ‘¡ğ‘Ÿ Primary/trigger node types
Taux Auxiliary node types
ğ´ğ‘¡ğ‘,ğ‘¡ğ‘âˆˆ{0,1}|Vğ‘¡ğ‘|Ã—Vğ‘¡ğ‘Adjacency matrix between types ğ‘¡ğ‘,ğ‘¡ğ‘
Y Class label set
ğ‘¦ğ‘¡ Target class
Vğ‘¡ğ‘,V(ğ‘)Primary-type nodes, poisoned subset
Vğ‘¦ğ‘¡,VÂ¬ğ‘¦ğ‘¡ Primary-type nodes w/ or w/o label ğ‘¦ğ‘¡
V(new)
ğ‘¡trNewly added trigger nodes
ğ‘‹(new),E(new)New trigger-node features, edges
eğº=(fV,eE,eğ‘‹) Poisoned graph
ğ‘“ğœƒ Classification model
F(ğº) Allowed modifications
1(Â·) Indicator function
remaining primary-type nodes Vğ‘¡ğ‘\V(ğ‘), the model should retain
its correct predictions, i.e., ğ‘“ğœƒ(eğº,ğ‘£)=ğ‘¦ğ‘£,âˆ€ğ‘£âˆˆVğ‘¡ğ‘\V(ğ‘). Formally,
the attack is formulated as an optimization problem:
eğºâˆ—=arg max
eğºâˆˆF(ğº)ï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£°âˆ‘ï¸
ğ‘£âˆˆV(ğ‘)1 ğ‘“ğœƒ(eğº,ğ‘£)=ğ‘¦ğ‘¡+âˆ‘ï¸
ğ‘£âˆˆVğ‘¡ğ‘\V(ğ‘)1 ğ‘“ğœƒ(eğº,ğ‘£)=ğ‘¦ğ‘£ï£¹ï£ºï£ºï£ºï£ºï£ºï£ºï£»(1)
Here, 1(Â·)is an indicator function that returns 1 if the condition
is satisfied and 0 otherwise, and F(ğº)denotes the space of permis-
sible modifications to ğº, which may include adding or modifying
nodes, edges, or node features.
4 Methodology
In this section, we introduce the details of HeteroBA, which aims to
meet Eq. (1) to conduct backdoor attacks on heterogeneous graphs.
Since directly optimizing the features and connections of the in-
serted trigger node ğ‘£(ğ‘›ğ‘’ğ‘¤)
ğ‘¡ğ‘¡ğ‘Ÿto ensure both attack effectiveness and
stealthiness is computationally expensive and challenging, Het-
eroBA decomposes the attack process into two key components,
addressing the following two core challenges: (i) how to generate
the features of the inserted trigger node ğ‘£(ğ‘›ğ‘’ğ‘¤)
ğ‘¡ğ‘¡ğ‘Ÿto enhance their
stealthiness and make them less detectable; (ii) how to construct
the connections of the inserted trigger node ğ‘£(ğ‘›ğ‘’ğ‘¤)
ğ‘¡ğ‘¡ğ‘Ÿto maximize
attack effectiveness while maintaining structural consistency with
the original graph. To tackle these challenges, HeteroBA consists of
two main modules. The Feature Generator is responsible for gener-
ating trigger node features by learning the distribution of existing
Vğ‘¡ğ‘¡ğ‘Ÿnodes. This process ensures that the injected trigger nodes
blend seamlessly into the overall feature space, thereby improving
stealthiness. The Edge Generator determines how the inserted trig-
ger nodeğ‘£(ğ‘›ğ‘’ğ‘¤)
ğ‘¡ğ‘¡ğ‘Ÿconnects to existing nodes. Specifically, ğ‘£(ğ‘›ğ‘’ğ‘¤)
ğ‘¡ğ‘¡ğ‘Ÿis
linked to primary-type nodes ğ‘£ğ‘¡ğ‘âˆˆVğ‘¡ğ‘and auxiliary type nodes
ğ‘£ğ‘¡ğ‘âˆˆTaux. To establish these connections, HeteroBA introduces
two strategies: a clustering-based strategy and an attention-based
strategy.By integrating these two modules, HeteroBA generates a new
poisoned graph eğº=(eV,eE,eğ‘‹), which ensures both high attack
effectiveness and strong stealthiness. Fig. 1 provides a conceptual
illustration of how HeteroBA generates trigger nodes and estab-
lishes connections. The pseudocodes of this process are provided
in Appendix D, and the corresponding time complexity analysis is
detailed in Appendix A.
4.1 Feature generator
In HeteroBA, the Feature Generator is responsible for generating
feature embeddings for the inserted trigger nodes ğ‘£(ğ‘›ğ‘’ğ‘¤)
ğ‘¡ğ‘¡ğ‘Ÿ, ensur-
ing that they remain indistinguishable from existing nodes in the
feature space. To achieve this, we first extract the set of non-target
class nodesVÂ¬ğ‘¦ğ‘¡and identify their neighbors connected via edges
of typeğ‘Ÿğ‘¡ğ‘,ğ‘¡ğ‘¡ğ‘Ÿ. We can get the subset of trigger-type nodes Vğ‘¡ğ‘¡ğ‘Ÿ
that are linked toVÂ¬ğ‘¦ğ‘¡and denote this subset as Vâ€²
ğ‘¡ğ‘¡ğ‘Ÿ, which is
used as the basis for feature generation by two strategies, one for
continuous features and one for binary features.
4.1.1 Continuous Feature Generation. For each feature dimension
ğ‘—âˆˆ {1,2,...,ğ‘‘}inğ‘‹â€²
ğ‘¡ğ‘¡ğ‘Ÿ, we employ Kernel Density Estimation
(KDE) [ 18] to approximate the underlying probability distribution:
Ë†ğ‘“(ğ‘¥)=1
ğ‘šâ„ğ‘šâˆ‘ï¸
ğ‘˜=1ğ¾ğ‘¥âˆ’ğ‘¥ğ‘˜
â„
, (2)
whereğ¾(Â·)is the kernel function (commonly Gaussian), â„is the
bandwidth, and{ğ‘¥ğ‘˜}ğ‘š
ğ‘˜=1represents the feature values of dimension
ğ‘—for all nodes inVâ€²
ğ‘¡ğ‘¡ğ‘Ÿ, withğ‘š=Vâ€²
ğ‘¡ğ‘¡ğ‘Ÿdenoting the number of
nodes in this subset. Let Ë†ğ‘“ğ‘—denote the fitted KDE for the ğ‘—-th feature
dimension. We then sample the feature values for newly inserted
trigger nodesV(new)
ğ‘¡ğ‘¡ğ‘Ÿfrom this estimated distribution:
ğ‘‹(new)(ğ‘–,ğ‘—) âˆ¼ Ë†ğ‘“ğ‘—,âˆ€ğ‘–=1,...,V(new)
ğ‘¡ğ‘¡ğ‘Ÿandğ‘—=1,...,ğ‘‘. (3)
This ensures that each dimension of the newly generated features
follows the same statistical profile as the existing trigger-type nodes
inVâ€²
ğ‘¡ğ‘¡ğ‘Ÿ. Consequently, the resulting feature matrix ğ‘‹(new)for the
inserted nodes seamlessly aligns with the original distribution,
thereby enhancing the stealth of the injected triggers.
4.1.2 Binary Feature Generation. When node features are binary
(e.g., indicating a categorical attribute or the presence/absence of a
property), directly applying KDE is not feasible. Instead, we com-
pute the empirical probability of each feature being 1 from the
extracted setVâ€²
ğ‘¡ğ‘¡ğ‘Ÿ. Specifically, for each binary feature dimension
ğ‘—âˆˆ{1,2,...,ğ‘‘}, let
Ë†ğ‘ğ‘—=1
ğ‘šğ‘šâˆ‘ï¸
ğ‘˜=1ğ‘‹â€²
ğ‘¡ğ‘¡ğ‘Ÿ(ğ‘˜,ğ‘—), (4)
whereğ‘‹â€²
ğ‘¡ğ‘¡ğ‘Ÿ(ğ‘˜,ğ‘—)is theğ‘—-th feature of the ğ‘˜-th node inVâ€²
ğ‘¡ğ‘¡ğ‘Ÿ, and
ğ‘š=|Vâ€²
ğ‘¡ğ‘¡ğ‘Ÿ|. We then generate the binary features for the newly
inserted trigger nodes V(new)
ğ‘¡ğ‘¡ğ‘Ÿby sampling each dimension ğ‘—via a
Bernoulli distribution:
ğ‘‹(new)(ğ‘–,ğ‘—) âˆ¼ Bernoulli Ë†ğ‘ğ‘—,âˆ€ğ‘–=1,...,V(new)
ğ‘¡ğ‘¡ğ‘Ÿandğ‘—=1,...,ğ‘‘.
(5)HeteroBA: A Structure-Manipulating Backdoor Attack on Heterogeneous Graphs Conference acronym â€™XX, June 03â€“05, 2018, Woodstock, NY
This process ensures that the newly generated binary features main-
tain the same empirical probabilities as the existing trigger-type
nodes, preserving consistency with the original data distribution.
By combining both the continuous and binary feature generation
strategies, the feature generator can effectively produce feature
embeddings for trigger nodes that blend seamlessly into the het-
erogeneous graph, thus minimizing the risk of detection.
4.2 Edge Generator
To determine which existing nodes should connect with the newly
inserted trigger nodes, we first use edge type ğ‘Ÿğ‘¡ğ‘,ğ‘¡ğ‘¡ğ‘Ÿto gather the
first-hop trigger-type neighbors V(1)
ğ‘¡ğ‘¡ğ‘ŸâŠ†Vğ‘¡ğ‘¡ğ‘ŸofVğ‘¦ğ‘¡, then collect
the second-hop auxiliary-type neighbors V(2)
auxâŠ†V auxbased on
V(1)
ğ‘¡ğ‘¡ğ‘Ÿvia edgesğ‘Ÿğ‘¡ğ‘¡ğ‘Ÿ,ğ‘¡ğ‘forğ‘¡ğ‘âˆˆ T aux. The identified second-hop
neighbors serve as the backup nodes, which will be connected to
the trigger nodes.
For each auxiliary type ğ‘¡ğ‘âˆˆTaux, the number of auxiliary-type
nodes connected to each trigger node is denoted as ğ‘‘ğ‘¡ğ‘, which
corresponds to the average degree of trigger-type nodes on edges
of typeğ‘Ÿğ‘¡ğ‘¡ğ‘Ÿ,ğ‘¡ğ‘. We next feed the heterogeneous graph ğºinto a
surrogate modelMto retrieve attention weights ğ›¼(ğ‘¢,ğ‘£)and node
embeddings zğ‘£. Building on these outputs, the attention-based and
clustering-based strategies respectively utilize attention values and
embeddings to select the top ğ‘‘ğ‘¡ğ‘most influential nodes in each
auxiliary type ğ‘¡ğ‘âˆˆTaux, which are then connected to the newly
inserted trigger nodes.
In HeteroBA, we select SimpleHGN [ 13] asMfor three primary
reasons: it directly yields both node embeddings and attention
scores, has comparatively fewer parameters than other heteroge-
neous models, and requires no explicit metapath definition, thereby
mitigating potential biases from metapath design.
4.2.1 Attention-based strategy. We leverage the learned attention
coefficients ğ›¼(ğ‘¢,ğ‘£)from the surrogate model Mto quantify the
importance of each node in V(2)
auxin influencingVğ‘¦ğ‘¡. Specifically,
for each target node ğ‘£ğ‘¦ğ‘¡âˆˆVğ‘¦ğ‘¡, we consider its first-hop trigger-
type neighbors inV(1)
ğ‘¡ğ‘¡ğ‘Ÿvia edges of type ğ‘Ÿğ‘¡ğ‘,ğ‘¡ğ‘¡ğ‘Ÿ, and subsequently
aggregate contributions from their second-hop neighbors in V(2)
aux
through edges ğ‘Ÿğ‘¡ğ‘¡ğ‘Ÿ,ğ‘¡ğ‘.
For an auxiliary-type node ğ‘£(2)
auxâˆˆV(2)
aux, its influence on ğ‘£ğ‘¦ğ‘¡is de-
termined by the product of the first-layer attention value ğ›¼(ğ‘£(2)
aux,ğ‘£(1)
ğ‘¡ğ‘¡ğ‘Ÿ)
and the second-layer attention value ğ›¼(ğ‘£(1)
ğ‘¡ğ‘¡ğ‘Ÿ,ğ‘£ğ‘¦ğ‘¡):
ğ¼ ğ‘£(2)
aux,ğ‘£ğ‘¦ğ‘¡=âˆ‘ï¸
ğ‘£(1)
ğ‘¡ğ‘¡ğ‘ŸâˆˆV(1)
ğ‘¡ğ‘¡ğ‘Ÿ(ğ‘£ğ‘¦ğ‘¡)ğ›¼(ğ‘£(2)
aux,ğ‘£(1)
ğ‘¡ğ‘¡ğ‘Ÿ)Â·ğ›¼(ğ‘£(1)
ğ‘¡ğ‘¡ğ‘Ÿ,ğ‘£ğ‘¦ğ‘¡). (6)
whereV(1)
ğ‘¡ğ‘¡ğ‘Ÿ(ğ‘£ğ‘¦ğ‘¡)represents the set of first-hop trigger-type neigh-
bors ofğ‘£ğ‘¦ğ‘¡.
Summing over all ğ‘£ğ‘¦ğ‘¡âˆˆVğ‘¦ğ‘¡, we compute the total importance
score for each auxiliary-type node:
ğ¼ ğ‘£(2)
aux=âˆ‘ï¸
ğ‘£ğ‘¦ğ‘¡âˆˆVğ‘¦ğ‘¡ğ¼ ğ‘£(2)
aux,ğ‘£ğ‘¦ğ‘¡. (7)Nodes inV(2)
auxwith higher ğ¼(ğ‘£(2)
aux)scores are ranked in descend-
ing order, and the top-ranked nodes in each auxiliary type are
selected to connect with the newly inserted trigger nodes. This en-
sures that adversarial information is efficiently propagated toward
Vğ‘¦ğ‘¡, thereby enhancing the backdoor attack effectiveness while
maintaining the structural consistency of the heterogeneous graph.
4.2.2 Clustering-based Strategy. In another strategy, we leverage
the node embeddings obtained from the surrogate model Mto
identify structurally and semantically cohesive nodes within V(2)
aux.
Specifically, we extract the embedding representations of all second-
hop auxiliary-type neighbors V(2)
auxand employ a clustering-based
selection strategy to determine which nodes should connect to the
newly inserted trigger nodes.
Given the embedding matrix ZâˆˆR|V(2)
aux|Ã—ğ‘‘, where each row zğ‘–
corresponds to the ğ‘‘-dimensional embedding of node ğ‘£(2)
aux,ğ‘–âˆˆV(2)
aux,
we first compute the pairwise cosine similarity matrix:
ğ‘†=ZÂ·Zğ‘‡, (8)
where the entry ğ‘†ğ‘–ğ‘—represents the cosine similarity between nodes
ğ‘£(2)
aux,ğ‘–andğ‘£(2)
aux,ğ‘—. To ensure that self-similarity does not dominate
the selection process, we set the diagonal elements of ğ‘†to zero:
ğ‘†ğ‘–ğ‘–=0,âˆ€ğ‘–âˆˆ{1,2,...,|V(2)
aux|}. (9)
For each node ğ‘£(2)
aux,ğ‘–, we compute its average similarity score,
defined as:
ğ¼(ğ‘£(2)
aux,ğ‘–)=1
|V(2)
aux|âˆ’1âˆ‘ï¸
ğ‘—â‰ ğ‘–ğ‘†ğ‘–ğ‘—. (10)
Nodes inV(2)
auxwith higher ğ¼(ğ‘£(2)
aux,ğ‘–)scores exhibit stronger em-
bedding similarities to other nodes within the same type, indicating
their centrality within structurally cohesive regions. We rank all
nodes in descending order based on ğ¼(ğ‘£(2)
aux,ğ‘–)and select the top-
ranked nodes within each auxiliary type to connect with the newly
inserted trigger nodes.
By enforcing connections with the most clustered and semanti-
cally aligned nodes, this strategy ensures that the inserted trigger
nodes integrate seamlessly into the graph structure, thereby im-
proving stealthiness while maintaining attack effectiveness.
5 Experiments
In this section, we evaluate our proposed method on multiple bench-
mark datasets to investigate the following research questions:
RQ1: How effective is the attack?
RQ2: How is the stealthiness?
RQ3: Do the two edge-generation strategies (e.g., attention-based
or clustering-based) indeed improve attack performance ?
RQ4: What is the relationship between the poison rate and attack
effectiveness?
RQ5: Why do these particular auxiliary-type nodes effectively
facilitate backdoor infiltration in a heterogeneous graph,
and what crucial role do they play in the attack success?Conference acronym â€™XX, June 03â€“05, 2018, Woodstock, NY Trovato et al.
5.1 Experimental Settings
5.1.1 Datasets. We evaluate our method on three real-world het-
erogeneous datasets: DBLP, ACM, and IMDB[ 5]. DBLP consists of
four entity types (authors, papers, terms, conferences), with authors
being categorized into three research areas (database, data mining,
artificial intelligence). ACM includes papers from KDD, SIGMOD,
SIGCOMM, MobiCOMM, and VLDB, being categorized into three
fields (database, wireless communication, data mining). IMDB con-
tains movies, keywords, actors, and directors, with movies being
classified into action, comedy, and drama. The statistics of these
datasets are shown in Table 2.
Table 2: Dataset Statistics
Dataset #Node Types #Edge Types #Nodes #Edges Primary Type
ACM 3 4 11252 34864 paper
IMDB 3 4 11616 34212 movie
DBLP 4 6 26198 242142 author
5.1.2 Train settings. We conduct experiments using HAN [ 20],
HGT [ 8], and SimpleHGN [ 13] as victim models, ensuring a fair
comparison of backdoor attack performance under the same train-
ing and evaluation conditions. The dataset is divided into training,
testing, and validation sets. The training set comprises 70% of the
primary-type nodes Vğ‘¡ğ‘, including both clean and poisoned nodes.
Specifically, the poisoned training set (Poison Trainset) accounts
for 5% ofVğ‘¡ğ‘, serving as the injected trigger nodes to facilitate
backdoor activation. The testing set constitutes 20% of Vğ‘¡ğ‘, within
which the poisoned testing set (Poison Testset) also accounts for
5%, allowing us to evaluate the attackâ€™s effectiveness during infer-
ence. The remaining 10% is allocated to the validation set, which is
used for hyperparameter tuning and early stopping. The training
parameters are provided in Appendix B.
5.1.3 Compared Methods. Since our work is the first to explore
backdoor attacks on heterogeneous graphs, we adapt existing back-
door attack methods originally designed for homogeneous graphs,
namely UGBA [ 3] and CGBA [ 25], and modify them to be compati-
ble with heterogeneous graphs, using the adapted versions as our
baselines.
For UGBA, to ensure its applicability to heterogeneous graphs,
we first convert the heterogeneous graph into a homogeneous graph.
Following UGBAâ€™s bi-level optimization strategy, we generate and
inject adversarial graph structures. After completing the attack
in the homogeneous setting, we convert the graph back into its
heterogeneous form. During this process, the newly inserted nodes
and edges introduced by UGBA are assigned random node types
and edge types to conform to the heterogeneous graph schema.
For CGBA, as it does not involve structural modifications, we
directly adapt its feature perturbation strategy to heterogeneous
graphs by applying it to the nodes in V(ğ‘), ensuring its effective-
ness in this setting.
5.1.4 Evaluation Metrics. The Attack Success Rate (ASR) [3] mea-
sures the probability that the backdoored model ğ‘“ğ‘misclassifies a
sample embedded with a trigger ğ‘”ğ‘¡into the target class ğ‘¦ğ‘¡. Formally,
ASR is defined as:ğ´ğ‘†ğ‘…=Ãğ‘›
ğ‘–=11(ğ‘“ğ‘(ğ‘£ğ‘–)=ğ‘¦ğ‘¡)
ğ‘›(11)
whereğ‘›denotes the number of poisoned test samples, and 1(Â·)
represents the indicator function. A higher ASR indicates a more
effective backdoor attack.
The Clean Accuracy Drop (CAD) [25] quantifies the degradation
in classification accuracy of the backdoored model ğ‘“ğ‘on clean
samples compared to the clean model ğ‘“ğ‘. It is defined as:
ğ¶ğ´ğ· =ğ´ğ‘ğ‘ğ‘“ğ‘(Clean)âˆ’ğ´ğ‘ğ‘ğ‘“ğ‘(Clean) (12)
whereğ´ğ‘ğ‘ğ‘“ğ‘(Clean)andğ´ğ‘ğ‘ğ‘“ğ‘(Clean)denote the prediction accu-
racies of the clean model ğ‘“ğ‘and the backdoored model ğ‘“ğ‘on clean
samples, respectively. A lower CAD indicates that the backdoor
attack preserves the original modelâ€™s performance on clean data.
We introduce a method to calculate the Stealthiness Score for
node injection-based methods in heterogeneous graphs, providing
a quantitative measure for evaluating the concealment of injected
nodes. This score assesses the similarity between injected trigger
nodes and clean nodes in both feature and structural aspects. Given
the original graph ğºand the poisoned graph eğº, we compute the
feature similarity Sim featand structural similarity Sim struct , then
combine them to obtain the final score.
Feature similarity measures how closely the injected nodesâ€™ fea-
ture distribution matches that of clean nodes. Let V(ğ‘›ğ‘’ğ‘¤)
ğ‘¡ğ‘¡ğ‘Ÿbe the set
of newly injected trigger nodes and V(ğ‘ğ‘™ğ‘’ğ‘ğ‘›)
ğ‘¡ğ‘¡ğ‘Ÿthe clean nodes of the
same type. For each feature dimension ğ‘–, we compute the Wasser-
stein distance WDğ‘–between the feature distributions of these two
sets and define the average Wasserstein distance as:
WD=1
ğ‘‘ğ‘‘âˆ‘ï¸
ğ‘–=1WDğ‘–. (13)
Feature similarity is then given by:
Sim feat=1
1+WD. (14)
Structural similarity evaluates the degree consistency between
injected and clean nodes. Let Â¯ğ‘‘ğ‘¡ğ‘Ÿğ‘”and Â¯ğ‘‘ğ‘ğ‘™ğ‘’ğ‘ğ‘› be the average degrees
of injected and clean nodes, respectively. The degree difference is
defined as:
Î”ğ‘‘=|Â¯ğ‘‘ğ‘¡ğ‘Ÿğ‘”âˆ’Â¯ğ‘‘ğ‘ğ‘™ğ‘’ğ‘ğ‘›|, (15)
and the structural similarity is computed as:
Sim struct=1
1+Î”ğ‘‘. (16)
The final stealthiness score is a weighted sum of both compo-
nents:
Stealthiness(ğº,eğº)=ğ‘¤1Â·Sim feat+ğ‘¤2Â·Sim struct, (17)
whereğ‘¤1andğ‘¤2are weighting factors (default to 0.5). A higher
score indicates that the injected nodes blend more naturally into the
graph, enhancing attack stealthiness. Unlike previous works, which
qualitatively discuss stealthiness, our proposed Stealthiness Score
provides a quantitative measure, enabling a more precise evaluation
of attack concealment.HeteroBA: A Structure-Manipulating Backdoor Attack on Heterogeneous Graphs Conference acronym â€™XX, June 03â€“05, 2018, Woodstock, NY
Table 3: Attack effectiveness on three datasets (ACM, DBLP, IMDB).
Dataset Victim Model Class TriggerASR CAD
HeteroBA-C HeteroBA-A HeteroBA-R CGBA UGBA HeteroBA-C HeteroBA-A HeteroBA-R CGBA UGBA
ACMHAN0
author0.9983 0.3748 0.3416 0.9420 0.0664 -0.0033 -0.0028âˆ’0.0558â€ 0.0160 0.0099
1 1.0000 0.7463 0.8275 0.5970 0.9783 -0.0005 0.0480âˆ’0.0602â€ 0.1109 0.0149
2 1.0000 0.7861 0.5224 0.8126 0.0498 -0.0132 -0.0193 âˆ’0.0480â€ -0.0375 0.0149
HGT0
author1.0000 1.0000 0.9751 0.9436 0.9867 -0.0033 -0.0044 0.0226 -0.0022 -0.0038
1 0.9569 0.9469 0.9851â€ 0.8905 0.9851 -0.0061 -0.0028 -0.0017 0.0122 -0.0061
2 1.0000 1.0000 0.7977 0.9005 0.9469 0.0050 -0.0027 0.0138 0.0083 0.0006
SimpleHGN0
author0.9967 1.0000 0.9536 0.9602 1.0000 -0.0027 0.0000 0.0099 -0.0022 -0.0254
1 0.9950 1.0000 0.9967 0.9303 1.0000 0.0028 0.0033 -0.0011 0.0000 -0.0750
2 1.0000 1.0000 0.6965 0.9038 1.0000 0.0011 0.0011 0.0111 0.0033 -0.0695
DBLPHAN0
paper0.7849 0.7783 0.2167 0.8993 0.0673 0.0110 0.0104 0.0005â€ 0.0038 0.0094
1 0.6043 0.6716 0.1576 0.9422 0.0541 0.0214 0.0411 0.0033 0.0022 0.0027
2 0.6749 0.5534 0.1855 0.9142 0.0312 0.0143 0.0011 0.0104 0.0088 -0.0115
HGT0
paper0.9343 0.9130 0.9950â€ 0.9175 0.0788 0.0137 0.0165 0.0148 -0.0027 0.0088
1 0.7980 0.9967 0.7537 0.9505 0.1117 0.0099 0.0137 0.0115 0.0016 0.0110
2 0.8588 0.8867 0.6650 0.9439 0.1790 0.0137 0.0131 0.0181 0.0077 0.0192
SimpleHGN0
paper1.0000 1.0000 0.9984 0.9224 0.0263 0.0016 0.0033 0.0082 0.0077 0.0044
1 0.9754 1.0000 0.6897 0.9538 0.1347 0.0055 0.0033 0.0027â€ -0.0016 0.0066
2 0.7307 0.9294 0.7093 0.9422 0.1084 -0.0060 0.0071 0.0077 0.0011 -0.0044
IMDBHAN0
director0.9953 0.8006 0.6791 0.5618 0.2087 0.0307 0.0089 0.0265 0.0037 0.0364
1 0.9984 0.8473 0.8458 0.4523 0.2991 -0.0031 -0.0192 -0.0094 -0.0119 0.0037
2 1.0000 0.9174 0.9003 0.4992 0.3582 0.0068 -0.0234 -0.0068 0.0010 0.0067
HGT0
director0.8473 0.9237 0.7975 0.4851 0.5109 0.0036 0.0062 0.0021 -0.0104 0.0291
1 0.9299 0.9283 0.8878 0.4147 0.7757 0.0182 0.0234 âˆ’0.0146â€ 0.0130 0.0026
2 0.8894 0.9377 0.8193 0.4523 0.6807 0.0026 -0.0026âˆ’0.0099â€ -0.0015 0.0182
SimpleHGN0
director0.9533 0.9813 0.7679 0.3881 0.8443 -0.0047 0.0021 0.0015 -0.0244 0.0005
1 0.9502 0.9564 0.9486 0.3850 0.9595 0.0047 0.0109 0.0052 -0.0130 0.0291
2 0.9720 0.9642 0.8255 0.3474 0.9330 -0.0052 0.0099âˆ’0.0166â€ 0.0156 0.0078
5.2 Experiment result
5.2.1 Attack effectiveness. To answer RQ1 , we evaluate HeteroBAâ€™s
effectiveness against UGBA and CGBA on three heterogeneous
graph datasets. Each experiment was repeated three times, with
averaged results reported. Table 3 shows key results, while Table 5
in appendix provides additional data. Bold highlights the best ASR
values among HeteroBA-C, HeteroBA-A, UGBA, and CGBA.
HeteroBA consistently achieves high Attack Success Rates (ASR),
outperforming UGBA and CGBA across datasets and models. For
example, on ACM, HeteroBA-A achieves an ASR of 1.0000 on HAN
and HGT, while UGBA reaches only 0.0664 on HAN (class 0). On
DBLP, HeteroBA-C achieves 1.0000 ASR on SimpleHGN (class 0),
surpassing UGBAâ€™s 0.0263. On IMDB, HeteroBA-A achieves 0.9813
ASR on SimpleHGN (class 0), outperforming CGBA (0.3881) and
UGBA (0.8443). These results highlight HeteroBAâ€™s superior attack
effectiveness.
Despite high ASR, HeteroBA introduces minimal classification
accuracy degradation (CAD), often close to zero or negative, indi-
cating little impact on clean data. Although UGBA achieves slightly
lower CAD in some cases (e.g., DBLP, class 1, SimpleHGN), the
difference is negligible. Overall, HeteroBA maintains clean data
performance while achieving superior attack effectiveness.
5.2.2 Stealthiness analysis. As for RQ2 , we compare the Stealth-
iness Score of HeteroBA and UGBA across different datasets and
trigger settings, as shown in Table 4. CGBA is not included in this
comparison since it only perturbs node features without modifying
the graph structure, making the Stealthiness Score inapplicable to
it.
Results show that HeteroBA consistently outperforms UGBA
in stealthiness, indicating that its injected trigger nodes are less
detectable. For instance, in ACM with author as the trigger, Heter-
oBA achieves significantly higher scores across all classes (up to
0.8603), while UGBA remains below 0.2251. In DBLP, where paperis used as the trigger, HeteroBA maintains an advantage, achiev-
ing scores around 0.6201 compared to UGBAâ€™s 0.4841. Similarly,
in IMDB, when using director as the trigger, HeteroBA achieves a
stealthiness score of up to 0.6865, outperforming UGBAâ€™s 0.6531.
These results confirm that HeteroBA effectively integrates trigger
nodes into the original graph through sampled feature and edge
generation strategies, improving attack stealthiness.
Table 4: Stealthiness Score of HeteroBA and UGBA.
Dataset Class Trigger HeteroBA UGBA
ACM0
author0.7715 0.2109
1 0.8603 0.2251
2 0.7226 0.1899
0
field0.3937 0.0342
1 0.3815 0.0342
2 0.3539 0.0294
DBLP0
paper0.6161 0.5063
1 0.6201 0.4841
2 0.6179 0.4963
IMDB0
director0.6567 0.6492
1 0.6711 0.6531
2 0.6865 0.6297
0
actor0.7663 0.6304
1 0.7302 0.6252
2 0.7874 0.6090
5.2.3 Ablation study. To answer RQ3 , we conducted an ablation
study by replacing the edge-generation strategies in HeteroBA
with a random connection strategy, denoted as HeteroBA-R, to
evaluate the impact of the Cluster-based strategy (HeteroBA-C)
and the Attention-based strategy (HeteroBA-A). If HeteroBA-R
outperforms other methods, we mark it with â€ . The results in Table
3 show that HeteroBA-R consistently exhibits a significant drop inConference acronym â€™XX, June 03â€“05, 2018, Woodstock, NY Trovato et al.
(a) ACM Paper Attn. Dist.
 (b) DBLP Term Attn. Dist.
 (c) IMDB Director Attn. Dist.
(d) ACM Paper Clustering
 (e) DBLP Term Clustering
 (f) IMDB Movie Clustering
Figure 2: Attention distribution and Embedding Clustering
Attack Success Rate (ASR) across different datasets. For example, in
the ACM dataset with author as the trigger, HeteroBA-C achieves
an ASR of 1.0000 on HGT (class 2), while HeteroBA-R only reaches
0.7977. Similar trends are observed in DBLP and IMDB, indicating
that structured edge-generation strategies help improve ASR.
In terms of Clean Accuracy Drop (CAD), HeteroBA-R does not
show a significant advantage. Although CAD is slightly lower in
some cases (e.g., in the ACM dataset, HeteroBA-Râ€™s CAD on HAN
(class 1) is -0.0602, lower than HeteroBA-Câ€™s -0.0005), the difference
is minimal. This suggests that HeteroBA-C and HeteroBA-A can en-
hance ASR without significantly affecting clean data performance.
In summary, Cluster-based and Attention-based edge-generation
strategies are crucial for improving attack effectiveness. Random
edge selection reduces ASR and provides no significant benefit in
maintaining clean data accuracy.
(a) HeteroBA-A
 (b) HeteroBA-C
Figure 3: Comparison of attack success rates for HeteroBA-A
and HeteroBA-C under different poison rates.
5.2.4 Impact of Poison Rate on Attack Effectiveness. In this exper-
iment, we explore how the poison rate influences attack successrate (ASR) across three representative scenarios to answer the RQ4 ,
as depicted in the left figure (HeteroBA-A) and the right figure
(HeteroBA-C) of Fig. 3. When the poison rate is only 0.01, the ASR
is relatively low, but it increases markedly as the proportion of
poisoned samples in the training set grows. This trend mirrors the
phenomenon reported in [ 29], where a complex system undergoes
a sudden collapse at a specific critical point. Once the poison rate
exceeds that threshold, the backdoor attack success rate tends to
spike sharply, indicating heightened model vulnerability to the
backdoor trigger within that range.
Notably, in some cases, even a very small poison rate (e.g., 0.01)
can still yield a considerable level of attack effectiveness. This sug-
gests that when the backdoor trigger is well-aligned with the model
architecture or the underlying data distribution, only a modest
number of poisoned samples is required for the model to learn the
backdoor features and achieve a high ASR. These findings under-
score the insidious nature of backdoor attacks and highlight the
pressing need for robust defensive strategies.
5.2.5 Data visualization. In the Fig. 2, the â€œAttention Distributionâ€
panels show that the victim modelâ€™s attention scores are heavily
concentrated on a few influential auxiliary-type nodes within the
second-hop neighborhood, following a long-tailed pattern. These
nodes capture most of the attention weight, while the majority of
nodes contribute minimally. In the â€œEmbedding Clusterâ€ figures,
highlighted nodesâ€”top-ranked by average cosine similarityâ€”are
positioned near dense cluster centers, reflecting strong semantic or
structural similarity with neighboring nodes.
These patterns reveal that a small set of auxiliary-type nodes
plays a key role in propagating adversarial triggers. Their high
attention scores and central cluster positions make them effectiveHeteroBA: A Structure-Manipulating Backdoor Attack on Heterogeneous Graphs Conference acronym â€™XX, June 03â€“05, 2018, Woodstock, NY
conduits for influencing target node representations. This enables
more successful backdoor attacks, as triggers align with the graphâ€™s
inherent structure. These findings address RQ5 by showing that
these key nodes can efficiently transmit adversarial signals to target
nodes.
6 Conclusion and future work
In this paper, we introduce HeteroBA, the first backdoor attack
framework tailored for HGNNs in node classification. By injecting
trigger nodes and forming targeted connections with both primary
and auxiliary neighbors through two distinct strategies, HeteroBA
misleads the model into predicting a designated target class while
maintaining clean data performance. Extensive experiments on
benchmark datasets and various HGNN architectures reveal that
HeteroBA achieves high attack success rates with strong stealthi-
ness.
Future work will explore extending the attack to other tasks,
such as recommendation systems and graph classification, and
developing effective defense strategies against backdoor attacks on
heterogeneous graphs.
References
[1]Yang Chen, Zhonglin Ye, Haixing Zhao, and Ying Wang. 2023. Feature-Based
Graph Backdoor Attack in the Node Classification Task. International Journal of
Intelligent Systems 2023, 1 (2023), 5418398.
[2]Pengzhou Cheng, Zongru Wu, Wei Du, Haodong Zhao, Wei Lu, and Gongshen
Liu. 2023. Backdoor attacks and countermeasures in natural language processing
models: A comprehensive security review. arXiv preprint arXiv:2309.06055 (2023).
[3]Enyan Dai, Minhua Lin, Xiang Zhang, and Suhang Wang. 2023. Unnoticeable
backdoor attacks on graph neural networks. In Proceedings of the ACM Web
Conference 2023 . ACM, New York, NY, 2263â€“2273.
[4]Saman Forouzandeh, Mehrdad Rostami, Kamal Berahmand, and Razieh Sheikh-
pour. 2024. Health-aware food recommendation system with dual attention in
heterogeneous graphs. Computers in Biology and Medicine 169 (2024), 107882.
[5]Xinyu Fu, Jiani Zhang, Ziqiao Meng, and Irwin King. 2020. MAGNN: Metap-
ath aggregated graph neural network for heterogeneous graph embedding. In
Proceedings of the Web Conference 2020 . ACM, New York, NY, 2331â€“2341.
[6]Honglin Gao and Gaoxi Xiao. 2024. Top k enhanced reinforcement learning at-
tacks on heterogeneous graph node classification. arXiv preprint arXiv:2408.01964
(2024).
[7]Jun Hu, Bryan Hooi, and Bingsheng He. 2024. Efficient heterogeneous graph
learning via random projection. IEEE Transactions on Knowledge and Data Engi-
neering (2024).
[8]Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. 2020. Heterogeneous
graph transformer. In Proceedings of the Web Conference 2020 . ACM, New York,
NY, 2704â€“2710.
[9]Yiming Li. 2023. Poisoning-based backdoor attacks in computer vision. In
Proceedings of the AAAI Conference on Artificial Intelligence . Vol. 37. AAAI Press,
Menlo Park, CA, 16121â€“16122.
[10] Wenfei Liang, Yanan Zhao, Rui She, Yiming Li, and Wee Peng Tay. 2024. Fed-
SheafHN: Personalized Federated Learning on Graph-structured Data. arXiv
preprint arXiv:2405.16056 (2024).
[11] Yunfei Liu, Xingjun Ma, James Bailey, and Feng Lu. 2020. Reflection backdoor:
A natural backdoor attack on deep neural networks. In Computer Visionâ€“ECCV
2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings,
Part X 16 . Springer, 182â€“199.
[12] Yujia Liu, Kang Zeng, Haiyang Wang, Xin Song, and Bin Zhou. 2021. Content
matters: A GNN-based model combined with text semantics for social network
cascade prediction. In Pacific-Asia Conference on Knowledge Discovery and Data
Mining . Springer, 728â€“740.
[13] Qingsong Lv, Ming Ding, Qiang Liu, Yuxiang Chen, Wenzheng Feng, Siming
He, Chang Zhou, Jianguo Jiang, Yuxiao Dong, and Jie Tang. 2021. Are we really
making much progress? Revisiting, benchmarking and refining heterogeneous
graph neural networks. In Proceedings of the 27th ACM SIGKDD Conference on
Knowledge Discovery & Data Mining . ACM, New York, NY, 1150â€“1160.
[14] Giulia Muzio, Leslie Oâ€™Bray, and Karsten Borgwardt. 2021. Biological network
analysis with deep learning. Briefings in Bioinformatics 22, 2 (2021), 1515â€“1530.
[15] Trung-Kien Nguyen, Zemin Liu, and Yuan Fang. 2023. Link prediction on latent
heterogeneous graphs. In Proceedings of the ACM Web Conference 2023 . ACM,New York, NY, 263â€“273.
[16] Amirreza Salamat, Xiao Luo, and Ali Jafari. 2021. HeteroGraphRec: A hetero-
geneous graph-based neural networks for social recommendations. Knowledge-
Based Systems 217 (2021), 106817.
[17] Xuan Sheng, Zhaoyang Han, Piji Li, and Xiangmao Chang. 2022. A survey on
backdoor attack and defense in natural language processing. In 2022 IEEE 22nd
International Conference on Software Quality, Reliability and Security (QRS) . IEEE,
809â€“820.
[18] George R Terrell and David W Scott. 1992. Variable kernel density estimation.
The Annals of Statistics (1992), 1236â€“1265.
[19] Jianfei Wang, Cuiqing Jiang, Lina Zhou, and Zhao Wang. 2024. Representing and
discovering heterogeneous interactions for financial risk assessment of SMEs.
Expert Systems with Applications 247 (2024), 123330.
[20] Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S
Yu. 2019. Heterogeneous graph attention network. In The World Wide Web
Conference . ACM, New York, NY, 2022â€“2032.
[21] Bin Wu, Kuo-Ming Chao, and Yinsheng Li. 2024. Heterogeneous graph neural
networks for fraud detection and explanation in supply chain finance. Information
Systems 121 (2024), 102335.
[22] Zhaohan Xi, Ren Pang, Shouling Ji, and Ting Wang. 2021. Graph backdoor. In
30th USENIX Security Symposium (USENIX Security 21) . 1523â€“1540.
[23] Zhaohan Xi, Ren Pang, Shouling Ji, and Ting Wang. 2021. Graph backdoor. In
30th USENIX Security Symposium (USENIX Security 21) . 1523â€“1540.
[24] Sheng Xiang, Dawei Cheng, Chencheng Shang, Ying Zhang, and Yuqi Liang.
2022. Temporal and heterogeneous graph neural network for financial time
series prediction. In Proceedings of the 31st ACM international conference on
information & knowledge management . ACM, New York, NY, 3584â€“3593.
[25] Xiaogang Xing, Ming Xu, Yujing Bai, and Dongdong Yang. 2024. A clean-label
graph backdoor attack method in node classification task. Knowledge-Based
Systems 304 (2024), 112433.
[26] Siyong Xu, Cheng Yang, Chuan Shi, Yuan Fang, Yuxin Guo, Tianchi Yang, Luhao
Zhang, and Maodi Hu. 2021. Topic-aware heterogeneous graph neural network
for link prediction. In Proceedings of the 30th ACM international conference on
information & knowledge management . ACM, New York, NY, 2261â€“2270.
[27] Bo Yan, Yang Cao, Haoyu Wang, Wenchuan Yang, Junping Du, and Chuan Shi.
2024. Federated heterogeneous graph neural network for privacy-preserving
recommendation. In Proceedings of the ACM on Web Conference 2024 . ACM, New
York, NY, 3919â€“3929.
[28] Zi Ye, Yogan Jaya Kumar, Goh Ong Sing, Fengyan Song, and Junsong Wang. 2022.
A comprehensive survey of graph neural networks for knowledge graphs. IEEE
Access 10 (2022), 75729â€“75741.
[29] Yi Yu, Gaoxi Xiao, Jie Zhou, Yubo Wang, Zhen Wang, JÃ¼rgen Kurths, and
Hans Joachim Schellnhuber. 2016. System crash as dynamics of complex networks.
Proceedings of the National Academy of Sciences 113, 42 (2016), 11726â€“11731.
[30] Xi Zeng, Fang-Yuan Lei, Chang-Dong Wang, and Qing-Yun Dai. 2024. Multi-view
Heterogeneous Graph Neural Networks for Node Classification. Data Science
and Engineering 9, 3 (2024), 294â€“308.
[31] Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, and Nitesh V
Chawla. 2019. Heterogeneous graph neural network. In Proceedings of the 25th
ACM SIGKDD international conference on knowledge discovery & data mining .
ACM, New York, NY, 793â€“803.
[32] Mengmei Zhang, Xiao Wang, Meiqi Zhu, Chuan Shi, Zhiqiang Zhang, and Jun
Zhou. 2022. Robust heterogeneous graph neural networks against adversarial
attacks. In Proceedings of the AAAI Conference on Artificial Intelligence . Vol. 36.
AAAI Press, Menlo Park, CA, 4363â€“4370.
[33] Mengmei Zhang, Xiao Wang, Meiqi Zhu, Chuan Shi, Zhiqiang Zhang, and Jun
Zhou. 2022. Robust heterogeneous graph neural networks against adversarial
attacks. In Proceedings of the AAAI Conference on Artificial Intelligence . Vol. 36.
AAAI Press, Menlo Park, CA, 4363â€“4370.
[34] Zaixi Zhang, Jinyuan Jia, Binghui Wang, and Neil Zhenqiang Gong. 2021. Back-
door attacks to graph neural networks. In Proceedings of the 26th ACM Symposium
on Access Control Models and Technologies . ACM, New York, NY, 15â€“26.
[35] He Zhao, Zhiwei Zeng, Yongwei Wang, Deheng Ye, and Chunyan Miao. 2024.
HGAttack: Transferable Heterogeneous Graph Adversarial Attack. arXiv preprint
arXiv:2401.09945 (2024).
[36] Yanan Zhao, Xingchao Jian, Feng Ji, Wee Peng Tay, and Antonio Ortega. 2024.
Generalized Graph Signal Reconstruction via the Uncertainty Principle. arXiv
preprint arXiv:2409.04229 (2024).
[37] Shichao Zhu, Chuan Zhou, Shirui Pan, Xingquan Zhu, and Bin Wang. 2019.
Relation structure-aware heterogeneous graph neural network. In 2019 IEEE
International Conference on Data Mining (ICDM) . IEEE, 1534â€“1539.
[38] Zhihua Zhu, Xinxin Fan, Xiaokai Chu, and Jingping Bi. 2020. HGCN: A heteroge-
neous graph convolutional network-based deep learning model toward collective
classification. In Proceedings of the 26th ACM SIGKDD International Conference
on Knowledge Discovery & Data Mining . ACM, New York, NY, 1161â€“1171.Conference acronym â€™XX, June 03â€“05, 2018, Woodstock, NY Trovato et al.
Table 5: Remaining attack results.
Dataset Victim Model Class TriggerASR CAD
HeteroBA-C HeteroBA-A HeteroBA-R CGBA UGBA HeteroBA-C HeteroBA-A HeteroBA-R CGBA UGBA
ACMHAN0
field0.3167 0.7612 0.9021 0.9420 0.0697 -0.0072 0.0508âˆ’0.0419â€ 0.0160 0.0122
1 0.6667 0.6716 0.7960â€ 0.5970 0.1178 0.0066 0.0513âˆ’0.0171â€ 0.1109 0.0187
2 0.0829 1.0000 0.9967 0.8126 0.0398 0.0006 0.1424 -0.0215 -0.0375 0.0000
HGT0
field0.7164 0.4859 0.6020 0.9436 0.9867 -0.0105 - 0.0105 0.0016 -0.0022 -0.0038
1 0.7861 0.8060 0.6733 0.8905 0.9851 0.0055 -0.0011 -0.0028 0.0122 -0.0061
2 0.6020 0.7131 0.8275 0.9005 0.9469 0.0039 0.0033 0.0055 0.0083 0.0006
SimpleHGN0
field0.9718 1.0000 0.9983 0.9602 1.0000 0.0094 0.0160 -0.0022 -0.0022 -0.0660
1 0.9735 1.0000 0.9884 0.9303 1.0000 -0.0061 -0.0022 0.0033 0.0000 -0.0182
2 0.9685 1.0000 1.0000 0.9038 1.0000 0.0033 0.0066 0.0066 0.0033 -0.0701
IMDBHAN0
actor0.2866 0.6854 0.5358 0.5618 0.2087 0.0208 0.0016 0.0099 0.0037 0.0364
1 0.9751 0.7212 0.5545 0.4523 0.2991 -0.0187 -0.0187 -0.0041 -0.0119 0.0047
2 0.8178 0.8910 0.5997 0.4992 0.3832 -0.0031 -0.0073 0.0088 0.0010 0.0114
HGT0
actor0.6511 0.8006 0.6230 0.4851 0.5109 0.0140 0.0026 0.0052 -0.0104 0.0291
1 0.8022 0.8240 0.7227 0.4147 0.7757 0.0145 0.0244 âˆ’0.0078â€ 0.0130 0.0026
2 0.7290 0.8286 0.6075 0.4523 0.6807 0.0109 0.0145 0.0036 -0.0015 0.0182
SimpleHGN0
actor0.8660 0.9829 0.7492 0.3881 0.8427 -0.0005 -0.0047 0.0052 -0.0244 -0.0016
1 0.9346 0.8614 0.9455â€ 0.3850 0.9611 0.0015 -0.0062 0.0146 -0.0130 0.0322
2 0.8988 0.9408 0.8084 0.3474 0.9330 0.0047 -0.0057 -0.0031 0.0156 0.0047
A Time complexity analysis
The time complexity of the algorithm is primarily determined by
the graph size, the number of target nodes for trigger insertion, and
the selection strategy of auxiliary nodes. Let ğ‘›=|V|denote the
total number of nodes in the graph, and ğ‘š=|E|the total number
of edges. DefineVğ‘¡ğ‘as the set of nodes of type ğ‘¡ğ‘, with a size of ğ‘›ğ‘¡ğ‘.
The set of target nodes for trigger insertion is denoted as V(ğ‘)âŠ†
Vğ‘¡ğ‘, with sizeğ‘=|V(ğ‘)|. Additionally, letVaux=Ã
ğ‘¡ğ‘âˆˆTauxVğ‘¡ğ‘
be the set of auxiliary type nodes, with size ğ‘›aux.
The algorithm first filters out nodes of the target type that do
not match a specific label and identifies relevant nodes in their
neighborhood. A single-hop neighbor search typically has a com-
plexity of at most ğ‘‚(ğ‘š), depending on the adjacency structure. If
multi-hop neighborhoods are considered, this step can be viewed as
a breadth-first search (BFS) on the relevant subgraph, with an upper
bound ofğ‘‚(ğ‘›+ğ‘š). Following this, the average degree information
for different types of nodes is computed, which involves scanning
specific sets of nodes or edges. Without index optimization, this
step also has a complexity of ğ‘‚(ğ‘›+ğ‘š).
During the trigger insertion process, each target node is assigned
a new trigger node, and its feature values are sampled accordingly.
If the features are discrete, a simple Bernoulli sampling method is
applied, which has a complexity of ğ‘‚(1). For continuous features
using kernel density estimation (KDE), the complexity depends
on whether the KDE model is pre-trained. If a pre-trained model
is available, the complexity per sample is ğ‘‚(1)orğ‘‚(logğ‘›). The
newly inserted trigger node must be connected to the target node
and auxiliary nodes. To ensure proper connectivity, auxiliary nodes
are selected using an attention-based or clustering-based sorting
mechanism. If sorting is applied, the complexity can be as high as
ğ‘‚(ğ‘›auxlogğ‘›aux). If clustering is used, the complexity depends on
the specific clustering algorithm, but in most cases, it remains close
toğ‘‚(ğ‘›auxlogğ‘›aux). Since this process is executed for each target
node, the cumulative complexity becomes ğ‘‚(ğ‘Â·ğ‘›auxlogğ‘›aux). After
selecting the auxiliary node set, adding the corresponding edges
incurs a linear complexity with respect to the number of selected
nodes. If the maximum number of connections per node is bounded
byğ·, this step has a complexity of ğ‘‚(ğ·).Algorithm 1 HeteroBA Overall Algorithm
1:Input:ğº=(V,E,ğ‘‹),ğ‘¡ğ‘,ğ‘¡ğ‘¡ğ‘Ÿ,Taux,ğ‘¦ğ‘¡,V(ğ‘)âŠ†Vğ‘¡ğ‘
2:Output: eğº=(fV,eE,eğ‘‹)
3:IdentifyVÂ¬ğ‘¦ğ‘¡â†{ğ‘£âˆˆVğ‘¡ğ‘|ğ‘¦ğ‘£â‰ ğ‘¦ğ‘¡}
4:Vâ€²
ğ‘¡ğ‘¡ğ‘Ÿâ†Neigh(VÂ¬ğ‘¦ğ‘¡,ğ‘Ÿğ‘¡ğ‘,ğ‘¡ğ‘¡ğ‘Ÿ)
5:Compute average degrees {ğ‘‘ğ‘¡ğ‘}for edges(ğ‘¡ğ‘¡ğ‘Ÿ,ğ‘¡ğ‘),âˆ€ğ‘¡ğ‘âˆˆTaux
6:E(new)â†âˆ…, ğ‘‹(new)â†âˆ…
7:foreachğ‘£âˆˆV(ğ‘)do
8: Insert a new trigger node ğ‘¢
9: iffeature is continuous: sample ğ‘¥(new)
ğ‘¢ via KDE
10: else (binary): sample ğ‘¥(new)
ğ‘¢ via Bernoulli
11:E(new)â†E(new)âˆª{(ğ‘¢,ğ‘£),(ğ‘£,ğ‘¢)}
12: Letğ‘Šâ†{top-ğ‘‘ğ‘¡ğ‘in eachVaux(via attention/clustering) }
13:E(new)â†E(new)âˆª{(ğ‘¢,ğ‘¤),(ğ‘¤,ğ‘¢) |ğ‘¤âˆˆğ‘Š}
14:ğ‘‹(new)â†ğ‘‹(new)âˆª{ğ‘¥(new)
ğ‘¢}
15:end for
16:fVâ†Vâˆª{ all newğ‘¢}
17:eEâ†EâˆªE(new)
18:eğ‘‹â†"
ğ‘‹
ğ‘‹(new)#
19:return eğº=(fV,eE,eğ‘‹)
Once all trigger nodes have been constructed, they must be
merged into the original graph, including updating the node set,
edge set, and feature matrix. The number of newly added nodes is ğ‘,
and the number of new edges is typically at most ğ‘‚(ğ‘ğ·), leading to
a complexity of ğ‘‚(ğ‘)orğ‘‚(ğ‘ğ·). Overall, the total time complexity
of the algorithm is given by:
ğ‘‚(ğ‘›+ğ‘š)+ğ‘‚ ğ‘Â·ğ‘›auxlogğ‘›aux.
B Other training parameters
The training parameters are shown in Table 6.
C Other attack results
The remaining attack results are presented in Table 5.
D Pseudocode of HeteroBA
The pseudocode of HeteroBA is in Algorithm 1HeteroBA: A Structure-Manipulating Backdoor Attack on Heterogeneous Graphs Conference acronym â€™XX, June 03â€“05, 2018, Woodstock, NY
Table 6: Training Parameters and Model-Specific Hyperpa-
rameters
Key Training Parameters
Parameter Value
Loss function Cross Entropy
Optimizer AdamW
Epochs 400
Learning rate 1e-3
Scheduler OneCycleLR
Dropout 0.2
Weight decay 1e-4
Gradient Clipping 1.0
Model-Specific Hyperparameters
Model Hyperparameters (Value)
HGT Hidden Units: 64; Layers: 8; Heads: 4
HAN Hidden Units: 64; Heads: 4
SimpleHGN Hidden Units: 64; Heads: 8; Layers: 4;Received 20 February 2007; revised 12 March 2009; accepted 5 June 2009