A domain adaptation neural network for digital
twin-supported fault diagnosis
Zhenling Chen
CentraleSupélec,
Université Paris-Saclay,
Gif-sur-Yvette, 91190, FranceHaiwei Fu
CentraleSupélec,
Université Paris-Saclay,
Gif-sur-Yvette, 91190, France
Zhiguo Zeng
Chair on Risk and Resilience of Complex Systems,
Laboratoie Genie Industriel, CentraleSupélec,
Université Paris-Saclay, 91190, Gif-sur-Yvette, France
Abstract —Digital twins offer a promising solution to the lack
of sufficient labeled data in deep learning-based fault diagnosis
by generating simulated data for model training. However,
discrepancies between simulation and real-world systems can
lead to a significant drop in performance when models are
applied in real scenarios. To address this issue, we propose a
fault diagnosis framework based on Domain-Adversarial Neu-
ral Networks (DANN), which enables knowledge transfer from
simulated (source domain) to real-world (target domain) data.
We evaluate the proposed framework using a publicly available
robotics fault diagnosis dataset, which includes 3,600 sequences
generated by a digital twin model and 90 real sequences collected
from physical systems. The DANN method is compared with
commonly used lightweight deep learning models such as CNN,
TCN, Transformer, and LSTM. Experimental results show that
incorporating domain adaptation significantly improves the diag-
nostic performance. For example, applying DANN to a baseline
CNN model improves its accuracy from 70.00% to 80.22% on
real-world test data, demonstrating the effectiveness of domain
adaptation in bridging the sim-to-real gap.1
Index Terms —predictive maintenance, fault diagnosis, digital
failure twin, domain adaptation neural network (DANN)
I. I NTRODUCTION
Fault diagnosis aims at identifying the cause of a failure
from observational data from sensors [1]. One of the major
challenge in fault diagnosis is that the state-of-the-art deep
learning-based models often require large amount of data. It
is, however, often difficult to obtain these data in practice
[2]. Digital twin technology combines physical entity with its
digital representation. It can accurately reproduce the scenes
in the physical world in the virtual environment, providing
great convenience for the analysis, optimization and control
of physical system [3]. Using digital twins to generate sim-
ulated failure data and train a deep learning model for fault
diagnosis has become a promising approach to solve the data
insufficiency issue of fault diagnosis.
There are already some existing works in applying dig-
ital twins for fault diagnosis. For example, Jain et al. [4]
proposed a digital twin-based fault diagnosis framework that
1Code and datasets available at: https://github.com/JialingRichard/Digital-
Twin-Fault-Diagnosisutilizes the digital twin model to simulate system behavior
and identify fault patterns in distributed photovoltaic systems,
Wang et al. [5] proposed a digital twin-based fault diagnosis
framework that integrates sensor data and physical models
to detect and diagnose faults in rotating machinery within
smart manufacturing systems. Yang et al.[6] proposed a digital
twin-driven fault diagnosis method that combines virtual and
real data to diagnose composite faults, where the digital twin
generates virtual samples to compensate for the scarcity of
fault samples in real systems. Most of these existing works
assume that condition-monitoring data are availalbe on the
same level as the component being diagnosed. In practice,
however, deploying sensors at the component level is often
difficult. One has to rely on system-level condition-monitoring
data to infer the component-level failure modes [7]. In one of
our previous works [8], we developed a digital twin model
of a robot and use it to generate simulated failure data for
fault diagnosis. Testing data are collected from a real robot
with different injected failures to test the performance of the
developed model.
The existing works share a common assumption: The digital
twin model can accurately predict the actual behavior of the
component under test. However, in practice, the digital twin
model is not always accurate. Then, the fault diagnosis model
trained on simulation data often suffers from poor performance
when applied to real data, due to the imprecision of the
simulation model. To address this issue, we propose a Domain
Adversarial Neural Network (DANN)-based framework for
digital twin-supported fault diagnosis. Through the DANN
[9], the developed model is able to learn useful features
from the simulated data even the simulation does not exactly
match the reality. We also performed a benchmark study
by comparing the performance of the developed model with
other state-of-the-art deep learning models, including LSTM
[10], Transformer [11], CNN [12] and TCN [13]. The main
contributions of this paper are:
•We propose a novel DANN-based framework for digital
twin-supported fault diagnosis.arXiv:2505.21046v1  [cs.LG]  27 May 2025•We present an open-source dataset for digital twin-
supported fault diagnosis. The dataset include simulated
training data and real test data.
•We conducted a detailed benchmark study where the
performance of the developed model is compared with
four other state-of-the-art deep learning models.
II. D IGITAL TWIN MODEL AND DATASET DESCRIPTION
In this paper, we consider the open source dataset for digital
twin-supported fault diagnosis we developed previously in [8].
The dataset is created based on the digital failure twin model
of a robot, as shown in Fig. 1.
Fig. 1: The fault diagnosis in digital twin for robot [8].
A digital twin model is a simulation model used to simulate
the failure behavior of the robot and connect to the physical
entity to reflect its real-time states. The robot comprises of
six motors. We monitor the trajectory of the end-effector and
the control commands of each motor. The goal of the fault
diagnosis is to use the condition-monitoring data to infer the
failure modes of the four out of the six motors. Each motor
might subject to two failure modes, i.e., stuck and steady-state
error.
The digital failure twin model is built as a two-layer model.
On the motor level, we model the dynamics of the motor
and its controller. Then, the response of each motor is fed
into a forward kinematics model, which allows simulating the
end-effector trajectory from the postions of the motors. The
stuck and steady-state error can be simulated by changing the
response of each motor, as shown in Fig. 1.
To generate the training dataset, we generate 400 random
trajectories, and simulate the 9classes (one normal state and
eight failure states where each motor could be in either one
of the two failure modes) under each trajectory. Each sample
contains records spanning 1000 time steps. Then, we collect
test data by randomly simulate 90 trajectories following the
same protocals.
In the original work [8], an LSTM was trained on the
simulation dataset and applied to dignose the failures on the
real robot. The results showed that, although the trained model
performed well on the validation set (seperated from training
data, but still from simulation), it performs poorly on the real
testing dataset ( 96% V .S.69%). The main reason is that the
simulation model does not match exactly the behavior of thereal robot. In this paper, we intend to address this issue through
transfer learning.
III. E XISTING TRANSFER LEARNING MODELS
Prevalent deep learning-based models show great success in
both academia and industry [14]. For example, Convolutional
Neural Networks (CNN) use in automated fault detection for
machinery vibrations [15], Recurrent Neural Networks (RNN)
for example, LSTM have proven useful in diagnosing faults
based on time series data [16]. In current work, Plakias et
al. combined the dense convolutional blocks and the attention
mechanism to develop a new attentive dense CNN for fault
diagnosis [17]. Although these methods can achieve high per-
formance in fault diagnosis, the application of these methods
is usually under the assumption that test data and train data
come from the same data distribution. Also, the current deep
learning-based models are under the Independent Identically
Distribution (i.i.d.).
As we discussed before, the data generated from a digital
twin might not exactly match the actual behavior in the
physical entity. As a result, the distribution of training and
testing dataset cannot be assumed as i.d.d., due to steady-state
errors that cause in friction or other mechanical effects and real
time faults that can big impact the results. In this paper, we
use transfer learning methods to deal with source domain and
target domain alignment in digital twin in data distribution.
To solve the issue of data distribution discrepancy, various
domain adaptation techniques in transfer learning have been
introduced for diagnosing bearing faults [18–20]. Transfer
learning can also be used to learn knowledge from source
domain for fault diagnosis on a different target domain.
Applications of transfer learning in fault diagnosis include
representation adaptation [21–24], parameter transfer [25–27],
adversarial-based domain adaptation [28, 29].
One of the most often used domain adaptation methods is
representation adaptation which to align the distribution of the
representations from the source domain and target domain by
reducing the distribution discrepancy. Some neural networks
are build for this, such as feature-based transfer neural network
(FTNN) [24], deep convolutional transfer learning network
(DCTLN) [21]. Shao et al. proposed a CNN-based machine
fault diagnosis framework in parameter transfer [27], and
experimental results show that DCTLN can get the average
accuracy of 86.3%. Experimental results illustrate that the
proposed method can achieve the test accuracy near 100%
on three mechanical datasets, and in the gearbox dataset, the
accuracy can reach 99.64%.
In adversarial-based domain adaptation, Cheng et al. pro-
posed Wasserstein distance based deep transfer learning (WD-
DTL) [28] which uses CNN as pre-trained model. Experimen-
tal results show that the transfer accuracy of WD-DTL can
reach 95.75% on average. Lu et al. develop a domain adapta-
tion combined with deep convolutional generative adversarial
network (DADCGAN)-based methodology for diagnosing DC
arc faults [29]. DADCGAN is a robust and reliable faultdiagnosis scheme based on a lightweight CNN-based classifier
can be achieved for the target domain.
In this paper, we choose the DANN architecture to de-
velop a framework of digital twin-supported fault diagnosis.
The main reason is that its architecture is simple and can
efficiently capture the features from the source domain and
generalize well on the target domain. Moreover, DANN’s
adversarial training mechanism enables the model to learn
domain-invariant features, making it particularly effective in
reducing the distribution discrepancy between source and tar-
get domains. Furthermore, DANN performs well with limited
labeled data from the target domain, addressing the common
challenge of insufficient fault data in practical applications. Its
ability to handle complex and nonlinear relationships in data
and make DANN a reliable and scalable solution for fault
diagnosis.
IV. DANN M ODEL ARCHITECTURE
We use Domain Adversarial Neural Network (DANN)
model [9] and extend its application in digital twin in robotics
maintenance prediction that previously and originally utilize
in transfer learning in domain adaptation. The architecture of
DANN is shown in Figure 2.
Let us assume the input samples are represented by x∈X,
where Xis some input space and certain labels (output) yfrom
the label space Y. We assume that there exist two distributions
S(x, y)andT(x, y)onX⊗Y, which will be referred to as the
source domain and the target domain. Our goal is to predict
labels ygiven the input xfor the target domain.
We denote with dithe binary variable (domain label) for
theith example, which indicates whether xicome from
the source domain ( xi∼S(x) if di=0) or from the target
distribution ( xi∼T(x) if di=1). We assume that the input x
is first representative by a representation learning Gf(Feature
Extractor) to a d-dimensional feature vector f ∈Rd, and we
denote the vector of parameters of all layers in this mapping as
θf,f=Gf(x;θf). Then, the feature vector fis representative
byGy(label predictor) to the label y, and we denote the
parameters of this learning with θy. Finally, the same feature
vector fis representative to the domain label dby a mapping
Gd(domain classifier) with the parameters θd.
For the model learning, we minimize the label prediction
loss on the annotated part (i.e. the source part) of the train
set, also the parameters of both the feature extractor and
the label predictor are optimized in order to minimize the
empirical loss for the source domain samples. This ensures
the discriminativeness of the features fand the overall good
prediction performance of the combination of the feature
extractor and the label predictor on the source domain. By
doing so, we make the features fdomain-invariant.
We need to make the distributions S(f)=Gf(x;θf)|
x∼S(x) and T(f)=Gf(x;θf)| x∼T(x) to be similar [30].
To Measure the dissimilarity of the distributions S(f)and
T(f), the distributions are constantly changing in learning
progresses, we estimate the dissimilarity is to look at the
loss of the domain classifier Gd, provided that the parametersθdof the domain classifier have been trained to discriminate
between the two feature distributions. In training to obtain
domain-invariant features, we seek the parameters θfof the
feature representative that maximize the loss of the domain
classifier (by making the two feature distributions as similar
as possible), and simultaneously seeking the parameters θdof
the domain classifier that minimize the loss of the domain
classifier. And we seek to minimize the loss of the label
predictor. The function is:
E(θf, θy, θd) =X
i=1..NLy(Gy(Gf(xi;θf);θy), yi)−
λX
i=1..NLd(Gd(Gf(xi;θf);θd), yi)
=X
i=1..NLi
y(θf, θy)−λX
i=1..NLi
d(θf, θd)(1)
where Lyis the loss for label prediction, Ldis the loss for
the domain classification, and Li
y,Li
ddenote the corresponding
loss functions evaluated at the i training example.
We seek the the parameters ˆθf,ˆθy,ˆθdby solving the
following optimization problem:
(ˆθf,ˆθy) =argmin
θf,θyE(θf, θy,ˆθd)
ˆθd=argmax
θdE(ˆθf,ˆθy, θd)(2)
Then, we do optimization in backpropagation to seek the
parameters ˆθf,ˆθy,ˆθdat the end progressing of class classifier
and domain classifier. We also do a gradient reversal layer
(GRL) to update and diferences the −λfacotor in (1). The
backpropagation processing passes through the GRL, by the
partial derivatives of the loss that is downstream the GRL (i.e.
Ld) w.r.t. the layer parameters that are upstream the GRL (i.e.
θf) get multiplied by −λ(i.e.∂Ld
∂θfis effectively replaced with
−λ∂Ld
∂θf). We have forward and backward function Rλ(x):
Rλ(x) =x (3)
dRλ
dx=−λI (4)
where I is the identity matrix.
In feature extractor, we use CNN to do feature extracting,
based on our baseline, CNN model has a better results, so
we use CNN architecture and its representation to do feature
extracting. The CNN is in two convolutional layers, and we
set kernel size is 3, number of filters is 64.
V. E XPERIMENTS
A. Dataset
In this case study, we work on the dataset originally reported
in [8]. As [8], we retained the desired and realized trajectory
coordinates (x, y, z) and introduced a derived feature set
representing the residuals between the desired and realized
trajectories. As a result, the final feature set comprises six
features: the desired trajectory coordinates (x, y, z) and the
corresponding residuals (x, y, z).Fig. 2: DANN Architecture [9]
The source domain dataset generated by the digital twin
consists of 3600 samples across 9 distinct labels, with each
label containing 400 samples. The real-world measurements
are treated as target domain. We have 90 samples in the target
domain. We split the source domain dataset into training and
validation sets with a 9to1ratio, and the target domain dataset
is used as the test set.
The DANN described in Sect. IV is used to train a fault
diagnosis model using the source domain data. Only the
measured features in the target domain, but not the labels
are used in the training process of the DANN to learn the
domain invariate features. Then, the trained DANN is applied
to predict the failure labels of the target domain.
B. Evaluation Metrics
The performance of all methods is evaluated using Accu-
racy andF1 Score , which are defined as follows:
a) Accuracy:
Accuracy =Number of Correct Predictions
Total Number of Predictions
=TP+TN
TP+TN+FP+FN(5)
where TP,TN,FP, and FN represent the number of true
positives, true negatives, false positives, and false negatives,
respectively.
b) F1 Score: The F1 Score is the harmonic mean of
precision and recall:
F1 Score = 2·Precision ·Recall
Precision +Recall(6)where:
Precision =TP
TP+FP,Recall =TP
TP+FN(7)
These metrics provide a balanced evaluation of the model’s
performance.
C. Benchmarked models
We use four current prevalent deep learning methods and
models as baseline:
•LSTM [10] Long Short-Term Memory (LSTM) deals
with time series data in deep learning, it often uses for
preventing gradient vanishing and gradient explosion in
deep learning. LSTM is a special type of recurrent neural
network (RNN), and can effectively capture and process
long-term dependencies in sequence data by introducing
memory units and gating mechanisms.
•Transformer [11] Transformer is better at context depen-
dency. And it is very versatile especially in multimodal.
This ability to dynamically focus on relevant parts of the
input is a key reason why Transformer model excel when
processing sequence data.
•CNN [12] Convolutional Neural Networks (CNN) is
mainly used as a visual neural network, which mainly
extracts features layer by layer through multiple and deep
convolution.
•TCN [13] It is a deep learning model specifically de-
signed to process sequential data, combining the parallel
processing capabilities of convolutional neural networks(CNN) with the long-term dependent modeling capabili-
ties of recurrent neural networks (RNN).
D. Implementation Details
The implementation of the DANN is carried out using
PyTorch. The experiments are conducted on NVIDIA RTX
3060 GPU with the following parameter settings: Learning
rate is 0.001, Batch size is 32, Number of epochs is 250,
Optimizer is Adam, and Alpha:
α=2
1 +e−10p−1 (8)
where
p=epoch
max epoch(9)
VI. R ESULTS AND DISCUSSIONS
A. Average accuracy and F1 score over all methods
In this subsection, we systematically compare the results
from the DANN with the four benchmarked models. We
conduct experiments to evaluate the accuracy of the models
on the train set, validation set, and real test set, as shown in
table I. Additionally, we record the F1-score for each one of
the nine classes, as shown in table II. Due to the randomness
of deep learning models, each experiment is conducted five
times, and both the average values and standard deviations of
the performance metrics are calculated.
From Table I, it can be seen that the four benchmarked
deep learning models do not perform well, especially on the
test set. The performance on the test set drops significantly
compared to the training set and validation set. This can be
explained by the imprecision of the simulation model used to
generate the training data. The DANN, on the other hand,
achieve much better performance on the test set. This is
because through domain adaptation, the DANN is able to
extract domain invariate features and generalize them to the
target domain.
It is observed from Table II that most of the benchmarked
models exhibit very low classification accuracy for the state
healthy. This is because, healthy state is very similar to
other states where one motor has steady-state errors. When
the simulation model is not accurate, the generated training
data are even more difficult to distinguish between healthy
and steady-state error states. The DANN, on the other hand,
performs well in classifying the state of healthy. This is
because after the domain adaptation, in the extracted feature
space, the healthy state becomes well-seperated with the other
states.
In summary, among the commonly used deep learning
models in our experiments, the model that combines a deeper
and wider CNN as the backbone with the DANN structure is
the relatively optimal choice.B. Ablation study for Digital Twin
To demonstrate the necessity of using a digital twin model
for this task, we conduct an ablation experiment. We train
the model using only the real test set, excluding the train and
validation sets generated entirely by the digital twin model.
In the real test data, we split the dataset into train and testing
sets at a ratio of 7:3. Our dataset contains only 90 real data
points, and it is clear that most deep learning models struggle
to fit on such a small dataset. The results we recorded in
Table III, which indicate that, with such a limited amount
of data, common methods cannot make accurate predictions.
Use digital twin model to generate simulation data, on the
other hand, clearly improve the performance, as the generated
simulation data help the deep learning model to better learn
the relevant features.
VII. C ONCLUSIONS AND FUTURE WORKS
In this paper, we proposed a new deep learning baseline
for fault diagnosis using an existing digital twin dataset. We
applied commonly used lightweight deep learning models
and demonstrated that the Domain-Adversarial Neural Net-
work (DANN) approach with a CNN backbone, as a transfer
learning method, achieves higher accuracy compared to other
models. Furthermore, our experiments validate that combining
digital twin simulation with domain adaptation techniques can
effectively address the issue of limited real-world data in fault
diagnosis tasks.
We selected lightweight models such as CNN, TCN, Trans-
former, and LSTM due to their wide adoption in time-series
fault diagnosis, ease of training, and relatively low computa-
tional cost. Although these models serve as strong baselines,
we acknowledge that more advanced architectures—such as
pre-trained large-scale models or graph-based neural net-
works—may offer improved generalization and performance.
Exploring these alternatives remains a promising direction for
future research.
However, several limitations remain. First, the DANN
framework requires more computational resources and deep
learning expertise, which may pose challenges for practical
deployment, particularly in resource-constrained industrial set-
tings. Second, the inevitable discrepancies between the digital
twin and the real-world system limit the performance of the
model, as current simulations cannot fully capture complex
physical dynamics. Third, while DANN improves generaliza-
tion, the deep learning models used in this study still have
room for improvement. Future work could explore more robust
and generalizable models, such as those pre-trained on large-
scale datasets or more advanced domain adaptation methods.
ACKNOWLEDGMENT
The research of Zhiguo Zeng is supported by ANR-22-
CE10-0004, and chair of Risk and Resilience of Complex
Systems (Chaire EDF, Orange and SNCF). Haiwei Fu and
Zhenling Chen participate in this project as lab project in their
master curricum in Centralesupélec. The authors would like to
thank Dr. Myriam Tami for managing this project.TABLE I: Performance Comparison of Baseline Models
Model Training Accuracy (%) Validation Accuracy (%) Test Accuracy (%)
LSTM 96.06±5.57 92.22±4.60 56.00±4.59
Transformer 97.73±0.33 75.94±1.52 48.44±2.29
TCN 87.96±0.86 67.67±0.65 44.22±1.63
CNN 99.94±0.11 96.78±0.76 70.00±1.99
DANN 99.29±0.67 95.28±0.72 80.22±1.78
TABLE II: Performance Comparison on Each Category (F1 Score)
LSTM Transformer TCN CNN DANN
Healthy 0.00±0.00 0.00±0.00 0.07±0.09 0.07±0.09 0.67±0.04
Motor 1 Stuck 0.86±0.06 0.63±0.05 0.65±0.04 0.81±0.03 0.84±0.04
Motor 1 Steady state error 0.55±0.14 0.67±0.09 0.46±0.04 0.85±0.03 0.90±0.05
Motor 2 Stuck 0.72±0.05 0.65±0.14 0.36±0.03 0.73±0.07 0.79±0.04
Motor 2 Steady state error 0.53±0.16 0.40±0.05 0.46±0.08 0.90±0.05 0.87±0.02
Motor 3 Stuck 0.55±0.05 0.54±0.08 0.48±0.05 0.63±0.09 0.80±0.03
Motor 3 Steady state error 0.63±0.11 0.38±0.10 0.62±0.10 0.91±0.03 0.91±0.06
Motor 4 Stuck 0.49±0.06 0.42±0.08 0.40±0.07 0.59±0.06 0.78±0.04
Motor 4 Steady state error 0.43±0.05 0.41±0.07 0.28±0.02 0.53±0.02 0.62±0.08
TABLE III: Performance Ablation Study
Model Only Real Data Accuracy (%) Digital twin-supported deep learning (%)
LSTM 14.92±4.09 56.00±4.59
Transformer 18.10±2.58 48.44±2.29
TCN 15.24±1.62 44.22±1.63
CNN 13.97±2.54 70.00±1.99
DANN 15.87±4.71 80.22±1.78
REFERENCES
[1] Y . Zhang, J. Ji, Z. Ren, Q. Ni, F. Gu, K. Feng, K. Yu, J. Ge, Z. Lei, and
Z. Liu, “Digital twin-driven partial domain adaptation network for intelligent fault
diagnosis of rolling bearing,” Reliability Engineering & System Safety , vol. 234,
p. 109186, 2023.
[2] D. Zhong, Z. Xia, Y . Zhu, and J. Duan, “Overview of predictive maintenance based
on digital twin technology,” Heliyon , vol. 9, no. 4, 2023.
[3] M. G. Juarez, V . J. Botti, and A. S. Giret, “Digital twins: Review and challenges,”
Journal of Computing and Information Science in Engineering , vol. 21, no. 3,
p. 030802, 2021.
[4] P. Jain, J. Poon, J. P. Singh, C. Spanos, S. R. Sanders, and S. K. Panda, “A
digital twin approach for fault diagnosis in distributed photovoltaic systems,” IEEE
Transactions on Power Electronics , vol. 35, no. 1, pp. 940–956, 2019.
[5] J. Wang, L. Ye, R. X. Gao, C. Li, and L. Zhang, “Digital twin for rotating machinery
fault diagnosis in smart manufacturing,” International Journal of Production
Research , vol. 57, no. 12, pp. 3920–3934, 2019.
[6] C. Yang, B. Cai, Q. Wu, C. Wang, W. Ge, Z. Hu, W. Zhu, L. Zhang, and
L. Wang, “Digital twin-driven fault diagnosis method for composite faults by
combining virtual and real data,” Journal of Industrial Information Integration ,
vol. 33, p. 100469, 2023.
[7] Y . Ran, X. Zhou, P. Lin, Y . Wen, and R. Deng, “A survey of predictive maintenance:
Systems, purposes and approaches,” arXiv preprint arXiv:1912.07383 , pp. 1–36,
2019.
[8] K. M. Court, X. M. Court, S. Du, and Z. Zeng, “Use digital twins to sup-
port fault diagnosis from system-level condition-monitoring data,” arXiv preprint
arXiv:2411.01360 , 2024.
[9] Y . Ganin and V . Lempitsky, “Unsupervised domain adaptation by backpropagation,”
inInternational conference on machine learning , pp. 1180–1189, PMLR, 2015.
[10] S. Hochreiter, “Long short-term memory,” Neural Computation MIT-Press , 1997.
[11] A. Vaswani, “Attention is all you need,” Advances in Neural Information Processing
Systems , 2017.
[12] Y . LeCun, B. Boser, J. Denker, D. Henderson, R. Howard, W. Hubbard, and
L. Jackel, “Handwritten digit recognition with a back-propagation network,”
Advances in neural information processing systems , vol. 2, 1989.
[13] S. Bai, J. Z. Kolter, and V . Koltun, “An empirical evaluation of generic
convolutional and recurrent networks for sequence modeling,” arXiv preprint
arXiv:1803.01271 , 2018.
[14] M. He and D. He, “Deep learning based approach for bearing fault diagnosis,”
IEEE Transactions on Industry Applications , vol. 53, no. 3, pp. 3057–3065, 2017.
[15] M. Xia, T. Li, L. Xu, L. Liu, and C. W. De Silva, “Fault diagnosis for rotating
machinery using multiple sensors and convolutional neural networks,” IEEE/ASME
transactions on mechatronics , vol. 23, no. 1, pp. 101–110, 2017.
[16] J. Shi, D. Peng, Z. Peng, Z. Zhang, K. Goebel, and D. Wu, “Planetary gearbox fault
diagnosis using bidirectional-convolutional lstm networks,” Mechanical Systems
and Signal Processing , vol. 162, p. 107996, 2022.[17] S. Plakias and Y . S. Boutalis, “Fault detection and identification of rolling element
bearings with attentive dense cnn,” Neurocomputing , vol. 405, pp. 208–217, 2020.
[18] W. Li, R. Huang, J. Li, Y . Liao, Z. Chen, G. He, R. Yan, and K. Gryllias,
“A perspective survey on deep transfer learning for fault diagnosis in industrial
scenarios: Theories, applications and challenges,” Mechanical Systems and Signal
Processing , vol. 167, p. 108487, 2022.
[19] H. Zhiyi, S. Haidong, J. Lin, C. Junsheng, and Y . Yu, “Transfer fault diagnosis
of bearing installed in different machines using enhanced deep auto-encoder,”
Measurement , vol. 152, p. 107393, 2020.
[20] H. Cao, H. Shao, X. Zhong, Q. Deng, X. Yang, and J. Xuan, “Unsupervised domain-
share cnn for machine fault transfer diagnosis from steady speeds to time-varying
speeds,” Journal of Manufacturing Systems , vol. 62, pp. 186–198, 2022.
[21] L. Guo, Y . Lei, S. Xing, T. Yan, and N. Li, “Deep convolutional transfer learning
network: A new method for intelligent fault diagnosis of machines with unlabeled
data,” IEEE Transactions on Industrial Electronics , vol. 66, no. 9, pp. 7316–7325,
2018.
[22] S. Pang and X. Yang, “A cross-domain stacked denoising autoencoders for rotating
machinery fault diagnosis under different working conditions,” Ieee Access , vol. 7,
pp. 77277–77292, 2019.
[23] D. Xiao, Y . Huang, L. Zhao, C. Qin, H. Shi, and C. Liu, “Domain adaptive motor
fault diagnosis using deep transfer learning,” Ieee Access , vol. 7, pp. 80937–80949,
2019.
[24] B. Yang, Y . Lei, F. Jia, and S. Xing, “An intelligent fault diagnosis approach based
on transfer learning from laboratory bearings to locomotive bearings,” Mechanical
Systems and Signal Processing , vol. 122, pp. 692–706, 2019.
[25] Z. He, H. Shao, X. Zhang, J. Cheng, and Y . Yang, “Improved deep transfer auto-
encoder for fault diagnosis of gearbox under variable working conditions with small
training samples,” Ieee Access , vol. 7, pp. 115368–115377, 2019.
[26] H. Kim and B. D. Youn, “A new parameter repurposing method for parameter
transfer with small dataset and its application in fault diagnosis of rolling element
bearings,” Ieee Access , vol. 7, pp. 46917–46930, 2019.
[27] S. Shao, S. McAleer, R. Yan, and P. Baldi, “Highly accurate machine fault diagnosis
using deep transfer learning,” IEEE Transactions on Industrial Informatics , vol. 15,
no. 4, pp. 2446–2455, 2018.
[28] C. Cheng, B. Zhou, G. Ma, D. Wu, and Y . Yuan, “Wasserstein distance based
deep adversarial transfer learning for intelligent fault diagnosis with unlabeled or
insufficient labeled data,” Neurocomputing , vol. 409, pp. 35–45, 2020.
[29] S. Lu, T. Sirojan, B. T. Phung, D. Zhang, and E. Ambikairajah, “Da-dcgan: An
effective methodology for dc series arc fault diagnosis in photovoltaic systems,”
IEEE Access , vol. 7, pp. 45831–45840, 2019.
[30] H. Shimodaira, “Improving predictive inference under covariate shift by weighting
the log-likelihood function,” Journal of statistical planning and inference , vol. 90,
no. 2, pp. 227–244, 2000.